<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[redis配置项说明]]></title>
    <url>%2F2019%2F09%2F06%2Fredis%E9%85%8D%E7%BD%AE%E9%A1%B9%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[redis.conf 配置项说明如下： Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 port 6379 绑定的主机地址 bind 127.0.0.1 5.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null logfile stdout 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb 指定本地数据库存放目录 dir ./ 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 slaveof 当master服务设置了密码保护时，slav服务连接master的密码 masterauth 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭 requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendonly no 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof 指定更新日志条件，共有3个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折衷，默认值） appendfsync everysec 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） vm-enabled no 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 0 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-page-size 32 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-pages 134217728 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 vm-max-threads 4 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） activerehashing yes 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解epoll]]></title>
    <url>%2F2019%2F09%2F06%2F%E7%90%86%E8%A7%A3epoll%2F</url>
    <content type="text"><![CDATA[epoll模型是在单个线程中侦听多个套接字fd行为的一种IO多路复用模型。主要有epoll_create,epoll_ctl,epoll_wait三个接口。 一、epoll的使用1. 创建epoll句柄 int epfd = epoll_create(intsize);创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大。size就是你在这个epoll fd上能关注的最大socket fd数。 2.将被监听的描述符添加到epoll句柄或从epool句柄中删除或者对监听事件进行修改。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)参数：epfd：由 epoll_create 生成的epoll专用的文件描述符；op：要进行的操作例如注册事件，可能的取值EPOLL_CTL_ADD 注册、EPOLL_CTL_MOD 修 改、EPOLL_CTL_DEL 删除fd：关联的文件描述符；event：指向epoll_event的指针；如果调用成功返回0,不成功返回-1 第一个参数是epoll_create()的返回值，第二个参数表示动作，用三个宏来表示： EPOLL_CTL_ADD： 注册新的fd到epfd中； EPOLL_CTL_MOD： 修改已经注册的fd的监听事件； EPOLL_CTL_DEL： 从epfd中删除一个fd；第三个参数是需要监听的fd，第四个参数是告诉内核需要监听什么事件，structepoll_event结构如下：123456789101112131415161718192021typedef union epoll_data &#123;void *ptr; //指向要附加的数据结构int fd; //一般设为监视的fd__uint32_t u32;__uint64_t u64;&#125; epoll_data_t;struct epoll_event &#123;/* Epoll eventsevents可以是以下几个宏的集合： EPOLLIN： 触发该事件，表示对应的文件描述符上有可读数据。(包括对端SOCKET正常关闭)； EPOLLOUT： 触发该事件，表示对应的文件描述符上可以写数据； EPOLLPRI： 表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR： 表示对应的文件描述符发生错误； EPOLLHUP： 表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT： 只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里。 */__uint32_t events; epoll_data_t data; /* User data variable */&#125;; 如要监听服务端套接字的连接，listenfd对对应的socket套接字，之前已经bind和listen好。将它加入到epfd指定的epoll对象中1234567struct epoll_event ev;//设置与要处理的事件相关的文件描述符ev.data.fd=listenfd;//设置要处理的事件类型ev.events=EPOLLIN|EPOLLET;//注册epoll事件epoll_ctl(epfd,EPOLL_CTL_ADD,listenfd,&amp;ev); 3.等待事件触发，当超过timeout还没有事件触发时，就超时。 int epoll_wait(int epfd, struct epoll_event events, intmaxevents, int timeout);函数声明:int epoll_wait(int epfd,struct epoll_event events,int maxevents,int timeout)该函数用于轮询I/O事件的发生；参数：epfd:由epoll_create 生成的epoll专用的文件描述符；epoll_event:用于回传代处理事件的数组，已经分配好内存；maxevents:每次能处理的最大事件数；timeout:等待I/O事件发生的超时值(单位我也不太清楚)；-1相当于阻塞，0相当于非阻塞。一般用-1即可返回发生事件数。 二、epoll的原理本节会以示例和图表来讲解epoll的原理和流程。 1.创建epoll对象如下图所示，当某个进程调用epoll_create方法时，内核会创建一个eventpoll对象（也就是程序中epfd所代表的对象）。eventpoll对象也是文件系统中的一员，和socket一样，它也会有等待队列。 创建一个代表该epoll的eventpoll对象是必须的，因为内核要维护“就绪列表”等数据，“就绪列表”可以作为eventpoll的成员。 2.维护监视列表创建epoll对象后，可以用epoll_ctl添加或删除所要监听的socket。以添加socket为例，如下图，如果通过epoll_ctl添加sock1、sock2和sock3的监视，内核会将eventpoll添加到这三个socket的等待队列中。 当socket收到数据后，中断程序会操作eventpoll对象，而不是直接操作进程。 3.接收数据当socket收到数据后，中断程序会给eventpoll的“就绪列表”添加socket引用。如下图展示的是sock2和sock3收到数据后，中断程序让rdlist引用这两个socket。 eventpoll对象相当于是socket和进程之间的中介，socket的数据接收并不直接影响进程，而是通过改变eventpoll的就绪列表来改变进程状态。 当程序执行到epoll_wait时，如果rdlist已经引用了socket，那么epoll_wait直接返回，如果rdlist为空，阻塞进程。 4.阻塞和唤醒进程假设计算机中正在运行进程A和进程B，在某时刻进程A运行到了epoll_wait语句。如下图所示，内核会将进程A放入eventpoll的等待队列中，阻塞进程。 当socket接收到数据，中断程序一方面修改rdlist，另一方面唤醒eventpoll等待队列中的进程，进程A再次进入运行状态（如下图）。也因为rdlist的存在，进程A可以知道哪些socket发生了变化。 三、epoll的实现细节读完这篇文章，还有三个问题需要细究一下。 eventpoll的数据结构是什么样子？ 就绪队列应该应使用什么数据结构？ eventpoll应使用什么数据结构来管理通过epoll_ctl添加或删除的socket？ 如下图所示，eventpoll包含了lock、mtx、wq（等待队列）、rdlist等成员。rdlist和rbr是我们所关心的。 1. 就绪列表的数据结构 就绪列表引用着就绪的socket，所以它应能够快速的插入数据。 程序可能随时调用epoll_ctl添加监视socket，也可能随时删除。当删除时，若该socket已经存放在就绪列表中，它也应该被移除。 所以就绪列表应是一种能够快速插入和删除的数据结构。双向链表就是这样一种数据结构，epoll使用双向链表来实现就绪队列（对应上图的rdllist）。 2.索引结构既然epoll将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的socket。至少要方便的添加和移除，还要便于搜索，以避免重复添加。红黑树是一种自平衡二叉查找树，搜索、插入和删除时间复杂度都是O(log(N))，效率较好。epoll使用了红黑树作为索引结构（对应上图的rbr），存储所监视的socket fd。]]></content>
      <categories>
        <category>IO多路复用</category>
      </categories>
      <tags>
        <tag>epoll</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海量数据处理问题]]></title>
    <url>%2F2019%2F09%2F06%2F%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一、方法论 对于固定大小的海量数据，通常可以采用分文件+哈希统计+内存处理（堆/快速/归并排序）的方法。 对于字符串数据，可以对字符串进行哈希，哈希值%n(n为分文件数量)，这样来说同一个字符串必然分配到一个文件当中，然后如果哈希均匀的话，就能够保证每个文件可以放入内存当中，在内存当中采用通用方法进行处理获得每个文件的结果，然后写到磁盘中，最后汇总或者直接在内存中汇总。 对于数字，可以直接x%n（n为分文件数量）或者采用二进制前k位来分成2^k个文件块。 Bloom filter(布隆过滤器) 判断一条记录在另一个记录集合中是否存在。具体操作时，对于记录集合S中的n条记录，设置m位的bitmap和k个独立hash函数，遍历S集合，对于每条记录，将其k个hash函数值对应位置1。要判断一条记录是否存在时，查看其k个hash函数值对应位是否都是1，如果是，就认为存在，否则就不存在。bloom filter对于有hash函数值为0的，那么就可以100%确定这条记录不存在，但是可能把不存在的误判成存在的。但是这样的概率很小。 m应该&gt;=nlg(1/E)lge 大概就是nlg(1/E)1.44倍，当hash函数个数k=(ln2)(m/n)时错误率最小。 Counting bloom filter（CBF）将位数组中的每一位扩展为一个counter，从而支持了元素的删除操作。counter可以记录hash值对应到该counter的次数 bitmap 对于uint32型的数据比较有用，uint32每个数字对应一位，最后会申请512M的内存。 Trie树（前缀树） 适用范围：数据量大，重复多，但是数据种类小可以放入内存。 基本原理及要点：实现方式，节点孩子的表示方式 扩展：压缩实现。 外排序 外部排序是针对海量数据无法放入内存中排序而产生的一种排序算法。基本算法是拆分成多个小文件，每个小文件可以放入内存当中，对于小文件进行排序后，再采用多路归并排序，也就是构造一个大小为文件块数的堆（升序就是小堆，降序就是最大堆），先分别从k个文件中读取一个数插入堆中，将堆顶元素写到文件中，然后从写出元素所在文件中再读入一个数，依次进行下去。 适用范围：大数据的排序，去重面试问题： 海量日志数据，提取出某日访问百度次数最多的那个IP。 方法一: 分而治之/哈希映射：读取ip，划分成n个文件根据hashCode%n值，分划到相应的文件当中 哈希统计：对于每个文件，可以读入内存，hashmap统计ip次数（注意一个ip只会出现在一个文件当中），然后通过排序或者遍历获得最大次数的ip。 汇总：获得每个文件中出现次数最多的ip，进行堆排或者快排或者扫描，就可以获得出现次数最多的ip。 方法二： trie树，用第k叉表示ip的一部分（ip可以分为四部分）。叶结点值可以存放ip次数。 寻找热门查询，300万个查询字符串中统计最热门的10个查询300万个字符串如果可以放进内存存储为hashmap，那么就不用分而治之/哈希映射了。哈希统计：hashmap统计每个字符串出现次数堆排序：简历大小为10的小顶堆，堆元素为键值对，键为字符串，值为字符串出现次数，遍历hasmap或者读入文件流，遇到键值对的值大于堆顶元素值，就插入堆，并且删除堆顶键值对。遍历完毕后就可以获得top k查询结果。trie树加大小为10的最小堆的方法也能够解决 在10G数据中，数据类型为uint32，内存1G，寻找其中重复出现的数字方法一、分而治之/哈希映射：根据uint32前4位将数据分成2^4个文件块哈希统计：hashmap统计每个文件块中重复出现的数字汇总：将每个文件快重复出现的数字直接并起来方法二、 bitmapuint32为2^32次方，对于每个数用一个bit记录是否出现，如果出现，就置该bit为1，如果发现该bit位已经为1，那么就直接将该数写到文件中，说明已经出现过。这种方法效率很高，但是如果可用内存更小或者改成uint64，那么就不行了。 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。 如果每个数据只在一台电脑上出现，那么求出每台电脑的TOP10，再进行汇总。 遍历一遍所有数据，重新hash取摸，如此使得同一个元素只出现在单独的一台电脑中，然后采用上面所说的方法，统计每台电脑中各个元素的出现次数找出TOP10，继而组合100台电脑上的TOP10，找出最终的TOP10。 或者，暴力求解：直接统计统计每台电脑中各个元素的出现次数，然后把同一个元素在不同机器中的出现次数相加，最终从所有数据中找出TOP10。 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？将a,b两个文件中的url经哈希分散到a[1000]个子文件中和b[1000]子文件中后，文件$a_i$与$b_i$放入内存取交集即可。 怎么在海量数据中找出重复次数最多的一个？先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个,然后求所有文件中最大的重复次数。总结：对于固定大小的海量数据，通用做法就是分文件hash+内存处理（堆/快速/归并排序）+汇总方法解决。可以一次性放进内存中处理的做法有bitmap，trie树。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>海量数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量迁移markdown文件图片到云存储中]]></title>
    <url>%2F2019%2F09%2F06%2F%E6%89%B9%E9%87%8F%E8%BF%81%E7%A7%BBmarkdown%E6%96%87%E4%BB%B6%E5%9B%BE%E7%89%87%E5%88%B0%E4%BA%91%E5%AD%98%E5%82%A8%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[批量迁移markdown文档到云存储中之前一直为撰写md文档的图片问题感到苦恼，要么存在本地但是文档想要整体迁移到网上就很麻烦，要么就得往文档中插入插入图片就得传到云端费时费力。于是感觉到写一个python脚本一劳永逸地解决这个问题的必要性。 需求 通过类似于python srcipt md_file/directory的命令整体将指定md文档或者指定文件夹下的所有md文档中的图片整体从其他网址或本地相对/绝对路径迁移到指定的云存储中 通过默认或者指定配置文件来支持多种类型的云存储 支持图片压缩 目前支持七牛云和又拍云云存储 整体的代码流程 ) 预备环境 python3 依赖库, pip install -r requirements.txt安装所有依赖库 1234567891011qiniucertifi==2019.6.16chardet==3.0.4decorator==4.4.0idna==2.8requests==2.22.0six==1.12.0tinify==1.5.1upyun==2.5.2urllib3==1.25.3validators==0.14.0 如果实在类unix系统中，可在家目录下新建.md.mdPicTransfer.cfg文件，用于配置云存储。格式如下： 三个配置大项。common,upai,qiniu分别对应基础配置，又拍云配置，七牛云配置 upai下面是又拍云上传文件所需要的基本配置 qiniu下面是七牛云上传文件所需要的基本配置 12345678910111213[common]option=upai/qiniutinypngkey=xxx[upai]servicename=xxxoperatorname=xxxpassword=xxxdomain=xxx[qiniu]accesskey=xxxsecretkey=xxxbucketname=xxxdomain=xxx 获得代码 将下面源码所列的四个文件放在一个文件夹中，按照提示运行程序迁移指定md文档或指定文件夹的所有md文档中的图片到云存储中。 从此仓库克隆代码下来到本地，pip install -r requirements.txt安装所有依赖库，按照提示运行程序。 源码 picUploader.py, 主文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328import reimport osimport sysimport datetimeimport platformimport imghdrimport shutilimport tinifyimport urllibimport sqlite3from hashlib import md5import validatorsimport getoptimport configparserfrom QiniuYun import Qiniufrom UpYun import Upaimd_loc = '' # md地址need_zip = Falseos_name = ''need_cache = Falsetoday = datetime.date.today()yyyymmdd = today.strftime('%Y%m%d') # 创建时间变量，用于图片起名total, success, failure, ignore = 0, 0, 0, 0cloud_cfg = Noneneed_back = Falsedef upload_file(upload_file_name): ''' 根据给定的图片名上传图片，并返回图片地址和一些上传信息 ''' global success, failure # 上传到云存储后的图片名:上传日期-MD文件名/image序号.png or jpg key = yyyymmdd + "_" + os.path.splitext(os.path.basename(sys.argv[1]))[0] + "/image" + ('&#123;0&#125;'.format(success + 1)) + \ os.path.splitext(upload_file_name)[1] try: upload_url = cloud_cfg.upload_file(upload_file_name, key, False) if upload_url: success = success + 1 return upload_url failure = failure + 1 except Exception as e: print("异常：", e) return Nonedef transfer_online_img(old_link): ''' 根据给定的图片链接上传图片到云存储，并返回图片地址和一些上传信息 ''' global success, ignore, failure if validators.url(old_link) is not True: ignore = ignore + 1 print('invalid url, ignore') return None # maybe a url # already from qiniu if old_link.find(cloud_cfg.domain) != -1: ignore = ignore + 1 print('already in target cloud, ignore') return None # omit the query string section like:?arg1=val1&amp;arg2=val2 in the url if old_link.find('?') != -1: old_link = old_link[: old_link.index('?')] # 上传到云存储后的图片名:上传日期-MD文件名/image序号 key = yyyymmdd + "_" + os.path.splitext(os.path.basename(sys.argv[1]))[0] + "/image" + ('&#123;0&#125;'.format(success + 1)) try: upload_url = cloud_cfg.upload_file(old_link, key, True) if upload_url: success = success + 1 return upload_url failure = failure + 1 except Exception as e: print("异常：", e) return Nonedef cached_img_url(img_loc_path): ''' 根据给定的本地图片绝对路径，转换成一个网上路径。 如果本地缓存中有，则直接读取并返回，如果没有，则上传后返回。 ''' conn = sqlite3.connect(md_loc + './img_hash_cache.db') cursor = conn.cursor() try: cursor.execute(''' CREATE TABLE if not exists img_cache_table ( img_hash TEXT, real_p TEXT, img_url TEXT ) ''') except Exception as e: pass img_hash = md5(open(img_loc_path, 'rb').read()).hexdigest() # 图片的hash值，用来确定图片的唯一性，避免多次上传，浪费流量 cursor.execute("SELECT img_url FROM img_cache_table WHERE img_hash='%s'" % img_hash) # 根据图片的hash值来找缓存下来的图片网址 select_res = [row for row in cursor] img_url = ( select_res[0][0] if select_res and len(select_res) &gt; 0 and select_res[0] and len(select_res[0]) &gt; 0 else None) remote_exists = False if img_url: try: remote_exists = urllib.request.urlopen(img_url).code == 200 except Exception as e: print('#warning: 网址不存在 ：', img_url) cursor.execute("DELETE FROM img_cache_table WHERE img_hash='%s'" % img_hash) remote_exists = False if remote_exists: print("已缓存") if not img_url or not remote_exists: # 如果没有查到图片的网址，或者网址失效 print('上传图片 ：', img_loc_path) img_url = upload_file(img_loc_path) # 接取上传后的图片信息 if not img_url: # 如果图片地址为空，则说明上传失败 print('#warning: 上传失败') conn.close() return None else: if not remote_exists: cursor.execute('INSERT INTO img_cache_table VALUES(?,?,?)', (img_hash, img_loc_path, img_url)) # 如果上传成功，则直接缓存下来 else: cursor.execute("UPDATE img_cache_table SET img_url='%s', u_info='%s' WHERE img_hash='%s'" % ( img_url, img_hash)) conn.commit() conn.close() return img_urldef zip_pic(loc_p): o_img = loc_p + '.ori' # 原始未压缩的图片 try: if not os.path.isfile(o_img) or not imghdr.what(o_img): # 如果没有的话，那就需要进行压缩处理 print('压缩图片 ：', loc_p) s_img = tinify.from_file(loc_p) s_img.to_file(loc_p + '.z') os.rename(loc_p, loc_p + '.ori') os.rename(loc_p + '.z', loc_p) except Exception as e: print('#warning: tinypng压缩出问题了，图片未压缩。')def upload_pic_proc(md_file, match): if not re.match('((http(s?))|(ftp))://.*', match): # 判断是不是已经是一个图片的网址 loc_p = match if not os.path.exists(loc_p) or not os.path.isfile(loc_p): # 如果文件不存在，则可能这是用的一个相对路径，需要转成绝对路径 # Windows中 md_file的本地路径为反斜杠\\, match的相对路径为 "MD标题\图片文件名" loc_p = (md_file[:md_file.rfind('\\') + 1] + match) if os_name == 'Windows' else ( md_file[:md_file.rfind('/') + 1] + match) if os.path.exists(loc_p) and os.path.isfile(loc_p) and imghdr.what(loc_p): if need_zip: zip_pic(loc_p) if need_cache: file_url = cached_img_url(loc_p) # 获取上传后的图片地址 else: print('上传图片 ：', loc_p) file_url = upload_file(loc_p) if file_url is None: print("上传失败") return file_url else: print('#warning: 文件不存在或者不是图片文件 ：', loc_p) return None else: print('markdown文件中的图片用的是网址 ：', match) file_url = transfer_online_img(match) # 获取上传后的图片地址 return file_urldef md_img_find(md_file): ''' 将给定的markdown文件里的图片本地路径转换成网上路径 ''' if need_back: bak_md = '%s.bak' % md_file shutil.copyfile(md_file, bak_md) # 在执行改动之前备份原MD文件，可手动删除 print('origin markdown file backup in: %s' % bak_md) post = None # 用来存放markdown文件内容 global total, success, failure, ignore with open(md_file, 'r', encoding='utf-8') as f: # 使用utf-8 编码打开 by chalkit post = f.read() matches = re.compile('!\\[.*?\\]\\((.*?)\\)|&lt;img.*?src=[\'\"](.*?)[\'\"].*?&gt;').findall(post) # 匹配md文件中的图片 if matches is None or len(matches) == 0: print("%s no matches" % md_file) return for sub_match in matches: # 正则里有个或，所以有分组，需要单独遍历去修改 for match in sub_match: # 遍历去修改每个图片 if match is None or len(match) == 0: continue total = total + 1 print("match pic : ", match) file_url = upload_pic_proc(md_file, match) if file_url: post = post.replace(match, file_url) # 替换md文件中的地址 else: ignore += 1 if post: open(md_file, 'w', encoding='utf-8').write(post) # 如果有内容的话，就直接覆盖写入当前的markdown文件 # 仍然注意用uft-8编码打开 print('Complete!') print(' total :%d' % total) print(' success :%d' % success) print(' failure :%d' % failure) print(' ignore :%d' % ignore)def find_md(folder): ''' 在给定的目录下寻找md文件 ''' if len(folder) &gt; 3 and folder[folder.rfind('.') + 1:] == 'md': md_img_find(folder) # 判断是否是一个md文件，如果是的话，直接开始转换 elif os.path.isdir(folder): files = os.listdir(folder) # 读取目录下的文件 for file in files: curp = folder + '/' + file if os.path.isdir(curp): find_md(curp) # 递归读取 elif file[file.rfind('.') + 1:] == 'md': md_img_find(curp)def get_config(cfg_file_path): global cloud_cfg if os.path.exists(cfg_file_path) and os.path.isfile(cfg_file_path): config = configparser.ConfigParser() config.read(cfg_file_path, encoding="utf-8") try: option = config.get('common', 'option') if option == "upai": servicename = config.get(option, "servicename") operatorname = config.get(option, "operatorname") password = config.get(option, "password") domain = config.get(option, "domain") cloud_cfg = Upai(servicename, operatorname, password, domain) elif option == "qiniu": ak = config.get(option, "accesskey") sk = config.get(option, "secretkey") bucketname = config.get(option, "bucketname") domain = config.get(option, "domain") cloud_cfg = Qiniu(ak, sk, bucketname, domain) else: print("目前不支持除又拍、七牛以外的云存储服务") sys.exit(0) if need_zip: tinify.key = config.get('common', 'tinypngkey') # 设置tinipng的key except configparser.NoOptionError as e: print("配置出错: ", e) sys.exit(0) else: print("配置文件路径出错") sys.exit(0)def usage(): print('''usage: python %s file [-c|--config configfile] [-z|--zip] [--cache] [-b|--back] python %s -R|--Recursive directory [-c|--config configfile] [-z|--zip] [-b|--back] python %s -h|--help ''' % (sys.argv[0], sys.argv[0], sys.argv[0]))if __name__ == '__main__': dir_path = '' file_path = '' config_file = '' os_name = platform.system() find_err = False try: opts, args = getopt.getopt(sys.argv[1:], 'hR:c:zb', ["help", "Recursive=", "config=", "zip", "cache", "back"]) for opt, arg in opts: if opt in ("-h", "--help"): usage() sys.exit(0) elif opt in ("-R", "--Recursive"): dir_path = arg elif opt in ("-c", "--config"): config_file = arg elif opt in ("-z", "--zip"): need_zip = True elif opt == "--cache": need_cache = True elif opt in ("-b", "--back"): need_back = True else: usage() exit(1) if args is not None and (len(args) != 0): if len(args) == 1: file_path = args[0] else: find_err = True except getopt.GetoptError: usage() sys.exit(1) if (file_path and dir_path) or (not file_path and not dir_path) or find_err: # 两个都设置或者两个都没设置或者已经发现错误，出错 usage() sys.exit(1) if file_path: c_p = file_path md_loc = c_p[:c_p.rfind('/') + 1] else: c_p = dir_path if c_p[-1] == '/': md_loc = c_p else: md_loc = c_p + '/' if not config_file: if os_name == 'Windows': print("please input config file path in Windows") exit(1) else: config_file = os.getenv("HOME") + "/.mdPicTransfer.cfg" if not os.path.exists(c_p): print("路径不存在") sys.exit(0) get_config(config_file) find_md(c_p) CommonYun.py, 云存储基类 123456789from abc import abstractmethodclass CommonYun(object): def __init__(self, domain): self.domain = domain @abstractmethod def upload_file(self): pass UpYun.py, 又拍云类 123456789101112131415161718192021222324import requestsfrom io import BytesIOimport upyunfrom CommonYun import CommonYunclass Upai(CommonYun): def __init__(self, servicename, operatorname, password, domain): self.option = "upai" CommonYun.__init__(self, domain) self.up = upyun.UpYun(servicename, operatorname, password) def upload_file(self, upload_file_name, key, is_old_link): res = None if is_old_link: response = requests.get(upload_file_name) if response.status_code == 200: file = BytesIO(response.content) res = self.up.put(key, file, checksum=True) else: with open(upload_file_name, 'rb') as f: res = self.up.put(key, f, checksum=True) return self.domain + "/" + key if res else None QiniuYun.py, 七牛云类 1234567891011121314151617181920212223from qiniu import Auth, put_file, etag, BucketManagerfrom CommonYun import CommonYunclass Qiniu(CommonYun): def __init__(self, accesskey, secretkey, bucketname, domain): self.option = "qiniu" self.bucketname = bucketname CommonYun.__init__(self, domain) self.qiniu = Auth(accesskey, secretkey) # 七牛认证 self.Bucket_Manager = BucketManager(self.qiniu) # 初始化BucketManager def upload_file(self, upload_file_name, key, is_old_link): if is_old_link: ret, info = self.Bucket_Manager.fetch(upload_file_name, self.bucketname, key) if ret['key'] == key: return self.domain + '/' + key else: mime_type = upload_file_name[upload_file_name.rfind('.') + 1:] token = self.qiniu.upload_token(self.bucketname, key) ret, info = put_file(token, key, upload_file_name, mime_type=mime_type, check_crc=True) if ret['key'] == key and ret['hash'] == etag(upload_file_name): return self.domain + '/' + key 演示效果 运行该程序，将得到文件与备份文件用git diff origin cur,比较有如下结果： 1234567891011121314151617181920diff --git &quot;a/Java\345\271\266\345\217\221.md&quot; &quot;b/Java\345\271\266\345\217\221.md.bak&quot;index 2ba4604..5db5bf0 100644--- &quot;a/Java\345\271\266\345\217\221.md&quot;+++ &quot;b/Java\345\271\266\345\217\221.md.bak&quot;@@ -2,7 +2,7 @@ ### 一、线程状态转换 -&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;http://hjx-markdown-images.test.upcdn.net/20190906_--cache/image1.png&quot; width=&quot;600px&quot;&gt; &lt;/div&gt;&lt;br&gt;+&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;pics/adfb427d-3b21-40d7-a142-757f4ed73079.png&quot; width=&quot;600px&quot;&gt; &lt;/div&gt;&lt;br&gt; #### 新建（New） @@ -675,7 +675,7 @@ java.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是 J. 维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。 -&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;http://hjx-markdown-images.test.upcdn.net/20190906_--cache/image2.png&quot; width=&quot;300px&quot;&gt; &lt;/div&gt;&lt;br&gt;+&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;pics/ba078291-791e-4378-b6d1-ece76c2f0b14.png&quot; width=&quot;300px&quot;&gt; &lt;/div&gt;&lt;br&gt;...]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>makdown图片迁移脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电梯运行模拟]]></title>
    <url>%2F2019%2F07%2F14%2F%E7%94%B5%E6%A2%AF%E8%BF%90%E8%A1%8C%E6%A8%A1%E6%8B%9F%2F</url>
    <content type="text"><![CDATA[​ 日常生活中，大家都坐过电梯，有时候会想想电梯在每个人按下键之后是怎么运行的呢？这是个看起来似乎简单但想清楚却也不容易的问题。 ​ 给电梯的运行进行建模。电梯在运行过程中会载人同时接受外部的请求，这样我们可以用两个队列来表示载人信息和请求信息。对于乘客来说，其信息主要是当前楼层和目标楼层，为了方便打印，给每个乘客命名。电梯的运行有三种状态：WAIT(停)，UP(上)，DOWN(下)。电梯根据载人队列和请求队列来更新自己的状态，在每一层都判断是否可以进人(针对请求队列)，出人(针对载人队列)。下面是运行算法图示。 ​ 当电梯处于上行/下行状态时，到达新的楼层时(本次循环开始)，每次循环检查是否需要有人进出，根据载人列表、请求列表及当前运行状态判断出接下来的状态，如果是上行/下行，沉睡1s作为上行/下行一层楼的时间。算法的特征是，先来先服务，在上行/下行过程中尽可能接到或者放出更多的人，在上行/下行过程中只接受与电梯运行方向一致的人。 ​ 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113import java.io.*;import java.util.LinkedList;import java.util.List;import java.util.Scanner;/*从文件中读入输入命令及参数*/public class Elevator &#123; private static List&lt;EleInfo&gt; infoList = new LinkedList&lt;&gt;(); public static void main(String[] args) throws FileNotFoundException &#123; start(); new EleRunner(infoList).start(); &#125; public static void start() throws FileNotFoundException &#123; int minFloor = 0; int maxFloor = 0; boolean started = false; boolean inputValid = false; Scanner in = new Scanner( new FileInputStream("/Users/macbook/programming/Java/leetcode/src/com/test/input.txt"),"UTF-8"); PrintWriter out = new PrintWriter( new FileOutputStream("/Users/macbook/programming/Java/leetcode/src/com/test/log.txt",true),true); while(!inputValid) &#123; out.println("电梯模拟运行开始,请输入参数（最低楼层，最高楼层）:"); try &#123; minFloor = Integer.parseInt(in.next()); maxFloor = Integer.parseInt(in.next()); inputValid = true; &#125; catch (Exception e) &#123; System.out.println("输入异常！"); &#125; &#125; while(true) &#123; out.println("请输入命令(up/down/stop/start):"); String cmd = in.next(); if(started &amp;&amp; cmd.equals("start")) &#123; //已经开始但输入命令仍是start, 报错 System.out.println("已经开始，不能再输入start!"); continue; &#125; if(!started &amp;&amp; !cmd.equals("start")) &#123; //没有开始但是输入命令不是start,报错 out.println("请输入start开始！"); continue; &#125; if (cmd.equals("start")) &#123;//开始 started = true; infoList.add(new EleInfo(null, minFloor, maxFloor, "start")); &#125; else if (cmd.equals("stop")) &#123;//结束，跳出循环 infoList.add(new EleInfo(null, 0, 0, "stop")); break; &#125; else if(cmd.equals("up") || cmd.equals("down")) &#123; String name = in.next(); try &#123; int curFloor = Integer.parseInt(in.next()); int targetFloor = Integer.parseInt(in.next()); if (curFloor&gt;=minFloor&amp;&amp;curFloor&lt;=maxFloor&amp;&amp;targetFloor&gt;=minFloor &amp;&amp;targetFloor&lt;=maxFloor&amp;&amp;targetFloor!=curFloor) &#123; if((cmd.equals("up")&amp;&amp;curFloor&gt;=targetFloor) || (cmd.equals("down")&amp;&amp;curFloor&lt;=targetFloor)) &#123; out.println("命令与输入楼层不匹配"); &#125; else if(curFloor==targetFloor) &#123; out.println("目标楼层与当前楼层不一致！"); &#125; else if(!isNameDuplicated(name)) &#123; out.println("人名重复！"); &#125; else &#123;//一切输入合法 infoList.add(new EleInfo(name, curFloor, targetFloor, cmd)); &#125; &#125; else &#123; if(curFloor &lt; minFloor || curFloor &gt; maxFloor) &#123; out.println("当前楼层不合法！"); &#125; if(targetFloor &lt; minFloor || targetFloor &gt; maxFloor) &#123; out.println("目标楼层不合法！"); &#125; if(targetFloor==curFloor) &#123; out.println("当前楼层与目标楼层不能相同！"); &#125; &#125; &#125; catch (Exception e) &#123; out.println("输入楼层异常！"); &#125; &#125; else &#123; out.println("输入命令出错！"); &#125; &#125; in.close(); &#125; private boolean isNameDuplicated(String name) &#123; for(EleInfo e:infoList) &#123; if(e.name.equals(name)) return true; &#125; &#125;&#125;class EleInfo &#123; String name; int curFloor; int targetFloor; String cmd; public EleInfo(String name, int curFloor, int targetFloor, String cmd) &#123; this.name = name; this.curFloor = curFloor; this.targetFloor = targetFloor; this.cmd = cmd; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.PrintWriter;import java.util.*;/*电梯运行过程状态变化*/public class EleRunner &#123; private List&lt;EleInfo&gt; requestList; private List&lt;EleInfo&gt; inElevatorList = new LinkedList&lt;&gt;(); PrintWriter out; private ElevatorState state = ElevatorState.WAIT; private int curFloor = 0; private boolean started = false; private boolean stop = false; public EleRunner(List&lt;EleInfo&gt; infoList) throws FileNotFoundException &#123; this.requestList = infoList; out = new PrintWriter(new FileOutputStream("/Users/macbook/programming/Java/leetcode/src/com/test/output.txt",true),true); &#125; public void start() &#123; while(true) &#123; if(requestList.isEmpty()) continue; while(started) &#123; if(requestList.isEmpty()) &#123; state = ElevatorState.WAIT; continue; &#125; if(requestList.size()==1 &amp;&amp; inElevatorList.isEmpty() &amp;&amp; requestList.get(0).cmd.equals("stop")) &#123; out.println("电梯停止运行！"); requestList.remove(0); started = false; stop = true; break; &#125; switch(state) &#123; case WAIT: waitProc(); break; case UP: upProc(); break; case DOWN: downProc(); break; default: throw new IllegalArgumentException(); &#125; if(!requestList.isEmpty()) personIn();//状态更新，可能还可以有人进来 if(state==ElevatorState.UP || state==ElevatorState.DOWN) &#123; try &#123; Thread.sleep(1000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; curFloor = (state==ElevatorState.UP)?(curFloor+1):(curFloor-1); String stateStr = (state==ElevatorState.UP)?"上升":"下降"; out.println("电梯到达"+curFloor+"楼，处于"+stateStr); &#125; &#125; if(stop) break; if(requestList.get(0).cmd.equals("start")) &#123; started = true; curFloor = requestList.get(0).curFloor; out.println("电梯启动！"); requestList.remove(0); &#125; &#125; &#125; private void waitProc() &#123; if(requestList.isEmpty()&amp;&amp;inElevatorList.isEmpty()) return; else &#123; //没有请求但是电梯还载着人 if(!requestList.isEmpty()) personIn(); if(!inElevatorList.isEmpty()) personOut(); if(!inElevatorList.isEmpty()) &#123; state = inElevatorList.get(0).targetFloor &gt; curFloor ? state = ElevatorState.UP:ElevatorState.DOWN; &#125; else if(isOnlyStopReq())&#123; state = ElevatorState.WAIT; out.println("电梯处于等待状态"); &#125; else if(!requestList.isEmpty())&#123; if(!requestList.get(0).cmd.equals("stop")) state = requestList.get(0).curFloor &gt; curFloor ? state = ElevatorState.UP:ElevatorState.DOWN; &#125; &#125; &#125; private void upProc() &#123; if(requestList.isEmpty()&amp;&amp;inElevatorList.isEmpty()) &#123; state = ElevatorState.WAIT; &#125; else &#123; if(!requestList.isEmpty()) personIn();//请求队列不空，看是否可以进人 if(!inElevatorList.isEmpty()) personOut();//在电梯队列不空，看是否可以放人 if(!inElevatorList.isEmpty()) &#123; for(EleInfo e:inElevatorList) &#123; if(e.targetFloor &gt; curFloor) return; &#125; state = ElevatorState.DOWN; &#125; else if(isOnlyStopReq())&#123; state = ElevatorState.WAIT; out.println("电梯处于等待状态"); &#125; else if(!requestList.isEmpty())&#123; for(EleInfo e:requestList) &#123; if(!e.cmd.equals("stop")&amp;&amp;e.curFloor &gt; curFloor) return; &#125; state = ElevatorState.DOWN; &#125; &#125; &#125; private void downProc() &#123; if(requestList.isEmpty()&amp;&amp;inElevatorList.isEmpty()) &#123; state = ElevatorState.WAIT; out.println("电梯处于等待状态"); &#125; else &#123; if(!requestList.isEmpty()) personIn(); if(!inElevatorList.isEmpty()) personOut(); if(!inElevatorList.isEmpty()) &#123; for(EleInfo e:inElevatorList) &#123; if(e.targetFloor &lt; curFloor) return; &#125; state = ElevatorState.UP; &#125; else if(isOnlyStopReq())&#123; state = ElevatorState.WAIT; out.println("电梯处于等待状态"); &#125; else if(!requestList.isEmpty())&#123; for(EleInfo e:requestList) &#123; if(!e.cmd.equals("stop")&amp;&amp;e.curFloor &lt; curFloor) return; &#125; state = ElevatorState.UP; &#125; &#125; &#125; private void personIn() &#123; Iterator&lt;EleInfo&gt; iterator = requestList.iterator(); while(iterator.hasNext()) &#123;//将curFloor等于电梯curFloor的请求删除，并放入inElevatorList中 EleInfo e = iterator.next(); if(e.curFloor==curFloor&amp;&amp;(state==ElevatorState.UP?(e.cmd.equals("up")):e.cmd.equals("down"))) &#123; out.println(e.name+"在"+curFloor+"楼进电梯了!"); iterator.remove(); inElevatorList.add(e); &#125; &#125; &#125; private void personOut() &#123; Iterator&lt;EleInfo&gt; iterator = inElevatorList.iterator(); while(iterator.hasNext()) &#123;//首先把在电梯上目标楼层是当前楼层的人放出 EleInfo e = iterator.next(); if(e.targetFloor == curFloor) &#123; out.println(e.name+"在"+curFloor+"楼出电梯了!"); iterator.remove(); &#125; &#125; &#125; private boolean isOnlyStopReq() &#123; return requestList.size()==1&amp;&amp;requestList.get(0).cmd.equals("stop"); &#125;&#125;enum ElevatorState &#123; WAIT, UP, DOWN&#125; 输入示例： 12345678910111 20startuphjx 2 10downhyk 6 2uphyk1 1 8downhjx2 15 2stop 输出结果： 1234567891011121314151617181920212223242526272829303132333435363738电梯启动！hyk1在1楼进电梯了!电梯到达2楼，处于上升hjx在2楼进电梯了!电梯到达3楼，处于上升电梯到达4楼，处于上升电梯到达5楼，处于上升电梯到达6楼，处于上升电梯到达7楼，处于上升电梯到达8楼，处于上升hyk1在8楼出电梯了!电梯到达9楼，处于上升电梯到达10楼，处于上升hjx在10楼出电梯了!电梯到达11楼，处于上升电梯到达12楼，处于上升电梯到达13楼，处于上升电梯到达14楼，处于上升电梯到达15楼，处于上升hjx2在15楼进电梯了!电梯到达14楼，处于下降电梯到达13楼，处于下降电梯到达12楼，处于下降电梯到达11楼，处于下降电梯到达10楼，处于下降电梯到达9楼，处于下降电梯到达8楼，处于下降电梯到达7楼，处于下降电梯到达6楼，处于下降hyk在6楼进电梯了!电梯到达5楼，处于下降电梯到达4楼，处于下降电梯到达3楼，处于下降电梯到达2楼，处于下降hjx2在2楼出电梯了!hyk在2楼出电梯了!电梯处于等待状态电梯停止运行！ 可以观察一下输入的记录和电梯运行的结果，还是挺符合生活习惯的。]]></content>
      <categories>
        <category>短发</category>
      </categories>
      <tags>
        <tag>电梯运行模拟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程间通信方式]]></title>
    <url>%2F2019%2F07%2F05%2F%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Unix IPC机制总结进程间通信(IPC, InterProcess Communication)是指在不同进程间传播或者交换信息 常见IPC的方式有管道、消息队列、信号量、共享存储、socket、Streams等，其中socket和streams支持不同主机上的两个进程进行通信。 一、管道1. 匿名管道特点 半双工，即数据只能在一个方向上流动，读写端固定 只能在具有亲缘关系的进程之间通信 可以看成是特殊的文件，有文件描述符，但只存在于内存中 原型12#include &lt;unistd.h&gt;int pipe(int fd[2]) 要关闭管道只需要将这两个文件描述符关闭就行 例子通常调用pipe的进程接着fork，这样就创建了父、子进程之间的IPC通道 若要数据流从父进程流向子进程，则需要关闭父进程的读端(fd[0])和子进程的写端(fd[1])；反之，则可以使得数据熊子进程流向父进程 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;int main()&#123; int fd[2]; pid_t pid; char buf[20]; if (pipe(fd) &lt; 0) &#123; printf("pipe error"); exit(1); &#125; if ((pid = fork()) &lt; 0) &#123; close(fd[0]); write(fd[1], "hello world\n", strlen("hello world\n")) &#125;&#125;]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>进程间通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Makefile赋值符辨析.md]]></title>
    <url>%2F2019%2F05%2F29%2FMakefile%E8%B5%8B%E5%80%BC%E7%AC%A6%E8%BE%A8%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Makefile 中:= ?= += =的区别在Makefile中我们经常看到 = := ?= +=这几个赋值运算符，那么他们有什么区别呢？我们来做个简单的实验 新建一个Makefile，内容为：12345678910111213141516171819ifdef DEFINE_VRE VRE = “Hello World!”elseendififeq ($(OPT),define) VRE ?= “Hello World! First!”endififeq ($(OPT),add) VRE += “Kelly!”endififeq ($(OPT),recover) VRE := “Hello World! Again!”endifall: @echo $(VRE) 敲入以下make命令： make DEFINE_VRE=true OPT=define 输出：Hello World!make DEFINE_VRE=true OPT=add 输出：Hello World! Kelly!make DEFINE_VRE=true OPT=recover 输出：Hello World! Again!make DEFINE_VRE= OPT=define 输出：Hello World! First!make DEFINE_VRE= OPT=add 输出：Kelly!make DEFINE_VRE= OPT=recover 输出：Hello World! Again! 从上面的结果中我们可以清楚的看到他们的区别了 = 是最基本的赋值 := 是覆盖之前的值 ?= 是如果没有被赋值过就赋予等号后面的值 += 是添加等号后面的值 之前一直纠结makefile中“=”和“:=”的区别到底有什么区别，因为给变量赋值时，两个符号都在使用。网上搜了一下，有人给出了解答，但是本人愚钝，看不懂什么意思。几寻无果之下，也就放下了。今天看一篇博客，无意中发现作者对于这个问题做了很好的解答。解决问题之余不免感叹，有时候给个例子不就清楚了吗？为什么非要说得那么学术呢。^_^ “=” make会将整个makefile展开后，再决定变量的值。也就是说，变量的值将会是整个makefile中最后被指定的值。看例子：123x = fooy = $(x) barx = xyz 在上例中，y的值将会是 xyz bar ，而不是 foo bar 。 “:=” “:=”表示变量的值决定于它在makefile中的位置，而不是整个makefile展开后的最终值。123x := fooy := $(x) barx := xyz 在上例中，y的值将会是 foo bar ，而不是 xyz bar了。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>Makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写数字识别]]></title>
    <url>%2F2018%2F12%2F10%2F%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[逻辑回归与神经网络实现手写数字识别本作业是采用Logistic回归和神经网络两种机器学习算法来识别0~9的手写数字。数据集来源于uci,编程语言为python,文档编写用jupyter notebook.通过wget命令下载数据 1!wget https://archive.ics.uci.edu/ml/machine-learning-databases/semeion/semeion.data 采用logistic算法识别手写数字逻辑回归，是一种被广泛用于分类的算法，通过对线性回归外套一个sigmoid函数使之适用于分类情况。采用一对多策略，先训练出K个二分类器（K为分类总数），当输入新样本时，选择使假设函数值最大的那个分类器对应的分类。首先导入机器学习常用的库，如numpy等。 12345678%matplotlib inlineimport numpy as npfrom numpy import *import matplotlib.pyplot as pltimport pandas as pdimport randomimport scipy.misc #Used to show matrix as an imageimport matplotlib.cm as cm #Used to display images in a specific colormap 导入并处理数据从文件导入数据，分析数据可知，数据共有1593行，每行有266个数字（0或1），其中前256个是16*16大小的手写数字图片的文本形式，后面10个数字分别表示0-9的识别结果。 1234fr = open('semeion.data')data = fr.readlines()data = [line.strip().split() for line in data]print("共有%d行数据,每行%d个数字"%(len(data),len(data[0]))) 1共有1593行数据,每行266个数字 将X,y从列表格式转成np.ndarray格式 12345678for i in range(len(data)): for j in range(len(data[0])): data[i][j] = int(float(data[i][j]))X = [example[0:256] for example in data]y_old = [example[256:] for example in data]y = [line.index(1) for line in y_old]X = np.array(X)y = np.array(y) 可视化数据123456789101112131415161718192021222324252627282930def getDatumImg(row,width,height): """ Function that is handed a single np array with shape 1x400, crates an image object from it, and returns it """ square = row[:].reshape(width,height) return square def displayData(width,height,indices_to_display = None): """ Function that picks 100 random rows from X, creates a 20x20 image from each, then stitches them together into a 10x10 grid of images, and shows it. """ nrows, ncols = 10, 10 if not indices_to_display: indices_to_display = random.sample(range(X.shape[0]), nrows*ncols) big_picture = np.zeros((height*nrows,width*ncols)) irow, icol = 0, 0 for idx in indices_to_display: if icol == ncols: irow += 1 icol = 0 iimg = getDatumImg(X[idx],width,height) big_picture[irow*height:irow*height+iimg.shape[0],icol*width:icol*width+iimg.shape[1]] = iimg icol += 1 fig = plt.figure(figsize=(6,6)) img = scipy.misc.toimage( big_picture ) plt.imshow(img,cmap = cm.Greys_r) 1displayData(16,16,list(range(100))) 训练算法：获得K*(n+1)的参数矩阵12# 添加全为1的第一列X = np.insert(X,0,values=np.ones(X.shape[0]),axis=1) # m*(n+1) 逻辑回归的代价函数如下图所示，其中第二项防止训练模型出现过拟合，也即经过正则化的代价函数逻辑回归代价函数对参数向量的梯度求解公式如下图所示，第二项也是为了防止过拟合的情况 1234567891011def sigmoid(z): return 1/(1+np.exp(-z))# 逻辑回归的假设函数def h(mytheta,myX): return sigmoid(np.dot(myX,mytheta)) # m一维向量# 逻辑回归的代价函数def computeCost(theta,X,y,lamb = 0): h_theta = h(theta,X) left_hand = np.mean(-y*np.log(h_theta)-(1-y)*np.log(1-h_theta)) right_hand = np.sum(np.square(theta[1:]))*lamb/(2*len(X)) return left_hand+right_hand 123456def costGradient(theta,X,y,lamb=0): #逻辑回归的梯度函数 first = (1/len(X))*X.T @ (h(theta,X)-y) # (n+1)一维向量 # (n+1)一维向量 reg = np.concatenate([np.array([0]),(lamb/len(X))*theta[1:]]) return first+reg 在代价函数及其梯度的求解方法确定后，就可以选择python第三方科学计算库scipy中的优化方法经过一定次数的迭代获得使代价函数最低的参数向量。当然也可以自己采用梯度下降法求解。 12345678910111213141516171819202122from scipy.optimize import minimizedef one_vs_all(X,y,lamb,K): """ 采用一对多策略利用逻辑回归分类 参数： X,特征矩阵，m*(n+1)，第一列为附加的0 y,真实分类向量，m一维向量 lamb，正则化用的lambda K,分类总数 返回： 训练好的theta向量,K*(n+1) """ all_theta = zeros((K,X.shape[1])) for i in range(K): init_theta = np.zeros(X.shape[1]) y_new = np.array([1 if i==num else 0 for num in y]) ret = minimize(fun=computeCost,x0=init_theta,args=(X,y_new,lamb), method='TNC',jac=costGradient,options=&#123;'maxiter':100,'disp':True&#125;) all_theta[i,:] = ret.x return all_theta 123456789101112def predictOneVsAll(all_theta,X): """ 估计手写数字样本数据X的识别结果 参数： all_theta,训练好的参数向量 X，待识别的样本数据 返回识别结果向量 """ # m*K，每一行向量代表该行对应样本取这个下标数字的可能性 h = sigmoid(X @ all_theta.T) h_argmax = np.argmax(h,axis=1) # 选取可能性最大的下标，表示样本取数字为该下标的可能性最大 return h_argmax 测试算法下面代码从样本数据集中随机抽取占比为0.67的数据作为训练数据集，剩余数据用作测试。采用sklearn库中classification_report方法打印算法的查准率p，查全率r和f1-分数（综合考虑p和r的因子） 123456789trainingProp = 0.67trainLen = int(len(X)*trainingProp)trainIndices = random.sample(range(len(X)),trainLen)trainingX = np.array([X[i,:] for i in range(len(X)) if i in trainIndices])testX = np.array([X[i,:] for i in range(len(X)) if i not in trainIndices])trainingy = np.array([y[i] for i in range(len(y)) if i in trainIndices])testy = np.array([y[i] for i in range(len(y)) if i not in trainIndices])print("总样本数：%d\n训练样本数:%d,%d\n测试样本数%d,%d"%(len(X),len(trainingX),len(trainingy),len(testX),len(testy))) 123总样本数：1593训练样本数:1067,1067测试样本数526,526 1all_theta = one_vs_all(trainingX,trainingy,0.1,10) 123def accuracy(all_theta,testX,realy): predicty = predictOneVsAll(all_theta,testX) print(classification_report(realy,predicty)) 1accuracy(all_theta,testX,testy) 12345678910111213141516 precision recall f1-score support 0 0.97 0.97 0.97 59 1 0.86 0.94 0.90 51 2 0.95 0.93 0.94 57 3 0.98 0.91 0.94 46 4 0.92 0.92 0.92 50 5 0.93 0.91 0.92 47 6 0.98 0.93 0.95 54 7 0.93 0.83 0.88 52 8 0.83 0.89 0.86 54 9 0.82 0.89 0.85 56 micro avg 0.91 0.91 0.91 526 macro avg 0.92 0.91 0.91 526weighted avg 0.92 0.91 0.91 526 从上面可以看出，逻辑回归算法的查准率和查全率均在90%以上，这说明这种算法对于分类问题表现还不错 采用神经网络BP算法识别采用三层神经网络，输入层包括256(16*16，不包括偏置1)个神经元，输出层包括10个神经元，隐层有25个(不包括偏置1)，如下图所示 准备数据123# 特征矩阵在前面已经准备好y_another = y # 存储原来用单个数字表示的y，y = np.array(y_old) # y的每个行向量表示一个数字 下面两个函数分别实现将矩阵扁平化为向量和从向量中抽取矩阵的功能 1234567891011121314151617# 此处X已加偏置列inputLayerSize = len(X[0])-1hiddenLayerSize = 25outputLayerSize = 10def serialize(a,b): """ 展开参数 """ return np.r_[a.flatten(),b.flatten()]def deserialize(theta): """ 从向量中提取theta1和theta2矩阵 """ t1 = theta[:(inputLayerSize+1)*hiddenLayerSize].reshape(hiddenLayerSize,inputLayerSize+1) t2 = theta[(inputLayerSize+1)*hiddenLayerSize:].reshape(outputLayerSize,hiddenLayerSize+1) return t1,t2 前向反馈在已知theta的情况下，通过前向反馈获得预测的各种分类可能性的向量 123456789101112131415161718192021def sigmoid(z): return 1/(1+np.exp(-z))def feed_forward(theta,X): """ theta为训练好的序列化的theta参数 inputLayerSize为输入层size,s1 hiddenLayerSize为隐层size,s2 outputLayerSize为输出层size,s3 X为特征矩阵，m*(s1+1) """ # t1, s2*(s1+1) # t2, s3*(s2+1) t1,t2 = deserialize(theta) a1 = X z2 = a1 @ t1.T # m*s2 a2 = np.insert(sigmoid(z2),0,1,axis = 1) #m*(s2+1) z3 = a2 @ t2.T # m*s3 a3 = sigmoid(z3) # m*s3 return a1,z2,a2,z3,a3 代价函数及其正则化1234def cost(theta,X,y): h = feed_forward(theta,X)[4] itemMat = -y*np.log(h)-(1-y)*np.log(1-h) return np.sum(itemMat)/len(X) 1234def regularized_cost(theta,X,y,lamb=1): t1,t2 = deserialize(theta) reg = np.sum(t1[:,1:]**2)+np.sum(t2[:,1:]**2) # 正则项 return lamb/(2*len(X))*reg + cost(theta,X,y) 12def sigmoidGrad(z): return sigmoid(z)*(1-sigmoid(z)) 神经网络梯度函数及其正则化Backpropagation反向传播 1234567891011121314def costGradient(theta,X,y): """ unregularized gradient 返回，所有theta的梯度 """ t1,t2 = deserialize(theta) a1,z2,a2,z3,a3 = feed_forward(theta,X) d3 = a3-y # m*s3 # theta2的第一列数据不予考虑 d2 = d3 @ t2[:,1:] * sigmoidGrad(z2) # m*(s2+1) D2 = d3.T@a2 # s3*(s2+1) D1 = d2.T@a1 # s2*(s1+1) return 1/len(X)*serialize(D1,D2) 1234567891011121314def regularizedGrad(theta,X,y,l=1): """ 正则化的梯度 返回，所有theta的梯度 """ # D1 and t1, s2*(s1+1);D2 and t2, s3*(s2+1) D1,D2 = deserialize(costGradient(theta,X,y)) t1,t2 = deserialize(theta) t1[:,0] = 0 t2[:,0] = 0 reg_D1 = D1 + (l / len(X)) * t1 reg_D2 = D2 + (l / len(X)) * t2 return serialize(D1,D2) 梯度检测因为反向传播算法代价函数和梯度函数代码编写过程中可能存在bug，故使用数值计算梯度与反向传播算法计算的梯度进行比较，以验证反向传播算法代价函数和梯度函数代码的正确性。不过这个函数运行起来超级慢，这里只贴代码，不展示运行结果了。 12345678910111213141516def gradientCheck(theta,X,y,e): numericGrad = [] for i in range(len(theta)): plus = theta.copy() minus = theta.copy() plus[i] += e minus[i] += e grad_i = (regularized_cost(plus,X,y)-regularized_cost(minus,X,y))/(2*e) numericGrad.append(grad_i) numericGrad = np.array(numericGrad) analyticGrad = regularizedGrad(theta, X, y) diff = np.linalg.norm(numericGrad - analyticGrad) / np.linalg.norm(numericGrad + analyticGrad) print('If your backpropagation implementation is correct,\nthe relative difference will \ be smaller than 10e-9 (assume epsilon=0.0001).\nRelative Difference: &#123;&#125;\n'.format(diff)) 1initTheta = randomInit((inputLayerSize+1)*hiddenLayerSize+(hiddenLayerSize+1)*outputLayerSize) 1gradientCheck(initTheta,X,y,0.0001) 测试算法12345def randomInit(size): """ 随机初始化size尺寸的矩阵 """ return np.random.uniform(-0.12, 0.12, size) 123456789def nn_training(X,y): init_theta = randomInit((inputLayerSize+1)*hiddenLayerSize+(hiddenLayerSize+1)*outputLayerSize) res = minimize(fun=regularized_cost, x0=init_theta, args=(X,y), method='TNC', jac=regularizedGrad, options=&#123;"maxiter":500&#125;) return res 123trainingy = np.array([y[i] for i in range(len(y)) if i in trainIndices])res = nn_training(trainingX,trainingy)res 12345678910 fun: 0.9114611628633325 jac: array([ 2.96364632e-03, -1.62797300e-04, 2.89863853e-04, ..., 9.59179838e-04, 1.10862199e-06, -4.78441900e-03])message: &apos;Converged (|f_n-f_(n-1)| ~= 0)&apos; nfev: 163 nit: 11 status: 1success: True x: array([ 0. , 0.44110449, 0.17106004, ..., -0.34636188, 0.6146963 , -0.88931194]) 12345from sklearn.metrics import classification_reportdef accuracyBP(theta,X,y): h = feed_forward(res.x,X)[4] y_pred = np.argmax(h,axis=1) print(classification_report(y,y_pred)) 12testy = np.array([y_another[i] for i in range(len(y_another)) if i not in trainIndices])accuracyBP(res.x,testX,testy) 12345678910111213141516 precision recall f1-score support 0 0.93 0.98 0.95 53 1 0.89 0.83 0.86 58 2 0.96 0.90 0.93 50 3 0.84 0.88 0.86 52 4 0.95 0.85 0.90 48 5 0.93 0.90 0.91 48 6 0.93 0.95 0.94 58 7 0.98 0.89 0.93 54 8 0.74 0.96 0.83 52 9 0.86 0.79 0.82 53 micro avg 0.89 0.89 0.89 526 macro avg 0.90 0.89 0.89 526weighted avg 0.90 0.89 0.89 526 从上面可以看出,查准率约为0.9，查全率约为0.89，比逻辑回归算法稍有不如。但是实际上神经网络的可调性很强，适用范围也更大。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>逻辑回归</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k近邻算法实战]]></title>
    <url>%2F2018%2F12%2F08%2Fk-nearest-neighbors%2F</url>
    <content type="text"><![CDATA[k-近邻算法概述k-近邻算法的工作原理是： 存在一个样本数据集，也即训练集，其中的每个样本数据对存在一个对应标签，也即样本的分类。当输入没有标签的新样本后，我们通过将新数据的每个特征与样本数据集中对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。通常做法是提取特征向量最相近的前k个数据，取其中出现次数最多的分类，作为输入新样本的分类标签 用一个简单的例子来描述一下k-近邻算法的一般流程 准备用pyhton导入数据创建一个名为kNN的Python模块，在kNN.py中增加下列代码： 123456789from numpy import *import operatordef createDataSet(): """ 以四个点(1,1.1),(1,1),(0,0),(0,0.1)为例，其标签分分别是'A','B','C','D' """ group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]]) labels = ['A','A','B','B'] return group,labels 123group,labels = createDataSet()print(group)print(labels) [[1. 1.1] [1. 1. ] [0. 0. ] [0. 0.1]] [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;] 实施kNN算法kNN算法的伪代码如下: 计算已知类别数据集中的点与当前点之间的距离 按照距离递增次序排序 选取与当前点距离最小的k个点 确定当前k个点所在类别的出现频率 返回前k个点出现频率最高的类别作为当前点的预测分类 pyhton函数classify0如下所示： 123456789101112131415161718def classify0(inX,dataSet,labels,k): """ 输入参数为inX（待分类的数据特征向量），dataSet(训练数据多个特征向量构成的矩阵)，labels(训练数据特征向量对应的标签向量)，k（k值） 返回为inX的预估的标签 """ dataSetSize = dataSet.shape[0] diffMat = tile(inX,(dataSetSize,1))-dataSet # 新数据与训练数据作差 sqDiffMat = diffMat**2 sqDistances = sqDiffMat.sum(axis = 1) # 对差平方矩阵进行每行求和 distances = sqDistances**0.5 # 开平方根，为新数据向量与训练数据向量的距离 sortedDistanceIndices = distances.argsort() #按照距离从小到大排序，返回下标向量 classCount = &#123;&#125; for i in range(k): # 统计前k个点对应的标签，插入classCount字典中 voteIlabel = labels[sortedDistanceIndices[i]] classCount[voteIlabel] = classCount.get(voteIlabel,0)+1 sortedClassCount = sorted(classCount.items(),key = operator.itemgetter(1),reverse=True) # 利用字典中的value值进行从大到小的排序 return sortedClassCount[0][0] 上述程序使用欧式距离公式，计算两个向量$xA$和$xB$之间的距离: d=\sqrt {(xA_0-xB_0)^2+(xA_1-xB_1)^2}对数据点[0,0]进行分类，它实际上属于B类（画个图就知道了）。运行下列代码，确实是B 1classify0([0,0],group,labels,3) &#39;B&#39; 使用k近邻算法改进约会网站的配对效果海伦将约会网站上的约会对象分为三种人， 不喜欢的人 魅力一般的人 极具魅力的人我们需要根据已有数据采用k近邻算法，来帮助海伦将约会对象划分到确切的分类中。大致步骤 收集数据：获得海伦给定的对象数据特征和分类标签 准备数据：使用pyhton解析文本文件 分析数据：使用matplotlib画二维扩散图 训练算法：k近邻算法用不着训练数据 测试算法：使用海伦提供的部分数据作为测试样本 使用算法：产生简单的命令行程序，使得海伦通过输入一些数据来判断对方是否为自己喜欢的类型准备数据下载海伦提供的数据。查看数据，可以看出，每个样本数据占据一行，每一行有四列，前三列是3种特征： 每年获得的飞行常客里程数 玩视频游戏所消耗的时间百分比 每周消耗的冰淇淋公升数第四列是海伦给这个样本定义的标签，有’largeDoses’,’smallDoses’,’didntLike’ 1!wget https://github.com/pbharrin/machinelearninginaction/raw/master/Ch02/datingTestSet.txt 1!cat datingTestSet.txt 在kNN.py中创建名为file2matrix的函数，以此来处理输入格式问题。file2matrix输入文件名，返回特征数据矩阵和标签向量 123456789101112131415161718def file2matrix(filename): """ 根据文件名读取数据，返回特征数据矩阵和标签向量 """ dic = &#123;'didntLike':1,'smallDoses':2,'largeDoses':3&#125; fr = open(filename) arrayOLines = fr.readlines() # 以列表形式存储文本数据，列表元素为字符串 numberOfLines = len(arrayOLines) returnMat = np.zeros((numberOfLines,3)) # 返回的特征数据矩阵 classLabelVector = [] # 返回的标签向量 index = 0 for line in arrayOLines: line = line.strip() # remove leading and trailing whitespace listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(dic[listFromLine[-1]]) index+=1 return returnMat,classLabelVector 在执行上述代码后，可调用file2matrix函数将文件’datingTestSet.txt’导入到内存中 1datingDataMat,datingLabels = file2matrix('datingTestSet.txt') 分析数据利用Matplotlib制作原始数据的散点图 1234567891011121314151617181920import matplotlibimport matplotlib.pyplot as pltfig = plt.figure(figsize=(10,15))ax1 = fig.add_subplot(311) # 设定figure里面有多少个子图和子图位置ax1.scatter(datingDataMat[:,0],datingDataMat[:,1],15.0*np.array(datingLabels),15.0*np.array(datingLabels))ax1.set_title("Charisma scattering plot")ax1.set_xlabel("Flying milages")ax1.set_ylabel("Time percentage of playing games")ax2 = fig.add_subplot(312) # 设定figure里面有多少个子图和子图位置ax2.scatter(datingDataMat[:,0],datingDataMat[:,2],15.0*np.array(datingLabels),15.0*np.array(datingLabels))ax2.set_title("Charisma scattering plot")ax2.set_xlabel("Flying milages")ax2.set_ylabel("Weekly consumption of ice cream/liter")ax3 = fig.add_subplot(313) # 设定figure里面有多少个子图和子图位置ax3.scatter(datingDataMat[:,1],datingDataMat[:,2],15.0*np.array(datingLabels),15.0*np.array(datingLabels))ax3.set_title('Charisma scattering plot')ax3.set_xlabel('Time percentage of playing games')ax3.set_ylabel('Weekly consumption of ice cream/liter')plt.show() 准备数据：归一化数值显然，因为飞行常客里程数远远大于玩视频游戏时间占比与每周消费冰淇淋公升数，而海伦认为这三种特征是同样重要的，所以需要对特征树进行归一化处理。通过下面公式将任意范围的特征值转为0到1区间的值： newValue = (oldValue-min)/(max-min)下面是归一化特征值的代码 123456789def autoNorm(dataSet): minVals = dataSet.min(0) # 对每一列求最小值，得到一个有三个元素的向量 maxVals = dataSet.max(0) # 对每一列求最大值，得到一个有三个元素的向量 ranges = maxVals-minVals # 获得每一列最大值与最小值的差值 normDataSet = np.zeros(np.shape(dataSet)) m = dataSet.shape[0] #数据集有多少行 normDataSet = dataSet - np.tile(minVals,(m,1)) normDataSet = normDataSet/tile(ranges,(m,1)) return normDataSet,ranges,minVals 1normMat,ranges,minVals = autoNorm(datingDataMat) 123print(normMat[0:5])print(ranges)print(minVals) [[0.44832535 0.39805139 0.56233353] [0.15873259 0.34195467 0.98724416] [0.28542943 0.06892523 0.47449629] [0.82320073 0.62848007 0.25248929] [0.42010233 0.07982027 0.0785783 ]] [9.1273000e+04 2.0919349e+01 1.6943610e+00] [0. 0. 0.001156] 测试算法为了测试分类器效果，我们定义了一个datingClassTest函数，该函数是自包含的，选用海伦提供数据的前10%作为测试数据，后90%作为训练集数据。代码如下： 1234567891011121314def datingClassTest(): hoRatio = 0.10 datingDataMat,datingDataLabels = file2matrix('datingTestSet.txt') normMat,ranges,minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errCoount = 0 # 预测错误向量个数 for i in range(numTestVecs): # 遍历所有的测试向量 classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) # print("the classifier came back with:%d, the real answer is:%d"%(classifierResult,datingLabels[i])) if classifierResult!=datingLabels[i]: errCoount += 1 print("the total error rate is: %f"%(errCoount/float(numTestVecs))) 1datingClassTest() the total error rate is: 0.050000 使用算法：构建完整系统设计一个函数，能够询问约会对象的特征数据，然后给出预估的分类 12345678910def classifyPerson(): resultList = ['not at all','in small doses','in large doses'] percentageTats = float(input("percentage of time spent in playing video games?")) ffMiles = float(input("frequent flier miles earned each year?")) icecream = float(input("liters of ice cream cosumed each week?")) datingDataMat,datingLabels = file2matrix('datingTestSet.txt') normMat,ranges,minVals = autoNorm(datingDataMat) inArr = array([ffMiles,percentageTats,icecream]) classifierResult = classify0((inArr-minVals)/ranges,normMat,datingLabels,3) print("You will propably like this person %s"%resultList[int(classifierResult)-1]) 1classifyPerson() percentage of time spent in playing video games?10 frequent flier miles earned each year?10000 liters of ice cream cosumed each week?0.5 You will propably like this person in small doses 1以上让人觉得十分容易看懂，事实上k-近邻算法本身就是一个非常简单的算法。接下来看看，如何在二进制存储的图像数据上使用kNN。 手写识别数字需要识别的数字已经通过软件转成宽高32x32的黑白图像，这里直接使用图像的文本格式 准备数据:将图像转化为测试向量执行以下指令，获取并解压数据文件，文件夹中包含两个文件夹trainingDigits和testDigits，分别对应训练数据和测试数据 12!wget https://github.com/pbharrin/machinelearninginaction/raw/master/Ch02/digits.zip!unzip digits.zip 首先编写一个函数根据手写数字的文件名读入数据将32x32的矩阵转成一个1x1024的向量 123456789101112def img2vector(filename): """ 参数为一个图像文本文件的名字 返回1x1024的向量 """ returnVect = zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVect 1print(img2vector("testDigits/0_0.txt")) [[0. 0. 0. ... 0. 0. 0.]] 测试算法：使用k近邻算法实现手写数字的识别下面实现一个函数classifyDigitTest，输入数字图像转化来的1x1024向量， 123456789101112131415161718192021222324252627282930from os import listdirdef classifyDigitTest(): # 首先列出trainingDigits下的所有文件名，文件数为m # 根据trainingDigits下的所有文件构造m*1024的特征矩阵和，m*1的标签向量 # 列出testDigits下的所有文件名，文件数为testN # 对testDigits文件夹下的进行循环判断，以获得算法的手写数字识别错误率 # 调用classify0获得digitVect的结果标签 # 有文件名名可获得digitVect的真实标签，对比，若不等errorCount++ # 获得手写识别错误率 trainingFiles = listdir('trainingDigits') m = len(trainingFiles) trainingDataMat = np.zeros((m,1024)) trainingLabelsVect = [] for i in range(m): trainingFileName = trainingFiles[i] realLabel = int(trainingFileName.split('.')[0].split('_')[0]) trainingDataMat[i,:] = img2vector('trainingDigits/'+trainingFileName) # 构造特征矩阵第i行 trainingLabelsVect.append(realLabel) testFiles = listdir('testDigits') testN = len(testFiles) errCount = 0.0 for i in range(testN): testFileName = testFiles[i] testDataVect = img2vector('testDigits/'+testFileName) # 获得测试文件的特征向量 testRealLabel = int(testFileName.split('.')[0].split('_')[0]) # 获得测试文件名中的数据标签 testLabel = classify0(testDataVect,trainingDataMat,trainingLabelsVect,3) # 采用k近邻算法估计测试文件的标签 # print("test data file:%s,predicted label:%s,real label:%s"%(testFileName,testLabel,testRealLabel)) if testLabel!=testRealLabel: errCount+=1 print("model accuracy:%.5f"%(1-errCount/testN)) 12start = tiemclassifyDigitTest() model accuracy:0.99 实际上，使用这个算法效率太低，而且训练集数据越大，耗时越多，我们需要为每个测试向量做m次距离计算(m是训练集样本数)，每个距离计算包括1024个维度的浮点数计算。k近邻算法没有训练出一个模型出来，而是直接将输入与所有的训练数据一一比较。]]></content>
      <categories>
        <category>机器学习实战</category>
      </categories>
      <tags>
        <tag>k近邻算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python传递参数究竟是值传递还是引用传递]]></title>
    <url>%2F2018%2F12%2F08%2Fpython-passParam%2F</url>
    <content type="text"><![CDATA[首先还是应该科普下函数参数传递机制，传值和传引用是什么意思？ 函数参数传递机制问题在本质上是调用函数（过程）和被调用函数（过程）在调用发生时进行通信的方法问题。基本的参数传递机制有两种：值传递和引用传递。 值传递（passl-by-value）过程中，被调函数的形式参数作为被调函数的局部变量处理，即在堆栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。 引用传递(pass-by-reference)过程中，被调函数的形式参数虽然也作为局部变量在堆栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过堆栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。 那么,python究竟是怎样的呢 123456789101112131415161718192021222324from ctypes import *import os.path import sysdef test(c): print("test before ") print(id(c)) c+=2 print("test after") print(id(c)) return cdef printIt(t): for i in range(len(t)): print(t[i])if __name__=="__main__": a=2 print("main before invoke test") print(id(a)) n=test(a) print("main afterf invoke test") print(a) print(id(a)) 12345main before invoke testtest before test after +main afterf invoke test39601564 从上可以看出，传参数进去时，传得是引用，因为参数地址没变。但是对传入参数赋值后，其地址就发生了变化。基于这个例子画了个图表示 那么python传递参数传得真是引用，然后传参的值在被调函数内被修改也不影响主调函数的实参变量的值？有传入对象可变与不可变的说法，对于可变对象，在被调函数内修改传参会影响主调函数的实参变量，对于不可变对象修改传参则不会改变主调函数实参的值，因为修改不可变对象实际上是另开辟内存重新赋值并让传参变量指向该内存。看下面例子 123456789101112131415161718192021222324from ctypes import *import os.path import sysdef test(list2): print("test before ") print(id(list2)) list2[1]=30 print("test after +") print(id(list2)) return list2def printIt(t): for i in range(len(t)): print(t[i])if __name__=="__main__": list1=["loleina",25,'female'] print("main before invoke test") print(id(list1)) list3=test(list1) print("main afterf invoke test") print(list1) print(id(list1)) 123456789main before invoke test4485568072test before 4485568072test after +4485568072main afterf invoke test[&apos;loleina&apos;, 30, &apos;female&apos;]4485568072 结论：python不允许程序员选择采用传值还是传引用。Python参数传递采用的肯定是“传对象引用”的方式。这种方式相当于传值和传引用的一种综合。如果函数收到的是一个可变对象（比如字典或者列表）的引用，就能修改对象的原始值－－相当于通过“传引用”来传递对象。如果函数收到的是一个不可变对象（比如数字、字符或者元组）的引用，就不能直接修改原始对象－－相当于通过“传值’来传递对象。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python在命令行下查看模块，函数的用法]]></title>
    <url>%2F2018%2F11%2F29%2Fpython-help%2F</url>
    <content type="text"><![CDATA[python的一个优势是有着大量自带和在线的模块(module)资源，可以提供丰富的功能，在使用这些模块的时候，如果每次都去网站找在线文档会过于耗费时间，结果也不一定准确。因此这里介绍下python自带的查看帮助功能，可以在编程时不中断地迅速找到所需模块和函数的使用方法。 通用帮助函数help()在python命令行中键入help(),可以看到：1234567891011121314151617&gt;&gt;&gt; help()Welcome to Python 3.5&apos;s help utility!If this is your first time using Python, you should definitely check outthe tutorial on the Internet at http://docs.python.org/3.5/tutorial/.Enter the name of any module, keyword, or topic to get help on writingPython programs and using Python modules. To quit this help utility andreturn to the interpreter, just type &quot;quit&quot;.To get a list of available modules, keywords, symbols, or topics, type&quot;modules&quot;, &quot;keywords&quot;, &quot;symbols&quot;, or &quot;topics&quot;. Each module also comeswith a one-line summary of what it does; to list the modules whose nameor summary contain a given string such as &quot;spam&quot;, type &quot;modules spam&quot;.help&gt; 进入help帮助文档界面，根据屏幕提示可以继续键入相应关键词进行查询，继续键入modules可以列出当前所有安装的模块：12345678910help&gt; modulesPlease wait a moment while I gather a list of all available modules...AutoComplete _pyio filecmp pyscreezeAutoCompleteWindow _random fileinput pytweening...... Enter any module name to get more help. Or, type &quot;modules spam&quot; to searchfor modules whose name or summary contain the string &quot;spam&quot;. 可以继续键入相应的模块名称得到该模块的帮助信息。这是python的通用的查询帮助，可以查到几乎所有的帮助文档，但我们很多时候不需要这样层级式地向下查询，接下来会介绍如何直接查询特定的模块和函数帮助信息。 模块帮助查询查看.py结尾的普通模块help(module_name)例如要查询math模块的使用方法，可以如下操作：12345678910111213141516171819&gt;&gt;&gt; import math&gt;&gt;&gt; help(math)Help on built-in module math:NAME mathDESCRIPTION This module is always available. It provides access to the mathematical functions defined by the C standard.FUNCTIONS acos(...) acos(x) Return the arc cosine (measured in radians) of x....&gt;&gt;&gt; 使用help(module_name)时首先需要import该模块，有些教程中不进行导入而在模块名中加入引号help(‘module_name’)，这种方法可能会带来问题，大家可以用math模块测试，建议使用先导入再使用help()函数查询。 查看内建模块sys.bultin_modulenames1234&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.builtin_module_names(&apos;_ast&apos;, &apos;_bisect&apos;, &apos;_codecs&apos;, &apos;_codecs_cn&apos;, &apos;_codecs_hk&apos;, ... &apos;zlib&apos;)&gt;&gt;&gt; 需要导入sys模块。这里列举的一般是自带的使用C/C++编译链接的模块 查询函数信息查看模块下所有函数dir(module_name)如我们需要列举出math模块下所有的函数名称123&gt;&gt;&gt; dir(math)[&apos;__doc__&apos;, &apos;__loader__&apos;, &apos;__name__&apos;,...]&gt;&gt;&gt; 同样需要首先导入该模块 查看模块下特定函数信息help(module_name.func_name)如查看math下的sin()函数 123456789&gt;&gt;&gt; help(math.sin)Help on built-in function sin in module math:sin(...) sin(x) Return the sine of x (measured in radians).&gt;&gt;&gt; 查看函数信息的另一种方法print(func_name.doc)如查看内建函数print用法。既可以用来查看内建函数，也可以查看模块函数信息。 123456&gt;&gt;&gt; print(print.__doc__)print(value, ..., sep=&apos; &apos;, end=&apos;\n&apos;, file=sys.stdout, flush=False)Prints the values to a stream, or to sys.stdout by default....&gt;&gt;&gt; doc前后是两个短下划线，在python中会合并为长下划线python中的help()类似unix中的man指令，熟悉后会对我们的编程带来很大帮助]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的lambda表达式]]></title>
    <url>%2F2018%2F11%2F29%2Fpython-lambda%2F</url>
    <content type="text"><![CDATA[这里，我们通过阅读各方资料，总结了关于Python中的lambda的“一个语法，三个特性，四个用法”。 一个语法在Python中，lambda的语法是唯一的。其形式如下： lambda argument_list: expression 其中，lambda是Python预留的关键字，argument_list和expression由用户自定义。具体介绍如下。这里的argument_list是参数列表。它的结构与Python中函数(function)的参数列表是一样的。具体来说，argument_list可以有非常多的形式。例如： a, b a=1, b=2 *args **kwargs a, b=1, *args 空 …… 这里的expression是一个关于参数的表达式。表达式中出现的参数需要在argument_list中有定义，并且表达式只能是单行的。以下都是合法的表达式： 1 None a + b sum(a) 1 if a &gt;10 else 0 …… 这里的lambda argument_list: expression表示的是一个函数。这个函数叫做lambda函数。 三个特性lambda函数有如下特性： lambda函数是匿名的：所谓匿名函数，通俗地说就是没有名字的函数。lambda函数没有名字。 lambda函数有输入和输出：输入是传入到参数列表argument_list的值，输出是根据表达式expression计算得到的值。 lambda函数一般功能简单：单行expression决定了lambda函数不可能完成复杂的逻辑，只能完成非常简单的功能。由于其实现的功能一目了然，甚至不需要专门的名字来说明。 下面是一些lambda函数示例：1234567lambda x, y: x*y；函数输入是x和y，输出是它们的积x*ylambda:None；函数没有输入参数，输出是Nonelambda *args: sum(args); 输入是任意个数的参数，输出是它们的和(隐性要求是输入参数必须能够进行加法运算)lambda **kwargs: 1；输入是任意键值对参数，输出是1 四个用法由于lambda语法是固定的，其本质上只有一种用法，那就是定义一个lambda函数。在实际中，根据这个lambda函数应用场景的不同，可以将lambda函数的用法扩展为以下几种： 将lambda函数赋值给一个变量，通过这个变量间接调用该lambda函数。例如，执行语句add=lambda x, y: x+y，定义了加法函数lambda x, y: x+y，并将其赋值给变量add，这样变量add便成为具有加法功能的函数。例如，执行add(1,2)，输出为3。 将lambda函数赋值给其他函数，从而将其他函数用该lambda函数替换。例如，为了把标准库time中的函数sleep的功能屏蔽(Mock)，我们可以在程序初始化时调用：time.sleep=lambda x:None。这样，在后续代码中调用time库的sleep函数将不会执行原有的功能。例如，执行time.sleep(3)时，程序不会休眠3秒钟，而是什么都不做。 将lambda函数作为其他函数的返回值，返回给调用者。函数的返回值也可以是函数。例如return lambda x, y: x+y返回一个加法函数。这时，lambda函数实际上是定义在某个函数内部的函数，称之为嵌套函数，或者内部函数。对应的，将包含嵌套函数的函数称之为外部函数。内部函数能够访问外部函数的局部变量，这个特性是闭包(Closure)编程的基础，在这里我们不展开。 将lambda函数作为参数传递给其他函数。 部分Python内置函数接收函数作为参数。典型的此类内置函数有这些。filter函数。此时lambda函数用于指定过滤列表元素的条件。例如filter(lambda x: x % 3 == 0, [1, 2, 3])指定将列表[1,2,3]中能够被3整除的元素过滤出来，其结果是[3]。 sorted函数。此时lambda函数用于指定对列表中所有元素进行排序的准则。例如sorted([1, 2, 3, 4, 5, 6, 7, 8, 9], key=lambda x: abs(5-x))将列表[1, 2, 3, 4, 5, 6, 7, 8, 9]按照元素与5距离从小到大进行排序，其结果是[5, 4, 6, 3, 7, 2, 8, 1, 9]。 map函数。此时lambda函数用于指定对列表中每一个元素的共同操作。例如map(lambda x: x+1, [1, 2,3])将列表[1, 2, 3]中的元素分别加1，其结果[2, 3, 4]。 reduce函数。此时lambda函数用于指定列表中两两相邻元素的结合条件。例如reduce(lambda a, b: &#39;{}, {}&#39;.format(a, b), [1, 2, 3, 4, 5, 6, 7, 8, 9])将列表 [1, 2, 3, 4, 5, 6, 7, 8, 9]中的元素从左往右两两以逗号分隔的字符的形式依次结合起来，其结果是’1, 2, 3, 4, 5, 6, 7, 8, 9’。 另外，部分Python库函数也接收函数作为参数，例如gevent的spawn函数。此时，lambda函数也能够作为参数传入。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>lambda表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数行列式总结]]></title>
    <url>%2F2018%2F11%2F28%2Fpost%2F</url>
    <content type="text"><![CDATA[最近入坑机器学习，线性代数的知识用到很多，所以就回顾了一下，发现也是挺有意思的。行列式对于方阵给出一个特殊的定义值，与方阵的秩和方阵对应的齐次线性方程有没有唯一非零解有着很大的关系。 定义当$n\geq2$时，$n\times n$矩阵$A=\begin{bmatrix}a_{ij}\end{bmatrix}$的行列式是形如$\pm a_{ij} detA_{ij}$的n个项的和，其中加减号交替出现，这里的$a_{11},a_{12},a_{13}…a_{1n}$来自于第一行，即 \begin{aligned} detA&=a_{11}\cdot detA_{11}-a_{12}\cdot detA_{12}+\cdots +(-1)^{1+n}a_{1n}detA_{1n}\\ &=\sum_{j=1}^{n}(-1)^{1+j}a_{1j}detA_{1j}\\ \end{aligned}当然这是针对第一行展开的，从中可以看出$n\times n$阶的行列式被展开成若干个$(n-1)\times(n-1)$阶的行列式。$detA_{1j}$称为代数余子式，是划掉行列式A的第$1$行第$j$列后余下行列式的值，也可以对第$i$行进行展开，$1$替换成$i$即可。同样地，也可以对某一列进行展开。 定理 若$A$为三角阵，则$detA$为主对角线上元素乘积。这里的三角阵仅考虑行列式主对角线上边或下边元素全为零的情况。 行变换性质。令$A$是一个方阵，则有 若$A$的一行加上另一行的倍数得到$B$，则$detA=detB$ 若$A$的两行互换得到$B$，则$detA=-detB$ 若$A$的某行乘以k得到$B$，则$detA=kdetB$ $A$中有任何一行为0，则$detA=0$ 实际上，列变换也具有这些性质通过行列式的行变换，可以将一个复杂的行列式化简成三角型，如果化成阶梯型后不是三角型，则说明行列式值为0。 当且仅当$detA\neq 0$时方阵$A$是可逆的 若$A$为一个$n\times n$矩阵，则$detA^T=detA$ 乘法性质。$det(AB)=(detA)(detB)$ 线性方程组的解集问题 齐次线性方程组的解集 首先说一下什么是齐次线性方程组。就是方程组可以写成$A\textbf x=\textbf 0$，$A$是系数矩阵($m\times n$阶)，$\textbf x$是未知数n维列向量。显然这个方程必然有零解($x_1=0,x_2=0\cdots x_n=0$)。 有没有非零解，取决于方程组有没有自由变量。如果系数矩阵的行秩$\geq$未知数个数n（事实上只能$=$，因为任何矩阵行秩$=$列秩$=$秩），也就是线性无关的有效方程的个数$=$未知数个数n，方程只有零解。如果小于，则$n-$行秩就是方程组自有变量的个数。如果$x_1,x_2$是自有变量的话，那么通解为$\textbf x=x_1\textbf u+x_2\textbf v$，$\textbf u,\textbf v$为由方程解出来的列向量。 非齐次线性方程的解集 非齐次线性方程组是为$A\textbf x=\textbf b$的形式，$\textbf b$为n维非$0$列向量。它的解有三种情况，由增广矩阵$\begin{bmatrix}A&amp;\textbf b\end{bmatrix}$与系数矩阵$A$的秩的关系决定。若$r_{系数矩阵}=r_{增广矩阵}=n$，则有唯一解；若$r_{系数矩阵}=r_{增广矩阵}&lt;n$,则有无穷解。若$r_{系数矩阵}\neq r_{增广矩阵}$，则无解。（其中n为未知数的个数）。$r_{系数矩阵}\neq r_{增广矩阵}$反映了给定的线性方程组有互相矛盾的情况，其差为矛盾线性方程的个数；若$r_{系数矩阵}=r_{增广矩阵}&lt;n$，则说明给定的线性无关方程的个数小于未知变量个数，自然会有无穷多个解。 如果非齐次线性方程组有解，且p是一个特解，则$A\textbf x=\textbf b$的解集所有形如$\textbf w=\textbf p+\textbf v_{h}$，其中$\textbf v_{h}$是齐次线性方程组$A\textbf x=\textbf 0$的通解。克拉默法则克拉默法则是用来求解系数矩阵为方阵且可逆的非齐次线性方程组的唯一解的定理。首先定义一个替换矩阵，对于任意$n\times n$矩阵$A$和任意$\mathbb{R^{n}}$中向量$\textbf b$，令${A_i(b)}$表示$A$中第i列由向量$b$替换得到的矩阵。即 {A_i(b)=}\begin{bmatrix} {a_1}& \cdots &{b} &\cdots &{a_n} \end{bmatrix}接下来正式说明一下什么是克拉默法则设$ A$是一个可逆的$n\times n$矩阵，对任意$\mathbb{R^{n}}$中向量$ b$，方程${Ax=b}$的唯一解可由下式给出， {x_i=\frac{detA_ib}{detA},i=1,2\cdots n}$detA\neq 0$再加上$n\times n$方阵的条件可以说明$r_{系数矩阵}=r_{增广矩阵}=n$]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>行列式</tag>
      </tags>
  </entry>
</search>
