<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[手写数字识别]]></title>
    <url>%2F2018%2F12%2F10%2F%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[逻辑回归与神经网络实现手写数字识别本作业是采用Logistic回归和神经网络两种机器学习算法来识别0~9的手写数字。数据集来源于uci,编程语言为python,文档编写用jupyter notebook.通过wget命令下载数据 1!wget https://archive.ics.uci.edu/ml/machine-learning-databases/semeion/semeion.data 采用logistic算法识别手写数字逻辑回归，是一种被广泛用于分类的算法，通过对线性回归外套一个sigmoid函数使之适用于分类情况。采用一对多策略，先训练出K个二分类器（K为分类总数），当输入新样本时，选择使假设函数值最大的那个分类器对应的分类。首先导入机器学习常用的库，如numpy等。 12345678%matplotlib inlineimport numpy as npfrom numpy import *import matplotlib.pyplot as pltimport pandas as pdimport randomimport scipy.misc #Used to show matrix as an imageimport matplotlib.cm as cm #Used to display images in a specific colormap 导入并处理数据从文件导入数据，分析数据可知，数据共有1593行，每行有266个数字（0或1），其中前256个是16*16大小的手写数字图片的文本形式，后面10个数字分别表示0-9的识别结果。 1234fr = open('semeion.data')data = fr.readlines()data = [line.strip().split() for line in data]print("共有%d行数据,每行%d个数字"%(len(data),len(data[0]))) 1共有1593行数据,每行266个数字 将X,y从列表格式转成np.ndarray格式 12345678for i in range(len(data)): for j in range(len(data[0])): data[i][j] = int(float(data[i][j]))X = [example[0:256] for example in data]y_old = [example[256:] for example in data]y = [line.index(1) for line in y_old]X = np.array(X)y = np.array(y) 可视化数据123456789101112131415161718192021222324252627282930def getDatumImg(row,width,height): """ Function that is handed a single np array with shape 1x400, crates an image object from it, and returns it """ square = row[:].reshape(width,height) return square def displayData(width,height,indices_to_display = None): """ Function that picks 100 random rows from X, creates a 20x20 image from each, then stitches them together into a 10x10 grid of images, and shows it. """ nrows, ncols = 10, 10 if not indices_to_display: indices_to_display = random.sample(range(X.shape[0]), nrows*ncols) big_picture = np.zeros((height*nrows,width*ncols)) irow, icol = 0, 0 for idx in indices_to_display: if icol == ncols: irow += 1 icol = 0 iimg = getDatumImg(X[idx],width,height) big_picture[irow*height:irow*height+iimg.shape[0],icol*width:icol*width+iimg.shape[1]] = iimg icol += 1 fig = plt.figure(figsize=(6,6)) img = scipy.misc.toimage( big_picture ) plt.imshow(img,cmap = cm.Greys_r) 1displayData(16,16,list(range(100))) 训练算法：获得K*(n+1)的参数矩阵12# 添加全为1的第一列X = np.insert(X,0,values=np.ones(X.shape[0]),axis=1) # m*(n+1) 逻辑回归的代价函数如下图所示，其中第二项防止训练模型出现过拟合，也即经过正则化的代价函数逻辑回归代价函数对参数向量的梯度求解公式如下图所示，第二项也是为了防止过拟合的情况 1234567891011def sigmoid(z): return 1/(1+np.exp(-z))# 逻辑回归的假设函数def h(mytheta,myX): return sigmoid(np.dot(myX,mytheta)) # m一维向量# 逻辑回归的代价函数def computeCost(theta,X,y,lamb = 0): h_theta = h(theta,X) left_hand = np.mean(-y*np.log(h_theta)-(1-y)*np.log(1-h_theta)) right_hand = np.sum(np.square(theta[1:]))*lamb/(2*len(X)) return left_hand+right_hand 123456def costGradient(theta,X,y,lamb=0): #逻辑回归的梯度函数 first = (1/len(X))*X.T @ (h(theta,X)-y) # (n+1)一维向量 # (n+1)一维向量 reg = np.concatenate([np.array([0]),(lamb/len(X))*theta[1:]]) return first+reg 在代价函数及其梯度的求解方法确定后，就可以选择python第三方科学计算库scipy中的优化方法经过一定次数的迭代获得使代价函数最低的参数向量。当然也可以自己采用梯度下降法求解。 12345678910111213141516171819202122from scipy.optimize import minimizedef one_vs_all(X,y,lamb,K): """ 采用一对多策略利用逻辑回归分类 参数： X,特征矩阵，m*(n+1)，第一列为附加的0 y,真实分类向量，m一维向量 lamb，正则化用的lambda K,分类总数 返回： 训练好的theta向量,K*(n+1) """ all_theta = zeros((K,X.shape[1])) for i in range(K): init_theta = np.zeros(X.shape[1]) y_new = np.array([1 if i==num else 0 for num in y]) ret = minimize(fun=computeCost,x0=init_theta,args=(X,y_new,lamb), method='TNC',jac=costGradient,options=&#123;'maxiter':100,'disp':True&#125;) all_theta[i,:] = ret.x return all_theta 123456789101112def predictOneVsAll(all_theta,X): """ 估计手写数字样本数据X的识别结果 参数： all_theta,训练好的参数向量 X，待识别的样本数据 返回识别结果向量 """ # m*K，每一行向量代表该行对应样本取这个下标数字的可能性 h = sigmoid(X @ all_theta.T) h_argmax = np.argmax(h,axis=1) # 选取可能性最大的下标，表示样本取数字为该下标的可能性最大 return h_argmax 测试算法下面代码从样本数据集中随机抽取占比为0.67的数据作为训练数据集，剩余数据用作测试。采用sklearn库中classification_report方法打印算法的查准率p，查全率r和f1-分数（综合考虑p和r的因子） 123456789trainingProp = 0.67trainLen = int(len(X)*trainingProp)trainIndices = random.sample(range(len(X)),trainLen)trainingX = np.array([X[i,:] for i in range(len(X)) if i in trainIndices])testX = np.array([X[i,:] for i in range(len(X)) if i not in trainIndices])trainingy = np.array([y[i] for i in range(len(y)) if i in trainIndices])testy = np.array([y[i] for i in range(len(y)) if i not in trainIndices])print("总样本数：%d\n训练样本数:%d,%d\n测试样本数%d,%d"%(len(X),len(trainingX),len(trainingy),len(testX),len(testy))) 123总样本数：1593训练样本数:1067,1067测试样本数526,526 1all_theta = one_vs_all(trainingX,trainingy,0.1,10) 123def accuracy(all_theta,testX,realy): predicty = predictOneVsAll(all_theta,testX) print(classification_report(realy,predicty)) 1accuracy(all_theta,testX,testy) 12345678910111213141516 precision recall f1-score support 0 0.97 0.97 0.97 59 1 0.86 0.94 0.90 51 2 0.95 0.93 0.94 57 3 0.98 0.91 0.94 46 4 0.92 0.92 0.92 50 5 0.93 0.91 0.92 47 6 0.98 0.93 0.95 54 7 0.93 0.83 0.88 52 8 0.83 0.89 0.86 54 9 0.82 0.89 0.85 56 micro avg 0.91 0.91 0.91 526 macro avg 0.92 0.91 0.91 526weighted avg 0.92 0.91 0.91 526 从上面可以看出，逻辑回归算法的查准率和查全率均在90%以上，这说明这种算法对于分类问题表现还不错 采用神经网络BP算法识别采用三层神经网络，输入层包括256(16*16，不包括偏置1)个神经元，输出层包括10个神经元，隐层有25个(不包括偏置1)，如下图所示 准备数据123# 特征矩阵在前面已经准备好y_another = y # 存储原来用单个数字表示的y，y = np.array(y_old) # y的每个行向量表示一个数字 下面两个函数分别实现将矩阵扁平化为向量和从向量中抽取矩阵的功能 1234567891011121314151617# 此处X已加偏置列inputLayerSize = len(X[0])-1hiddenLayerSize = 25outputLayerSize = 10def serialize(a,b): """ 展开参数 """ return np.r_[a.flatten(),b.flatten()]def deserialize(theta): """ 从向量中提取theta1和theta2矩阵 """ t1 = theta[:(inputLayerSize+1)*hiddenLayerSize].reshape(hiddenLayerSize,inputLayerSize+1) t2 = theta[(inputLayerSize+1)*hiddenLayerSize:].reshape(outputLayerSize,hiddenLayerSize+1) return t1,t2 前向反馈在已知theta的情况下，通过前向反馈获得预测的各种分类可能性的向量 123456789101112131415161718192021def sigmoid(z): return 1/(1+np.exp(-z))def feed_forward(theta,X): """ theta为训练好的序列化的theta参数 inputLayerSize为输入层size,s1 hiddenLayerSize为隐层size,s2 outputLayerSize为输出层size,s3 X为特征矩阵，m*(s1+1) """ # t1, s2*(s1+1) # t2, s3*(s2+1) t1,t2 = deserialize(theta) a1 = X z2 = a1 @ t1.T # m*s2 a2 = np.insert(sigmoid(z2),0,1,axis = 1) #m*(s2+1) z3 = a2 @ t2.T # m*s3 a3 = sigmoid(z3) # m*s3 return a1,z2,a2,z3,a3 代价函数及其正则化1234def cost(theta,X,y): h = feed_forward(theta,X)[4] itemMat = -y*np.log(h)-(1-y)*np.log(1-h) return np.sum(itemMat)/len(X) 1234def regularized_cost(theta,X,y,lamb=1): t1,t2 = deserialize(theta) reg = np.sum(t1[:,1:]**2)+np.sum(t2[:,1:]**2) # 正则项 return lamb/(2*len(X))*reg + cost(theta,X,y) 12def sigmoidGrad(z): return sigmoid(z)*(1-sigmoid(z)) 神经网络梯度函数及其正则化Backpropagation反向传播 1234567891011121314def costGradient(theta,X,y): """ unregularized gradient 返回，所有theta的梯度 """ t1,t2 = deserialize(theta) a1,z2,a2,z3,a3 = feed_forward(theta,X) d3 = a3-y # m*s3 # theta2的第一列数据不予考虑 d2 = d3 @ t2[:,1:] * sigmoidGrad(z2) # m*(s2+1) D2 = d3.T@a2 # s3*(s2+1) D1 = d2.T@a1 # s2*(s1+1) return 1/len(X)*serialize(D1,D2) 1234567891011121314def regularizedGrad(theta,X,y,l=1): """ 正则化的梯度 返回，所有theta的梯度 """ # D1 and t1, s2*(s1+1);D2 and t2, s3*(s2+1) D1,D2 = deserialize(costGradient(theta,X,y)) t1,t2 = deserialize(theta) t1[:,0] = 0 t2[:,0] = 0 reg_D1 = D1 + (l / len(X)) * t1 reg_D2 = D2 + (l / len(X)) * t2 return serialize(D1,D2) 梯度检测因为反向传播算法代价函数和梯度函数代码编写过程中可能存在bug，故使用数值计算梯度与反向传播算法计算的梯度进行比较，以验证反向传播算法代价函数和梯度函数代码的正确性。不过这个函数运行起来超级慢，这里只贴代码，不展示运行结果了。 12345678910111213141516def gradientCheck(theta,X,y,e): numericGrad = [] for i in range(len(theta)): plus = theta.copy() minus = theta.copy() plus[i] += e minus[i] += e grad_i = (regularized_cost(plus,X,y)-regularized_cost(minus,X,y))/(2*e) numericGrad.append(grad_i) numericGrad = np.array(numericGrad) analyticGrad = regularizedGrad(theta, X, y) diff = np.linalg.norm(numericGrad - analyticGrad) / np.linalg.norm(numericGrad + analyticGrad) print('If your backpropagation implementation is correct,\nthe relative difference will \ be smaller than 10e-9 (assume epsilon=0.0001).\nRelative Difference: &#123;&#125;\n'.format(diff)) 1initTheta = randomInit((inputLayerSize+1)*hiddenLayerSize+(hiddenLayerSize+1)*outputLayerSize) 1gradientCheck(initTheta,X,y,0.0001) 测试算法12345def randomInit(size): """ 随机初始化size尺寸的矩阵 """ return np.random.uniform(-0.12, 0.12, size) 123456789def nn_training(X,y): init_theta = randomInit((inputLayerSize+1)*hiddenLayerSize+(hiddenLayerSize+1)*outputLayerSize) res = minimize(fun=regularized_cost, x0=init_theta, args=(X,y), method='TNC', jac=regularizedGrad, options=&#123;"maxiter":500&#125;) return res 123trainingy = np.array([y[i] for i in range(len(y)) if i in trainIndices])res = nn_training(trainingX,trainingy)res 12345678910 fun: 0.9114611628633325 jac: array([ 2.96364632e-03, -1.62797300e-04, 2.89863853e-04, ..., 9.59179838e-04, 1.10862199e-06, -4.78441900e-03])message: &apos;Converged (|f_n-f_(n-1)| ~= 0)&apos; nfev: 163 nit: 11 status: 1success: True x: array([ 0. , 0.44110449, 0.17106004, ..., -0.34636188, 0.6146963 , -0.88931194]) 12345from sklearn.metrics import classification_reportdef accuracyBP(theta,X,y): h = feed_forward(res.x,X)[4] y_pred = np.argmax(h,axis=1) print(classification_report(y,y_pred)) 12testy = np.array([y_another[i] for i in range(len(y_another)) if i not in trainIndices])accuracyBP(res.x,testX,testy) 12345678910111213141516 precision recall f1-score support 0 0.93 0.98 0.95 53 1 0.89 0.83 0.86 58 2 0.96 0.90 0.93 50 3 0.84 0.88 0.86 52 4 0.95 0.85 0.90 48 5 0.93 0.90 0.91 48 6 0.93 0.95 0.94 58 7 0.98 0.89 0.93 54 8 0.74 0.96 0.83 52 9 0.86 0.79 0.82 53 micro avg 0.89 0.89 0.89 526 macro avg 0.90 0.89 0.89 526weighted avg 0.90 0.89 0.89 526 从上面可以看出,查准率约为0.9，查全率约为0.89，比逻辑回归算法稍有不如。但是实际上神经网络的可调性很强，适用范围也更大。]]></content>
  </entry>
  <entry>
    <title><![CDATA[k近邻算法实战]]></title>
    <url>%2F2018%2F12%2F08%2Fk-nearest-neighbors%2F</url>
    <content type="text"><![CDATA[k-近邻算法概述k-近邻算法的工作原理是： 存在一个样本数据集，也即训练集，其中的每个样本数据对存在一个对应标签，也即样本的分类。当输入没有标签的新样本后，我们通过将新数据的每个特征与样本数据集中对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。通常做法是提取特征向量最相近的前k个数据，取其中出现次数最多的分类，作为输入新样本的分类标签 用一个简单的例子来描述一下k-近邻算法的一般流程 准备用pyhton导入数据创建一个名为kNN的Python模块，在kNN.py中增加下列代码： 123456789from numpy import *import operatordef createDataSet(): """ 以四个点(1,1.1),(1,1),(0,0),(0,0.1)为例，其标签分分别是'A','B','C','D' """ group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]]) labels = ['A','A','B','B'] return group,labels 123group,labels = createDataSet()print(group)print(labels) [[1. 1.1] [1. 1. ] [0. 0. ] [0. 0.1]] [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;] 实施kNN算法kNN算法的伪代码如下: 计算已知类别数据集中的点与当前点之间的距离 按照距离递增次序排序 选取与当前点距离最小的k个点 确定当前k个点所在类别的出现频率 返回前k个点出现频率最高的类别作为当前点的预测分类 pyhton函数classify0如下所示： 123456789101112131415161718def classify0(inX,dataSet,labels,k): """ 输入参数为inX（待分类的数据特征向量），dataSet(训练数据多个特征向量构成的矩阵)，labels(训练数据特征向量对应的标签向量)，k（k值） 返回为inX的预估的标签 """ dataSetSize = dataSet.shape[0] diffMat = tile(inX,(dataSetSize,1))-dataSet # 新数据与训练数据作差 sqDiffMat = diffMat**2 sqDistances = sqDiffMat.sum(axis = 1) # 对差平方矩阵进行每行求和 distances = sqDistances**0.5 # 开平方根，为新数据向量与训练数据向量的距离 sortedDistanceIndices = distances.argsort() #按照距离从小到大排序，返回下标向量 classCount = &#123;&#125; for i in range(k): # 统计前k个点对应的标签，插入classCount字典中 voteIlabel = labels[sortedDistanceIndices[i]] classCount[voteIlabel] = classCount.get(voteIlabel,0)+1 sortedClassCount = sorted(classCount.items(),key = operator.itemgetter(1),reverse=True) # 利用字典中的value值进行从大到小的排序 return sortedClassCount[0][0] 上述程序使用欧式距离公式，计算两个向量$xA$和$xB$之间的距离: d=\sqrt {(xA_0-xB_0)^2+(xA_1-xB_1)^2}对数据点[0,0]进行分类，它实际上属于B类（画个图就知道了）。运行下列代码，确实是B 1classify0([0,0],group,labels,3) &#39;B&#39; 使用k近邻算法改进约会网站的配对效果海伦将约会网站上的约会对象分为三种人， 不喜欢的人 魅力一般的人 极具魅力的人我们需要根据已有数据采用k近邻算法，来帮助海伦将约会对象划分到确切的分类中。大致步骤 收集数据：获得海伦给定的对象数据特征和分类标签 准备数据：使用pyhton解析文本文件 分析数据：使用matplotlib画二维扩散图 训练算法：k近邻算法用不着训练数据 测试算法：使用海伦提供的部分数据作为测试样本 使用算法：产生简单的命令行程序，使得海伦通过输入一些数据来判断对方是否为自己喜欢的类型准备数据下载海伦提供的数据。查看数据，可以看出，每个样本数据占据一行，每一行有四列，前三列是3种特征： 每年获得的飞行常客里程数 玩视频游戏所消耗的时间百分比 每周消耗的冰淇淋公升数第四列是海伦给这个样本定义的标签，有’largeDoses’,’smallDoses’,’didntLike’ 1!wget https://github.com/pbharrin/machinelearninginaction/raw/master/Ch02/datingTestSet.txt 1!cat datingTestSet.txt 在kNN.py中创建名为file2matrix的函数，以此来处理输入格式问题。file2matrix输入文件名，返回特征数据矩阵和标签向量 123456789101112131415161718def file2matrix(filename): """ 根据文件名读取数据，返回特征数据矩阵和标签向量 """ dic = &#123;'didntLike':1,'smallDoses':2,'largeDoses':3&#125; fr = open(filename) arrayOLines = fr.readlines() # 以列表形式存储文本数据，列表元素为字符串 numberOfLines = len(arrayOLines) returnMat = np.zeros((numberOfLines,3)) # 返回的特征数据矩阵 classLabelVector = [] # 返回的标签向量 index = 0 for line in arrayOLines: line = line.strip() # remove leading and trailing whitespace listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(dic[listFromLine[-1]]) index+=1 return returnMat,classLabelVector 在执行上述代码后，可调用file2matrix函数将文件’datingTestSet.txt’导入到内存中 1datingDataMat,datingLabels = file2matrix('datingTestSet.txt') 分析数据利用Matplotlib制作原始数据的散点图 1234567891011121314151617181920import matplotlibimport matplotlib.pyplot as pltfig = plt.figure(figsize=(10,15))ax1 = fig.add_subplot(311) # 设定figure里面有多少个子图和子图位置ax1.scatter(datingDataMat[:,0],datingDataMat[:,1],15.0*np.array(datingLabels),15.0*np.array(datingLabels))ax1.set_title("Charisma scattering plot")ax1.set_xlabel("Flying milages")ax1.set_ylabel("Time percentage of playing games")ax2 = fig.add_subplot(312) # 设定figure里面有多少个子图和子图位置ax2.scatter(datingDataMat[:,0],datingDataMat[:,2],15.0*np.array(datingLabels),15.0*np.array(datingLabels))ax2.set_title("Charisma scattering plot")ax2.set_xlabel("Flying milages")ax2.set_ylabel("Weekly consumption of ice cream/liter")ax3 = fig.add_subplot(313) # 设定figure里面有多少个子图和子图位置ax3.scatter(datingDataMat[:,1],datingDataMat[:,2],15.0*np.array(datingLabels),15.0*np.array(datingLabels))ax3.set_title('Charisma scattering plot')ax3.set_xlabel('Time percentage of playing games')ax3.set_ylabel('Weekly consumption of ice cream/liter')plt.show() 准备数据：归一化数值显然，因为飞行常客里程数远远大于玩视频游戏时间占比与每周消费冰淇淋公升数，而海伦认为这三种特征是同样重要的，所以需要对特征树进行归一化处理。通过下面公式将任意范围的特征值转为0到1区间的值： newValue = (oldValue-min)/(max-min)下面是归一化特征值的代码 123456789def autoNorm(dataSet): minVals = dataSet.min(0) # 对每一列求最小值，得到一个有三个元素的向量 maxVals = dataSet.max(0) # 对每一列求最大值，得到一个有三个元素的向量 ranges = maxVals-minVals # 获得每一列最大值与最小值的差值 normDataSet = np.zeros(np.shape(dataSet)) m = dataSet.shape[0] #数据集有多少行 normDataSet = dataSet - np.tile(minVals,(m,1)) normDataSet = normDataSet/tile(ranges,(m,1)) return normDataSet,ranges,minVals 1normMat,ranges,minVals = autoNorm(datingDataMat) 123print(normMat[0:5])print(ranges)print(minVals) [[0.44832535 0.39805139 0.56233353] [0.15873259 0.34195467 0.98724416] [0.28542943 0.06892523 0.47449629] [0.82320073 0.62848007 0.25248929] [0.42010233 0.07982027 0.0785783 ]] [9.1273000e+04 2.0919349e+01 1.6943610e+00] [0. 0. 0.001156] 测试算法为了测试分类器效果，我们定义了一个datingClassTest函数，该函数是自包含的，选用海伦提供数据的前10%作为测试数据，后90%作为训练集数据。代码如下： 1234567891011121314def datingClassTest(): hoRatio = 0.10 datingDataMat,datingDataLabels = file2matrix('datingTestSet.txt') normMat,ranges,minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errCoount = 0 # 预测错误向量个数 for i in range(numTestVecs): # 遍历所有的测试向量 classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) # print("the classifier came back with:%d, the real answer is:%d"%(classifierResult,datingLabels[i])) if classifierResult!=datingLabels[i]: errCoount += 1 print("the total error rate is: %f"%(errCoount/float(numTestVecs))) 1datingClassTest() the total error rate is: 0.050000 使用算法：构建完整系统设计一个函数，能够询问约会对象的特征数据，然后给出预估的分类 12345678910def classifyPerson(): resultList = ['not at all','in small doses','in large doses'] percentageTats = float(input("percentage of time spent in playing video games?")) ffMiles = float(input("frequent flier miles earned each year?")) icecream = float(input("liters of ice cream cosumed each week?")) datingDataMat,datingLabels = file2matrix('datingTestSet.txt') normMat,ranges,minVals = autoNorm(datingDataMat) inArr = array([ffMiles,percentageTats,icecream]) classifierResult = classify0((inArr-minVals)/ranges,normMat,datingLabels,3) print("You will propably like this person %s"%resultList[int(classifierResult)-1]) 1classifyPerson() percentage of time spent in playing video games?10 frequent flier miles earned each year?10000 liters of ice cream cosumed each week?0.5 You will propably like this person in small doses 1以上让人觉得十分容易看懂，事实上k-近邻算法本身就是一个非常简单的算法。接下来看看，如何在二进制存储的图像数据上使用kNN。 手写识别数字需要识别的数字已经通过软件转成宽高32x32的黑白图像，这里直接使用图像的文本格式 准备数据:将图像转化为测试向量执行以下指令，获取并解压数据文件，文件夹中包含两个文件夹trainingDigits和testDigits，分别对应训练数据和测试数据 12!wget https://github.com/pbharrin/machinelearninginaction/raw/master/Ch02/digits.zip!unzip digits.zip 首先编写一个函数根据手写数字的文件名读入数据将32x32的矩阵转成一个1x1024的向量 123456789101112def img2vector(filename): """ 参数为一个图像文本文件的名字 返回1x1024的向量 """ returnVect = zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVect 1print(img2vector("testDigits/0_0.txt")) [[0. 0. 0. ... 0. 0. 0.]] 测试算法：使用k近邻算法实现手写数字的识别下面实现一个函数classifyDigitTest，输入数字图像转化来的1x1024向量， 123456789101112131415161718192021222324252627282930from os import listdirdef classifyDigitTest(): # 首先列出trainingDigits下的所有文件名，文件数为m # 根据trainingDigits下的所有文件构造m*1024的特征矩阵和，m*1的标签向量 # 列出testDigits下的所有文件名，文件数为testN # 对testDigits文件夹下的进行循环判断，以获得算法的手写数字识别错误率 # 调用classify0获得digitVect的结果标签 # 有文件名名可获得digitVect的真实标签，对比，若不等errorCount++ # 获得手写识别错误率 trainingFiles = listdir('trainingDigits') m = len(trainingFiles) trainingDataMat = np.zeros((m,1024)) trainingLabelsVect = [] for i in range(m): trainingFileName = trainingFiles[i] realLabel = int(trainingFileName.split('.')[0].split('_')[0]) trainingDataMat[i,:] = img2vector('trainingDigits/'+trainingFileName) # 构造特征矩阵第i行 trainingLabelsVect.append(realLabel) testFiles = listdir('testDigits') testN = len(testFiles) errCount = 0.0 for i in range(testN): testFileName = testFiles[i] testDataVect = img2vector('testDigits/'+testFileName) # 获得测试文件的特征向量 testRealLabel = int(testFileName.split('.')[0].split('_')[0]) # 获得测试文件名中的数据标签 testLabel = classify0(testDataVect,trainingDataMat,trainingLabelsVect,3) # 采用k近邻算法估计测试文件的标签 # print("test data file:%s,predicted label:%s,real label:%s"%(testFileName,testLabel,testRealLabel)) if testLabel!=testRealLabel: errCount+=1 print("model accuracy:%.5f"%(1-errCount/testN)) 12start = tiemclassifyDigitTest() model accuracy:0.99 实际上，使用这个算法效率太低，而且训练集数据越大，耗时越多，我们需要为每个测试向量做m次距离计算(m是训练集样本数)，每个距离计算包括1024个维度的浮点数计算。k近邻算法没有训练出一个模型出来，而是直接将输入与所有的训练数据一一比较。]]></content>
      <categories>
        <category>机器学习实战</category>
      </categories>
      <tags>
        <tag>k近邻算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python传递参数究竟是值传递还是引用传递]]></title>
    <url>%2F2018%2F12%2F08%2Fpython-passParam%2F</url>
    <content type="text"><![CDATA[首先还是应该科普下函数参数传递机制，传值和传引用是什么意思？ 函数参数传递机制问题在本质上是调用函数（过程）和被调用函数（过程）在调用发生时进行通信的方法问题。基本的参数传递机制有两种：值传递和引用传递。 值传递（passl-by-value）过程中，被调函数的形式参数作为被调函数的局部变量处理，即在堆栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。 引用传递(pass-by-reference)过程中，被调函数的形式参数虽然也作为局部变量在堆栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过堆栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。 那么,python究竟是怎样的呢 123456789101112131415161718192021222324from ctypes import *import os.path import sysdef test(c): print("test before ") print(id(c)) c+=2 print("test after") print(id(c)) return cdef printIt(t): for i in range(len(t)): print(t[i])if __name__=="__main__": a=2 print("main before invoke test") print(id(a)) n=test(a) print("main afterf invoke test") print(a) print(id(a)) 12345main before invoke testtest before test after +main afterf invoke test39601564 从上可以看出，传参数进去时，传得是引用，因为参数地址没变。但是对传入参数赋值后，其地址就发生了变化。基于这个例子画了个图表示 那么python传递参数传得真是引用，然后传参的值在被调函数内被修改也不影响主调函数的实参变量的值？有传入对象可变与不可变的说法，对于可变对象，在被调函数内修改传参会影响主调函数的实参变量，对于不可变对象修改传参则不会改变主调函数实参的值，因为修改不可变对象实际上是另开辟内存重新赋值并让传参变量指向该内存。看下面例子 123456789101112131415161718192021222324from ctypes import *import os.path import sysdef test(list2): print("test before ") print(id(list2)) list2[1]=30 print("test after +") print(id(list2)) return list2def printIt(t): for i in range(len(t)): print(t[i])if __name__=="__main__": list1=["loleina",25,'female'] print("main before invoke test") print(id(list1)) list3=test(list1) print("main afterf invoke test") print(list1) print(id(list1)) 123456789main before invoke test4485568072test before 4485568072test after +4485568072main afterf invoke test[&apos;loleina&apos;, 30, &apos;female&apos;]4485568072 结论：python不允许程序员选择采用传值还是传引用。Python参数传递采用的肯定是“传对象引用”的方式。这种方式相当于传值和传引用的一种综合。如果函数收到的是一个可变对象（比如字典或者列表）的引用，就能修改对象的原始值－－相当于通过“传引用”来传递对象。如果函数收到的是一个不可变对象（比如数字、字符或者元组）的引用，就不能直接修改原始对象－－相当于通过“传值’来传递对象。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python在命令行下查看模块，函数的用法]]></title>
    <url>%2F2018%2F11%2F29%2Fpython-help%2F</url>
    <content type="text"><![CDATA[python的一个优势是有着大量自带和在线的模块(module)资源，可以提供丰富的功能，在使用这些模块的时候，如果每次都去网站找在线文档会过于耗费时间，结果也不一定准确。因此这里介绍下python自带的查看帮助功能，可以在编程时不中断地迅速找到所需模块和函数的使用方法。 通用帮助函数help()在python命令行中键入help(),可以看到：1234567891011121314151617&gt;&gt;&gt; help()Welcome to Python 3.5&apos;s help utility!If this is your first time using Python, you should definitely check outthe tutorial on the Internet at http://docs.python.org/3.5/tutorial/.Enter the name of any module, keyword, or topic to get help on writingPython programs and using Python modules. To quit this help utility andreturn to the interpreter, just type &quot;quit&quot;.To get a list of available modules, keywords, symbols, or topics, type&quot;modules&quot;, &quot;keywords&quot;, &quot;symbols&quot;, or &quot;topics&quot;. Each module also comeswith a one-line summary of what it does; to list the modules whose nameor summary contain a given string such as &quot;spam&quot;, type &quot;modules spam&quot;.help&gt; 进入help帮助文档界面，根据屏幕提示可以继续键入相应关键词进行查询，继续键入modules可以列出当前所有安装的模块：12345678910help&gt; modulesPlease wait a moment while I gather a list of all available modules...AutoComplete _pyio filecmp pyscreezeAutoCompleteWindow _random fileinput pytweening...... Enter any module name to get more help. Or, type &quot;modules spam&quot; to searchfor modules whose name or summary contain the string &quot;spam&quot;. 可以继续键入相应的模块名称得到该模块的帮助信息。这是python的通用的查询帮助，可以查到几乎所有的帮助文档，但我们很多时候不需要这样层级式地向下查询，接下来会介绍如何直接查询特定的模块和函数帮助信息。 模块帮助查询查看.py结尾的普通模块help(module_name)例如要查询math模块的使用方法，可以如下操作：12345678910111213141516171819&gt;&gt;&gt; import math&gt;&gt;&gt; help(math)Help on built-in module math:NAME mathDESCRIPTION This module is always available. It provides access to the mathematical functions defined by the C standard.FUNCTIONS acos(...) acos(x) Return the arc cosine (measured in radians) of x....&gt;&gt;&gt; 使用help(module_name)时首先需要import该模块，有些教程中不进行导入而在模块名中加入引号help(‘module_name’)，这种方法可能会带来问题，大家可以用math模块测试，建议使用先导入再使用help()函数查询。 查看内建模块sys.bultin_modulenames1234&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.builtin_module_names(&apos;_ast&apos;, &apos;_bisect&apos;, &apos;_codecs&apos;, &apos;_codecs_cn&apos;, &apos;_codecs_hk&apos;, ... &apos;zlib&apos;)&gt;&gt;&gt; 需要导入sys模块。这里列举的一般是自带的使用C/C++编译链接的模块 查询函数信息查看模块下所有函数dir(module_name)如我们需要列举出math模块下所有的函数名称123&gt;&gt;&gt; dir(math)[&apos;__doc__&apos;, &apos;__loader__&apos;, &apos;__name__&apos;,...]&gt;&gt;&gt; 同样需要首先导入该模块 查看模块下特定函数信息help(module_name.func_name)如查看math下的sin()函数 123456789&gt;&gt;&gt; help(math.sin)Help on built-in function sin in module math:sin(...) sin(x) Return the sine of x (measured in radians).&gt;&gt;&gt; 查看函数信息的另一种方法print(func_name.doc)如查看内建函数print用法。既可以用来查看内建函数，也可以查看模块函数信息。 123456&gt;&gt;&gt; print(print.__doc__)print(value, ..., sep=&apos; &apos;, end=&apos;\n&apos;, file=sys.stdout, flush=False)Prints the values to a stream, or to sys.stdout by default....&gt;&gt;&gt; doc前后是两个短下划线，在python中会合并为长下划线python中的help()类似unix中的man指令，熟悉后会对我们的编程带来很大帮助]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的lambda表达式]]></title>
    <url>%2F2018%2F11%2F29%2Fpython-lambda%2F</url>
    <content type="text"><![CDATA[这里，我们通过阅读各方资料，总结了关于Python中的lambda的“一个语法，三个特性，四个用法”。 一个语法在Python中，lambda的语法是唯一的。其形式如下： lambda argument_list: expression 其中，lambda是Python预留的关键字，argument_list和expression由用户自定义。具体介绍如下。这里的argument_list是参数列表。它的结构与Python中函数(function)的参数列表是一样的。具体来说，argument_list可以有非常多的形式。例如： a, b a=1, b=2 *args **kwargs a, b=1, *args 空 …… 这里的expression是一个关于参数的表达式。表达式中出现的参数需要在argument_list中有定义，并且表达式只能是单行的。以下都是合法的表达式： 1 None a + b sum(a) 1 if a &gt;10 else 0 …… 这里的lambda argument_list: expression表示的是一个函数。这个函数叫做lambda函数。 三个特性lambda函数有如下特性： lambda函数是匿名的：所谓匿名函数，通俗地说就是没有名字的函数。lambda函数没有名字。 lambda函数有输入和输出：输入是传入到参数列表argument_list的值，输出是根据表达式expression计算得到的值。 lambda函数一般功能简单：单行expression决定了lambda函数不可能完成复杂的逻辑，只能完成非常简单的功能。由于其实现的功能一目了然，甚至不需要专门的名字来说明。 下面是一些lambda函数示例：1234567lambda x, y: x*y；函数输入是x和y，输出是它们的积x*ylambda:None；函数没有输入参数，输出是Nonelambda *args: sum(args); 输入是任意个数的参数，输出是它们的和(隐性要求是输入参数必须能够进行加法运算)lambda **kwargs: 1；输入是任意键值对参数，输出是1 四个用法由于lambda语法是固定的，其本质上只有一种用法，那就是定义一个lambda函数。在实际中，根据这个lambda函数应用场景的不同，可以将lambda函数的用法扩展为以下几种： 将lambda函数赋值给一个变量，通过这个变量间接调用该lambda函数。例如，执行语句add=lambda x, y: x+y，定义了加法函数lambda x, y: x+y，并将其赋值给变量add，这样变量add便成为具有加法功能的函数。例如，执行add(1,2)，输出为3。 将lambda函数赋值给其他函数，从而将其他函数用该lambda函数替换。例如，为了把标准库time中的函数sleep的功能屏蔽(Mock)，我们可以在程序初始化时调用：time.sleep=lambda x:None。这样，在后续代码中调用time库的sleep函数将不会执行原有的功能。例如，执行time.sleep(3)时，程序不会休眠3秒钟，而是什么都不做。 将lambda函数作为其他函数的返回值，返回给调用者。函数的返回值也可以是函数。例如return lambda x, y: x+y返回一个加法函数。这时，lambda函数实际上是定义在某个函数内部的函数，称之为嵌套函数，或者内部函数。对应的，将包含嵌套函数的函数称之为外部函数。内部函数能够访问外部函数的局部变量，这个特性是闭包(Closure)编程的基础，在这里我们不展开。 将lambda函数作为参数传递给其他函数。 部分Python内置函数接收函数作为参数。典型的此类内置函数有这些。filter函数。此时lambda函数用于指定过滤列表元素的条件。例如filter(lambda x: x % 3 == 0, [1, 2, 3])指定将列表[1,2,3]中能够被3整除的元素过滤出来，其结果是[3]。 sorted函数。此时lambda函数用于指定对列表中所有元素进行排序的准则。例如sorted([1, 2, 3, 4, 5, 6, 7, 8, 9], key=lambda x: abs(5-x))将列表[1, 2, 3, 4, 5, 6, 7, 8, 9]按照元素与5距离从小到大进行排序，其结果是[5, 4, 6, 3, 7, 2, 8, 1, 9]。 map函数。此时lambda函数用于指定对列表中每一个元素的共同操作。例如map(lambda x: x+1, [1, 2,3])将列表[1, 2, 3]中的元素分别加1，其结果[2, 3, 4]。 reduce函数。此时lambda函数用于指定列表中两两相邻元素的结合条件。例如reduce(lambda a, b: &#39;{}, {}&#39;.format(a, b), [1, 2, 3, 4, 5, 6, 7, 8, 9])将列表 [1, 2, 3, 4, 5, 6, 7, 8, 9]中的元素从左往右两两以逗号分隔的字符的形式依次结合起来，其结果是’1, 2, 3, 4, 5, 6, 7, 8, 9’。 另外，部分Python库函数也接收函数作为参数，例如gevent的spawn函数。此时，lambda函数也能够作为参数传入。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>lambda表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数行列式总结]]></title>
    <url>%2F2018%2F11%2F28%2Fpost%2F</url>
    <content type="text"><![CDATA[最近入坑机器学习，线性代数的知识用到很多，所以就回顾了一下，发现也是挺有意思的。行列式对于方阵给出一个特殊的定义值，与方阵的秩和方阵对应的齐次线性方程有没有唯一非零解有着很大的关系。 定义当$n\geq2$时，$n\times n$矩阵$A=\begin{bmatrix}a_{ij}\end{bmatrix}$的行列式是形如$\pm a_{ij} detA_{ij}$的n个项的和，其中加减号交替出现，这里的$a_{11},a_{12},a_{13}…a_{1n}$来自于第一行，即 \begin{aligned} detA&=a_{11}\cdot detA_{11}-a_{12}\cdot detA_{12}+\cdots +(-1)^{1+n}a_{1n}detA_{1n}\\ &=\sum_{j=1}^{n}(-1)^{1+j}a_{1j}detA_{1j}\\ \end{aligned}当然这是针对第一行展开的，从中可以看出$n\times n$阶的行列式被展开成若干个$(n-1)\times(n-1)$阶的行列式。$detA_{1j}$称为代数余子式，是划掉行列式A的第$1$行第$j$列后余下行列式的值，也可以对第$i$行进行展开，$1$替换成$i$即可。同样地，也可以对某一列进行展开。 定理 若$A$为三角阵，则$detA$为主对角线上元素乘积。这里的三角阵仅考虑行列式主对角线上边或下边元素全为零的情况。 行变换性质。令$A$是一个方阵，则有 若$A$的一行加上另一行的倍数得到$B$，则$detA=detB$ 若$A$的两行互换得到$B$，则$detA=-detB$ 若$A$的某行乘以k得到$B$，则$detA=kdetB$ $A$中有任何一行为0，则$detA=0$ 实际上，列变换也具有这些性质通过行列式的行变换，可以将一个复杂的行列式化简成三角型，如果化成阶梯型后不是三角型，则说明行列式值为0。 当且仅当$detA\neq 0$时方阵$A$是可逆的 若$A$为一个$n\times n$矩阵，则$detA^T=detA$ 乘法性质。$det(AB)=(detA)(detB)$ 线性方程组的解集问题 齐次线性方程组的解集 首先说一下什么是齐次线性方程组。就是方程组可以写成$A\textbf x=\textbf 0$，$A$是系数矩阵($m\times n$阶)，$\textbf x$是未知数n维列向量。显然这个方程必然有零解($x_1=0,x_2=0\cdots x_n=0$)。 有没有非零解，取决于方程组有没有自由变量。如果系数矩阵的行秩$\geq$未知数个数n（事实上只能$=$，因为任何矩阵行秩$=$列秩$=$秩），也就是线性无关的有效方程的个数$=$未知数个数n，方程只有零解。如果小于，则$n-$行秩就是方程组自有变量的个数。如果$x_1,x_2$是自有变量的话，那么通解为$\textbf x=x_1\textbf u+x_2\textbf v$，$\textbf u,\textbf v$为由方程解出来的列向量。 非齐次线性方程的解集 非齐次线性方程组是为$A\textbf x=\textbf b$的形式，$\textbf b$为n维非$0$列向量。它的解有三种情况，由增广矩阵$\begin{bmatrix}A&amp;\textbf b\end{bmatrix}$与系数矩阵$A$的秩的关系决定。若$r_{系数矩阵}=r_{增广矩阵}=n$，则有唯一解；若$r_{系数矩阵}=r_{增广矩阵}&lt;n$,则有无穷解。若$r_{系数矩阵}\neq r_{增广矩阵}$，则无解。（其中n为未知数的个数）。$r_{系数矩阵}\neq r_{增广矩阵}$反映了给定的线性方程组有互相矛盾的情况，其差为矛盾线性方程的个数；若$r_{系数矩阵}=r_{增广矩阵}&lt;n$，则说明给定的线性无关方程的个数小于未知变量个数，自然会有无穷多个解。 如果非齐次线性方程组有解，且p是一个特解，则$A\textbf x=\textbf b$的解集所有形如$\textbf w=\textbf p+\textbf v_{h}$，其中$\textbf v_{h}$是齐次线性方程组$A\textbf x=\textbf 0$的通解。克拉默法则克拉默法则是用来求解系数矩阵为方阵且可逆的非齐次线性方程组的唯一解的定理。首先定义一个替换矩阵，对于任意$n\times n$矩阵$A$和任意$\mathbb{R^{n}}$中向量$\textbf b$，令${A_i(b)}$表示$A$中第i列由向量$b$替换得到的矩阵。即 {A_i(b)=}\begin{bmatrix} {a_1}& \cdots &{b} &\cdots &{a_n} \end{bmatrix}接下来正式说明一下什么是克拉默法则设$ A$是一个可逆的$n\times n$矩阵，对任意$\mathbb{R^{n}}$中向量$ b$，方程${Ax=b}$的唯一解可由下式给出， {x_i=\frac{detA_ib}{detA},i=1,2\cdots n}$detA\neq 0$再加上$n\times n$方阵的条件可以说明$r_{系数矩阵}=r_{增广矩阵}=n$]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>行列式</tag>
      </tags>
  </entry>
</search>
