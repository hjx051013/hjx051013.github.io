<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>追风少年</title>
  
  <subtitle>Code is poetry</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="hjx051013.github.io/"/>
  <updated>2019-07-05T04:01:28.568Z</updated>
  <id>hjx051013.github.io/</id>
  
  <author>
    <name>jiaxinhuang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>进程间通信方式</title>
    <link href="hjx051013.github.io/2019/07/05/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/"/>
    <id>hjx051013.github.io/2019/07/05/进程间通信方式/</id>
    <published>2019-07-05T03:42:50.000Z</published>
    <updated>2019-07-05T04:01:28.568Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Unix-IPC机制总结"><a href="#Unix-IPC机制总结" class="headerlink" title="Unix IPC机制总结"></a>Unix IPC机制总结</h1><p>进程间通信(IPC, InterProcess Communication)是指在不同进程间传播或者交换信息</p><p>常见IPC的方式有管道、消息队列、信号量、共享存储、socket、Streams等，其中socket和streams支持不同主机上的两个进程进行通信。</p><h2 id="一、管道"><a href="#一、管道" class="headerlink" title="一、管道"></a>一、管道</h2><h3 id="1-匿名管道"><a href="#1-匿名管道" class="headerlink" title="1. 匿名管道"></a>1. 匿名管道</h3><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul><li>半双工，即数据只能在一个方向上流动，读写端固定</li><li>只能在具有亲缘关系的进程之间通信</li><li>可以看成是特殊的文件，有文件描述符，但只存在于内存中</li></ul><h4 id="原型"><a href="#原型" class="headerlink" title="原型"></a>原型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">int pipe(int fd[2])</span><br></pre></td></tr></table></figure><p><img src="http://ww3.sinaimg.cn/large/006tNc79gy1g4otttvk0uj30l60kqgms.jpg" alt="image-20190705115418630"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Unix-IPC机制总结&quot;&gt;&lt;a href=&quot;#Unix-IPC机制总结&quot; class=&quot;headerlink&quot; title=&quot;Unix IPC机制总结&quot;&gt;&lt;/a&gt;Unix IPC机制总结&lt;/h1&gt;&lt;p&gt;进程间通信(IPC, InterProcess Commun
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Makefile赋值符辨析.md</title>
    <link href="hjx051013.github.io/2019/05/29/Makefile%E8%B5%8B%E5%80%BC%E7%AC%A6%E8%BE%A8%E6%9E%90/"/>
    <id>hjx051013.github.io/2019/05/29/Makefile赋值符辨析/</id>
    <published>2019-05-29T13:49:16.000Z</published>
    <updated>2019-05-29T13:54:02.781Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Makefile-中-的区别"><a href="#Makefile-中-的区别" class="headerlink" title="Makefile 中:= ?= += =的区别"></a>Makefile 中:= ?= += =的区别</h2><p>在Makefile中我们经常看到 = := ?= +=这几个赋值运算符，那么他们有什么区别呢？我们来做个简单的实验</p><p>新建一个Makefile，内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">ifdef DEFINE_VRE</span><br><span class="line">    VRE = “Hello World!”</span><br><span class="line">else</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">ifeq ($(OPT),define)</span><br><span class="line">    VRE ?= “Hello World! First!”</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">ifeq ($(OPT),add)</span><br><span class="line">    VRE += “Kelly!”</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">ifeq ($(OPT),recover)</span><br><span class="line">    VRE := “Hello World! Again!”</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">all:</span><br><span class="line">    @echo $(VRE)</span><br></pre></td></tr></table></figure></p><p>敲入以下make命令：</p><p>make DEFINE_VRE=true OPT=define 输出：Hello World!<br>make DEFINE_VRE=true OPT=add 输出：Hello World! Kelly!<br>make DEFINE_VRE=true OPT=recover  输出：Hello World! Again!<br>make DEFINE_VRE= OPT=define 输出：Hello World! First!<br>make DEFINE_VRE= OPT=add 输出：Kelly!<br>make DEFINE_VRE= OPT=recover 输出：Hello World! Again!</p><p>从上面的结果中我们可以清楚的看到他们的区别了</p><ul><li>= 是最基本的赋值</li><li>:= 是覆盖之前的值</li><li>?= 是如果没有被赋值过就赋予等号后面的值</li><li>+= 是添加等号后面的值</li></ul><p>之前一直纠结makefile中“=”和“:=”的区别到底有什么区别，因为给变量赋值时，两个符号都在使用。网上搜了一下，有人给出了解答，但是本人愚钝，看不懂什么意思。几寻无果之下，也就放下了。今天看一篇博客，无意中发现作者对于这个问题做了很好的解答。解决问题之余不免感叹，有时候给个例子不就清楚了吗？为什么非要说得那么学术呢。^_^</p><ol><li>“=”</li></ol><p>make会将整个makefile展开后，再决定变量的值。也就是说，变量的值将会是整个makefile中最后被指定的值。看例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = foo</span><br><span class="line">y = $(x) bar</span><br><span class="line">x = xyz</span><br></pre></td></tr></table></figure></p><p>在上例中，y的值将会是 <code>xyz bar</code> ，而不是 <code>foo bar</code> 。</p><ol><li>“:=”</li></ol><p>“:=”表示变量的值决定于它在makefile中的位置，而不是整个makefile展开后的最终值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x := foo</span><br><span class="line">y := $(x) bar</span><br><span class="line">x := xyz</span><br></pre></td></tr></table></figure></p><p>在上例中，y的值将会是 <code>foo bar</code> ，而不是 <code>xyz bar</code>了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Makefile-中-的区别&quot;&gt;&lt;a href=&quot;#Makefile-中-的区别&quot; class=&quot;headerlink&quot; title=&quot;Makefile 中:= ?= += =的区别&quot;&gt;&lt;/a&gt;Makefile 中:= ?= += =的区别&lt;/h2&gt;&lt;p&gt;在Mak
      
    
    </summary>
    
      <category term="C/C++" scheme="hjx051013.github.io/categories/C-C/"/>
    
    
      <category term="Makefile" scheme="hjx051013.github.io/tags/Makefile/"/>
    
  </entry>
  
  <entry>
    <title>手写数字识别</title>
    <link href="hjx051013.github.io/2018/12/10/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>hjx051013.github.io/2018/12/10/手写数字识别/</id>
    <published>2018-12-10T07:37:46.000Z</published>
    <updated>2018-12-10T07:49:04.020Z</updated>
    
    <content type="html"><![CDATA[<h1 id="逻辑回归与神经网络实现手写数字识别"><a href="#逻辑回归与神经网络实现手写数字识别" class="headerlink" title="逻辑回归与神经网络实现手写数字识别"></a>逻辑回归与神经网络实现手写数字识别</h1><p>本作业是采用Logistic回归和神经网络两种机器学习算法来识别0~9的手写数字。数据集来源于<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/semeion/" target="_blank" rel="noopener">uci</a>,<br>编程语言为python,文档编写用jupyter notebook.通过wget命令下载数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://archive.ics.uci.edu/ml/machine-learning-databases/semeion/semeion.data</span><br></pre></td></tr></table></figure><h2 id="采用logistic算法识别手写数字"><a href="#采用logistic算法识别手写数字" class="headerlink" title="采用logistic算法识别手写数字"></a>采用logistic算法识别手写数字</h2><p>逻辑回归，是一种被广泛用于分类的算法，通过对线性回归外套一个sigmoid函数使之适用于分类情况。采用一对多策略，先训练出K个二分类器（K为分类总数），当输入新样本时，选择使假设函数值最大的那个分类器对应的分类。<br>首先导入机器学习常用的库，如numpy等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> scipy.misc <span class="comment">#Used to show matrix as an image</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cm <span class="comment">#Used to display images in a specific colormap</span></span><br></pre></td></tr></table></figure><h3 id="导入并处理数据"><a href="#导入并处理数据" class="headerlink" title="导入并处理数据"></a>导入并处理数据</h3><p>从文件导入数据，分析数据可知，数据共有1593行，每行有266个数字（0或1），其中前256个是16*16大小的手写数字图片的文本形式，后面10个数字分别表示0-9的识别结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fr = open(<span class="string">'semeion.data'</span>)</span><br><span class="line">data = fr.readlines()</span><br><span class="line">data = [line.strip().split() <span class="keyword">for</span> line <span class="keyword">in</span> data]</span><br><span class="line">print(<span class="string">"共有%d行数据,每行%d个数字"</span>%(len(data),len(data[<span class="number">0</span>])))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">共有1593行数据,每行266个数字</span><br></pre></td></tr></table></figure><p>将X,y从列表格式转成np.ndarray格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data[<span class="number">0</span>])):</span><br><span class="line">        data[i][j] = int(float(data[i][j]))</span><br><span class="line">X = [example[<span class="number">0</span>:<span class="number">256</span>] <span class="keyword">for</span> example <span class="keyword">in</span> data]</span><br><span class="line">y_old = [example[<span class="number">256</span>:] <span class="keyword">for</span> example <span class="keyword">in</span> data]</span><br><span class="line">y = [line.index(<span class="number">1</span>) <span class="keyword">for</span> line <span class="keyword">in</span> y_old]</span><br><span class="line">X = np.array(X)</span><br><span class="line">y = np.array(y)</span><br></pre></td></tr></table></figure><h3 id="可视化数据"><a href="#可视化数据" class="headerlink" title="可视化数据"></a>可视化数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDatumImg</span><span class="params">(row,width,height)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Function that is handed a single np array with shape 1x400,</span></span><br><span class="line"><span class="string">    crates an image object from it, and returns it</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    square = row[:].reshape(width,height)</span><br><span class="line">    <span class="keyword">return</span> square</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">displayData</span><span class="params">(width,height,indices_to_display = None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Function that picks 100 random rows from X, creates a 20x20 image from each,</span></span><br><span class="line"><span class="string">    then stitches them together into a 10x10 grid of images, and shows it.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    nrows, ncols = <span class="number">10</span>, <span class="number">10</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> indices_to_display:</span><br><span class="line">        indices_to_display = random.sample(range(X.shape[<span class="number">0</span>]), nrows*ncols)</span><br><span class="line">        </span><br><span class="line">    big_picture = np.zeros((height*nrows,width*ncols))</span><br><span class="line">    </span><br><span class="line">    irow, icol = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> indices_to_display:</span><br><span class="line">        <span class="keyword">if</span> icol == ncols:</span><br><span class="line">            irow += <span class="number">1</span></span><br><span class="line">            icol  = <span class="number">0</span></span><br><span class="line">        iimg = getDatumImg(X[idx],width,height)</span><br><span class="line">        big_picture[irow*height:irow*height+iimg.shape[<span class="number">0</span>],icol*width:icol*width+iimg.shape[<span class="number">1</span>]] = iimg</span><br><span class="line">        icol += <span class="number">1</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">    img = scipy.misc.toimage( big_picture )</span><br><span class="line">    plt.imshow(img,cmap = cm.Greys_r)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">displayData(<span class="number">16</span>,<span class="number">16</span>,list(range(<span class="number">100</span>)))</span><br></pre></td></tr></table></figure><p><img src="http://hjx-markdown-images.test.upcdn.net/2018/12/10/56f276b5eb24e381b936b31b8c0dc51c.png" alt="handwriting digit recognition_12_1.png"></p><h3 id="训练算法：获得K-n-1-的参数矩阵"><a href="#训练算法：获得K-n-1-的参数矩阵" class="headerlink" title="训练算法：获得K*(n+1)的参数矩阵"></a>训练算法：获得K*(n+1)的参数矩阵</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加全为1的第一列</span></span><br><span class="line">X = np.insert(X,<span class="number">0</span>,values=np.ones(X.shape[<span class="number">0</span>]),axis=<span class="number">1</span>) <span class="comment"># m*(n+1)</span></span><br></pre></td></tr></table></figure><p>逻辑回归的代价函数如下图所示，其中第二项防止训练模型出现过拟合，也即经过正则化的代价函数<br><img src="http://hjx-markdown-images.test.upcdn.net/2018/12/10/ae8a18d497057eb07a446a0c5b5ae873.png" alt="Xnip2018-12-10_00-59-06.png"><br>逻辑回归代价函数对参数向量的梯度求解公式如下图所示，第二项也是为了防止过拟合的情况<br><img src="http://hjx-markdown-images.test.upcdn.net/2018/12/10/324b6dd047f5490f5e355d036982a764.png" alt="Xnip2018-12-10_00-59-17.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-z))</span><br><span class="line"><span class="comment"># 逻辑回归的假设函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">h</span><span class="params">(mytheta,myX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sigmoid(np.dot(myX,mytheta)) <span class="comment"># m一维向量</span></span><br><span class="line"><span class="comment"># 逻辑回归的代价函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeCost</span><span class="params">(theta,X,y,lamb = <span class="number">0</span>)</span>:</span></span><br><span class="line">    h_theta = h(theta,X)</span><br><span class="line">    left_hand = np.mean(-y*np.log(h_theta)-(<span class="number">1</span>-y)*np.log(<span class="number">1</span>-h_theta))</span><br><span class="line">    right_hand = np.sum(np.square(theta[<span class="number">1</span>:]))*lamb/(<span class="number">2</span>*len(X))</span><br><span class="line">    <span class="keyword">return</span> left_hand+right_hand</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">costGradient</span><span class="params">(theta,X,y,lamb=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="comment">#逻辑回归的梯度函数</span></span><br><span class="line">    first = (<span class="number">1</span>/len(X))*X.T @ (h(theta,X)-y) <span class="comment"># (n+1)一维向量</span></span><br><span class="line">    <span class="comment"># (n+1)一维向量</span></span><br><span class="line">    reg = np.concatenate([np.array([<span class="number">0</span>]),(lamb/len(X))*theta[<span class="number">1</span>:]]) </span><br><span class="line">    <span class="keyword">return</span> first+reg</span><br></pre></td></tr></table></figure><p>在代价函数及其梯度的求解方法确定后，就可以选择python第三方科学计算库scipy中的优化方法经过一定次数的迭代获得使代价函数最低的参数向量。<br>当然也可以自己采用梯度下降法求解。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_vs_all</span><span class="params">(X,y,lamb,K)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    采用一对多策略利用逻辑回归分类</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X,特征矩阵，m*(n+1)，第一列为附加的0</span></span><br><span class="line"><span class="string">        y,真实分类向量，m一维向量</span></span><br><span class="line"><span class="string">        lamb，正则化用的lambda</span></span><br><span class="line"><span class="string">        K,分类总数</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        训练好的theta向量,K*(n+1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    all_theta = zeros((K,X.shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(K):</span><br><span class="line">        init_theta = np.zeros(X.shape[<span class="number">1</span>])</span><br><span class="line">        y_new = np.array([<span class="number">1</span> <span class="keyword">if</span> i==num <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> num <span class="keyword">in</span> y])</span><br><span class="line">        ret = minimize(fun=computeCost,x0=init_theta,args=(X,y_new,lamb),</span><br><span class="line">                method=<span class="string">'TNC'</span>,jac=costGradient,options=&#123;<span class="string">'maxiter'</span>:<span class="number">100</span>,<span class="string">'disp'</span>:<span class="keyword">True</span>&#125;)</span><br><span class="line">        all_theta[i,:] = ret.x</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> all_theta</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictOneVsAll</span><span class="params">(all_theta,X)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    估计手写数字样本数据X的识别结果</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        all_theta,训练好的参数向量</span></span><br><span class="line"><span class="string">        X，待识别的样本数据</span></span><br><span class="line"><span class="string">    返回识别结果向量</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># m*K，每一行向量代表该行对应样本取这个下标数字的可能性</span></span><br><span class="line">    h = sigmoid(X @ all_theta.T) </span><br><span class="line">    h_argmax = np.argmax(h,axis=<span class="number">1</span>) <span class="comment"># 选取可能性最大的下标，表示样本取数字为该下标的可能性最大</span></span><br><span class="line">    <span class="keyword">return</span> h_argmax</span><br></pre></td></tr></table></figure><h3 id="测试算法"><a href="#测试算法" class="headerlink" title="测试算法"></a>测试算法</h3><p>下面代码从样本数据集中随机抽取占比为0.67的数据作为训练数据集，剩余数据用作测试。采用sklearn库中classification_report方法打印算法的查准率p，查全率r和f1-分数（综合考虑p和r的因子）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">trainingProp = <span class="number">0.67</span></span><br><span class="line">trainLen = int(len(X)*trainingProp)</span><br><span class="line">trainIndices = random.sample(range(len(X)),trainLen)</span><br><span class="line"></span><br><span class="line">trainingX = np.array([X[i,:] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)) <span class="keyword">if</span> i <span class="keyword">in</span> trainIndices])</span><br><span class="line">testX = np.array([X[i,:] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> trainIndices])</span><br><span class="line">trainingy = np.array([y[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(y)) <span class="keyword">if</span> i <span class="keyword">in</span> trainIndices])</span><br><span class="line">testy = np.array([y[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(y)) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> trainIndices])</span><br><span class="line">print(<span class="string">"总样本数：%d\n训练样本数:%d,%d\n测试样本数%d,%d"</span>%(len(X),len(trainingX),len(trainingy),len(testX),len(testy)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">总样本数：1593</span><br><span class="line">训练样本数:1067,1067</span><br><span class="line">测试样本数526,526</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_theta = one_vs_all(trainingX,trainingy,<span class="number">0.1</span>,<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(all_theta,testX,realy)</span>:</span></span><br><span class="line">    predicty = predictOneVsAll(all_theta,testX)</span><br><span class="line">    print(classification_report(realy,predicty))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy(all_theta,testX,testy)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0       0.97      0.97      0.97        59</span><br><span class="line">           1       0.86      0.94      0.90        51</span><br><span class="line">           2       0.95      0.93      0.94        57</span><br><span class="line">           3       0.98      0.91      0.94        46</span><br><span class="line">           4       0.92      0.92      0.92        50</span><br><span class="line">           5       0.93      0.91      0.92        47</span><br><span class="line">           6       0.98      0.93      0.95        54</span><br><span class="line">           7       0.93      0.83      0.88        52</span><br><span class="line">           8       0.83      0.89      0.86        54</span><br><span class="line">           9       0.82      0.89      0.85        56</span><br><span class="line"></span><br><span class="line">   micro avg       0.91      0.91      0.91       526</span><br><span class="line">   macro avg       0.92      0.91      0.91       526</span><br><span class="line">weighted avg       0.92      0.91      0.91       526</span><br></pre></td></tr></table></figure><p>从上面可以看出，逻辑回归算法的查准率和查全率均在90%以上，这说明这种算法对于分类问题表现还不错</p><h2 id="采用神经网络BP算法识别"><a href="#采用神经网络BP算法识别" class="headerlink" title="采用神经网络BP算法识别"></a>采用神经网络BP算法识别</h2><p>采用三层神经网络，输入层包括256(16*16，不包括偏置1)个神经元，输出层包括10个神经元，隐层有25个(不包括偏置1)，如下图所示</p><p><img src="http://hjx-markdown-images.test.upcdn.net/2018/12/09/f6277d0a383ef5e9f581b400f3aa4de1.png" alt="Xnip2018-12-09_19-05-41.png"></p><h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征矩阵在前面已经准备好</span></span><br><span class="line">y_another = y    <span class="comment"># 存储原来用单个数字表示的y，</span></span><br><span class="line">y = np.array(y_old) <span class="comment"># y的每个行向量表示一个数字</span></span><br></pre></td></tr></table></figure><p>下面两个函数分别实现将矩阵扁平化为向量和从向量中抽取矩阵的功能</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处X已加偏置列</span></span><br><span class="line">inputLayerSize = len(X[<span class="number">0</span>])<span class="number">-1</span></span><br><span class="line">hiddenLayerSize = <span class="number">25</span></span><br><span class="line">outputLayerSize = <span class="number">10</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serialize</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    展开参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> np.r_[a.flatten(),b.flatten()]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deserialize</span><span class="params">(theta)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    从向量中提取theta1和theta2矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    t1 = theta[:(inputLayerSize+<span class="number">1</span>)*hiddenLayerSize].reshape(hiddenLayerSize,inputLayerSize+<span class="number">1</span>)</span><br><span class="line">    t2 = theta[(inputLayerSize+<span class="number">1</span>)*hiddenLayerSize:].reshape(outputLayerSize,hiddenLayerSize+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> t1,t2</span><br></pre></td></tr></table></figure><h4 id="前向反馈"><a href="#前向反馈" class="headerlink" title="前向反馈"></a>前向反馈</h4><p>在已知theta的情况下，通过前向反馈获得预测的各种分类可能性的向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_forward</span><span class="params">(theta,X)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    theta为训练好的序列化的theta参数</span></span><br><span class="line"><span class="string">    inputLayerSize为输入层size,s1</span></span><br><span class="line"><span class="string">    hiddenLayerSize为隐层size,s2</span></span><br><span class="line"><span class="string">    outputLayerSize为输出层size,s3</span></span><br><span class="line"><span class="string">    X为特征矩阵，m*(s1+1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># t1, s2*(s1+1)</span></span><br><span class="line">    <span class="comment"># t2, s3*(s2+1)</span></span><br><span class="line">    t1,t2 = deserialize(theta)</span><br><span class="line">    a1 = X</span><br><span class="line">    z2 = a1 @ t1.T     <span class="comment"># m*s2</span></span><br><span class="line">    a2 = np.insert(sigmoid(z2),<span class="number">0</span>,<span class="number">1</span>,axis = <span class="number">1</span>) <span class="comment">#m*(s2+1)</span></span><br><span class="line">    z3 = a2 @ t2.T     <span class="comment"># m*s3</span></span><br><span class="line">    a3 = sigmoid(z3)   <span class="comment"># m*s3</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a1,z2,a2,z3,a3</span><br></pre></td></tr></table></figure><h4 id="代价函数及其正则化"><a href="#代价函数及其正则化" class="headerlink" title="代价函数及其正则化"></a>代价函数及其正则化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(theta,X,y)</span>:</span></span><br><span class="line">    h = feed_forward(theta,X)[<span class="number">4</span>]</span><br><span class="line">    itemMat = -y*np.log(h)-(<span class="number">1</span>-y)*np.log(<span class="number">1</span>-h)</span><br><span class="line">    <span class="keyword">return</span> np.sum(itemMat)/len(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">regularized_cost</span><span class="params">(theta,X,y,lamb=<span class="number">1</span>)</span>:</span></span><br><span class="line">    t1,t2 = deserialize(theta)</span><br><span class="line">    reg = np.sum(t1[:,<span class="number">1</span>:]**<span class="number">2</span>)+np.sum(t2[:,<span class="number">1</span>:]**<span class="number">2</span>) <span class="comment"># 正则项</span></span><br><span class="line">    <span class="keyword">return</span> lamb/(<span class="number">2</span>*len(X))*reg + cost(theta,X,y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoidGrad</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sigmoid(z)*(<span class="number">1</span>-sigmoid(z))</span><br></pre></td></tr></table></figure><h4 id="神经网络梯度函数及其正则化"><a href="#神经网络梯度函数及其正则化" class="headerlink" title="神经网络梯度函数及其正则化"></a>神经网络梯度函数及其正则化</h4><p>Backpropagation反向传播<br><img src="http://hjx-markdown-images.test.upcdn.net/2018/12/09/3e3c3ed02f85a75a5612a914a7ef2244.png" alt="Xnip2018-12-09_21-02-49.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">costGradient</span><span class="params">(theta,X,y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    unregularized gradient</span></span><br><span class="line"><span class="string">    返回，所有theta的梯度</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    t1,t2 = deserialize(theta)</span><br><span class="line">    a1,z2,a2,z3,a3 = feed_forward(theta,X)</span><br><span class="line">    d3 = a3-y <span class="comment"># m*s3</span></span><br><span class="line">    <span class="comment"># theta2的第一列数据不予考虑</span></span><br><span class="line">    d2 = d3 @ t2[:,<span class="number">1</span>:] * sigmoidGrad(z2) <span class="comment"># m*(s2+1)</span></span><br><span class="line">    D2 = d3.T@a2              <span class="comment"># s3*(s2+1)</span></span><br><span class="line">    D1 = d2.T@a1              <span class="comment"># s2*(s1+1)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/len(X)*serialize(D1,D2)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">regularizedGrad</span><span class="params">(theta,X,y,l=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    正则化的梯度</span></span><br><span class="line"><span class="string">    返回，所有theta的梯度</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># D1 and t1, s2*(s1+1);D2 and t2, s3*(s2+1)</span></span><br><span class="line">    D1,D2 = deserialize(costGradient(theta,X,y))</span><br><span class="line">    t1,t2 = deserialize(theta)</span><br><span class="line">    t1[:,<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    t2[:,<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    reg_D1 = D1 + (l / len(X)) * t1</span><br><span class="line">    reg_D2 = D2 + (l / len(X)) * t2</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> serialize(D1,D2)</span><br></pre></td></tr></table></figure><h4 id="梯度检测"><a href="#梯度检测" class="headerlink" title="梯度检测"></a>梯度检测</h4><p>因为反向传播算法代价函数和梯度函数代码编写过程中可能存在bug，故使用数值计算梯度与反向传播算法计算的梯度进行比较，以验证反向传播算法代价函数和梯度函数代码的正确性。不过这个函数运行起来超级慢，这里只贴代码，不展示运行结果了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientCheck</span><span class="params">(theta,X,y,e)</span>:</span></span><br><span class="line">    numericGrad = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(theta)):</span><br><span class="line">        plus = theta.copy()</span><br><span class="line">        minus = theta.copy()</span><br><span class="line">        plus[i] += e</span><br><span class="line">        minus[i] += e</span><br><span class="line">        grad_i = (regularized_cost(plus,X,y)-regularized_cost(minus,X,y))/(<span class="number">2</span>*e)</span><br><span class="line">        numericGrad.append(grad_i)</span><br><span class="line">    </span><br><span class="line">    numericGrad = np.array(numericGrad)</span><br><span class="line">    analyticGrad = regularizedGrad(theta, X, y)</span><br><span class="line">    diff = np.linalg.norm(numericGrad - analyticGrad) / np.linalg.norm(numericGrad + analyticGrad)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'If your backpropagation implementation is correct,\nthe relative difference will \</span></span><br><span class="line"><span class="string">          be smaller than 10e-9 (assume epsilon=0.0001).\nRelative Difference: &#123;&#125;\n'</span>.format(diff))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">initTheta = randomInit((inputLayerSize+<span class="number">1</span>)*hiddenLayerSize+(hiddenLayerSize+<span class="number">1</span>)*outputLayerSize)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradientCheck(initTheta,X,y,<span class="number">0.0001</span>)</span><br></pre></td></tr></table></figure><h3 id="测试算法-1"><a href="#测试算法-1" class="headerlink" title="测试算法"></a>测试算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomInit</span><span class="params">(size)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    随机初始化size尺寸的矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> np.random.uniform(<span class="number">-0.12</span>, <span class="number">0.12</span>, size)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_training</span><span class="params">(X,y)</span>:</span></span><br><span class="line">    init_theta = randomInit((inputLayerSize+<span class="number">1</span>)*hiddenLayerSize+(hiddenLayerSize+<span class="number">1</span>)*outputLayerSize)</span><br><span class="line">    res = minimize(fun=regularized_cost,</span><br><span class="line">                  x0=init_theta,</span><br><span class="line">                  args=(X,y),</span><br><span class="line">                  method=<span class="string">'TNC'</span>,</span><br><span class="line">                  jac=regularizedGrad,</span><br><span class="line">                  options=&#123;<span class="string">"maxiter"</span>:<span class="number">500</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trainingy = np.array([y[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(y)) <span class="keyword">if</span> i <span class="keyword">in</span> trainIndices])</span><br><span class="line">res = nn_training(trainingX,trainingy)</span><br><span class="line">res</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">    fun: 0.9114611628633325</span><br><span class="line">    jac: array([ 2.96364632e-03, -1.62797300e-04,  2.89863853e-04, ...,</span><br><span class="line">       9.59179838e-04,  1.10862199e-06, -4.78441900e-03])</span><br><span class="line">message: &apos;Converged (|f_n-f_(n-1)| ~= 0)&apos;</span><br><span class="line">   nfev: 163</span><br><span class="line">    nit: 11</span><br><span class="line"> status: 1</span><br><span class="line">success: True</span><br><span class="line">      x: array([ 0.        ,  0.44110449,  0.17106004, ..., -0.34636188,</span><br><span class="line">       0.6146963 , -0.88931194])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracyBP</span><span class="params">(theta,X,y)</span>:</span></span><br><span class="line">    h = feed_forward(res.x,X)[<span class="number">4</span>]</span><br><span class="line">    y_pred = np.argmax(h,axis=<span class="number">1</span>)</span><br><span class="line">    print(classification_report(y,y_pred))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">testy = np.array([y_another[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(y_another)) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> trainIndices])</span><br><span class="line">accuracyBP(res.x,testX,testy)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0       0.93      0.98      0.95        53</span><br><span class="line">           1       0.89      0.83      0.86        58</span><br><span class="line">           2       0.96      0.90      0.93        50</span><br><span class="line">           3       0.84      0.88      0.86        52</span><br><span class="line">           4       0.95      0.85      0.90        48</span><br><span class="line">           5       0.93      0.90      0.91        48</span><br><span class="line">           6       0.93      0.95      0.94        58</span><br><span class="line">           7       0.98      0.89      0.93        54</span><br><span class="line">           8       0.74      0.96      0.83        52</span><br><span class="line">           9       0.86      0.79      0.82        53</span><br><span class="line"></span><br><span class="line">   micro avg       0.89      0.89      0.89       526</span><br><span class="line">   macro avg       0.90      0.89      0.89       526</span><br><span class="line">weighted avg       0.90      0.89      0.89       526</span><br></pre></td></tr></table></figure><p>从上面可以看出,查准率约为0.9，查全率约为0.89，比逻辑回归算法稍有不如。但是实际上神经网络的可调性很强，适用范围也更大。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;逻辑回归与神经网络实现手写数字识别&quot;&gt;&lt;a href=&quot;#逻辑回归与神经网络实现手写数字识别&quot; class=&quot;headerlink&quot; title=&quot;逻辑回归与神经网络实现手写数字识别&quot;&gt;&lt;/a&gt;逻辑回归与神经网络实现手写数字识别&lt;/h1&gt;&lt;p&gt;本作业是采用Logi
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>k近邻算法实战</title>
    <link href="hjx051013.github.io/2018/12/08/k-nearest-neighbors/"/>
    <id>hjx051013.github.io/2018/12/08/k-nearest-neighbors/</id>
    <published>2018-12-08T08:36:48.000Z</published>
    <updated>2018-12-08T08:45:43.030Z</updated>
    
    <content type="html"><![CDATA[<h2 id="k-近邻算法概述"><a href="#k-近邻算法概述" class="headerlink" title="k-近邻算法概述"></a>k-近邻算法概述</h2><p>k-近邻算法的工作原理是：</p><blockquote><p>存在一个样本数据集，也即训练集，其中的每个样本数据对存在一个对应标签，也即样本的分类。当输入没有标签的新样本后，我们通过将新数据的每个特征与样本数据集中对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。通常做法是提取特征向量最相近的前k个数据，取其中出现次数最多的分类，作为输入新样本的分类标签</p></blockquote><p>用一个简单的例子来描述一下k-近邻算法的一般流程</p><h3 id="准备用pyhton导入数据"><a href="#准备用pyhton导入数据" class="headerlink" title="准备用pyhton导入数据"></a>准备用pyhton导入数据</h3><p>创建一个名为kNN的Python模块，在kNN.py中增加下列代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    以四个点(1,1.1),(1,1),(0,0),(0,0.1)为例，其标签分分别是'A','B','C','D'</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    group = array([[<span class="number">1.0</span>,<span class="number">1.1</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">'A'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group,labels</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">group,labels = createDataSet()</span><br><span class="line">print(group)</span><br><span class="line">print(labels)</span><br></pre></td></tr></table></figure><pre><code>[[1.  1.1] [1.  1. ] [0.  0. ] [0.  0.1]][&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;]</code></pre><h3 id="实施kNN算法"><a href="#实施kNN算法" class="headerlink" title="实施kNN算法"></a>实施kNN算法</h3><p>kNN算法的伪代码如下:</p><ol><li>计算已知类别数据集中的点与当前点之间的距离</li><li>按照距离递增次序排序</li><li>选取与当前点距离最小的k个点</li><li>确定当前k个点所在类别的出现频率</li><li>返回前k个点出现频率最高的类别作为当前点的预测分类</li></ol><p>pyhton函数classify0如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX,dataSet,labels,k)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    输入参数为inX（待分类的数据特征向量），dataSet(训练数据多个特征向量构成的矩阵)，labels(训练数据特征向量对应的标签向量)，k（k值）</span></span><br><span class="line"><span class="string">    返回为inX的预估的标签</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    diffMat = tile(inX,(dataSetSize,<span class="number">1</span>))-dataSet  <span class="comment"># 新数据与训练数据作差</span></span><br><span class="line">    sqDiffMat = diffMat**<span class="number">2</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis = <span class="number">1</span>)  <span class="comment"># 对差平方矩阵进行每行求和</span></span><br><span class="line">    distances = sqDistances**<span class="number">0.5</span>       <span class="comment"># 开平方根，为新数据向量与训练数据向量的距离</span></span><br><span class="line">    sortedDistanceIndices = distances.argsort()  <span class="comment">#按照距离从小到大排序，返回下标向量</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment"># 统计前k个点对应的标签，插入classCount字典中</span></span><br><span class="line">        voteIlabel = labels[sortedDistanceIndices[i]]</span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>)+<span class="number">1</span></span><br><span class="line">    sortedClassCount = sorted(classCount.items(),key = operator.itemgetter(<span class="number">1</span>),reverse=<span class="keyword">True</span>)  <span class="comment"># 利用字典中的value值进行从大到小的排序</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>上述程序使用欧式距离公式，计算两个向量$xA$和$xB$之间的距离:</p><script type="math/tex; mode=display">d=\sqrt {(xA_0-xB_0)^2+(xA_1-xB_1)^2}</script><p>对数据点[0,0]进行分类，它实际上属于B类（画个图就知道了）。运行下列代码，确实是B</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classify0([<span class="number">0</span>,<span class="number">0</span>],group,labels,<span class="number">3</span>)</span><br></pre></td></tr></table></figure><pre><code>&#39;B&#39;</code></pre><h2 id="使用k近邻算法改进约会网站的配对效果"><a href="#使用k近邻算法改进约会网站的配对效果" class="headerlink" title="使用k近邻算法改进约会网站的配对效果"></a>使用k近邻算法改进约会网站的配对效果</h2><p>海伦将约会网站上的约会对象分为三种人，</p><ul><li>不喜欢的人</li><li>魅力一般的人</li><li>极具魅力的人<br>我们需要根据已有数据采用k近邻算法，来帮助海伦将约会对象划分到确切的分类中。<h3 id="大致步骤"><a href="#大致步骤" class="headerlink" title="大致步骤"></a>大致步骤</h3></li></ul><ol><li>收集数据：获得海伦给定的对象数据特征和分类标签</li><li>准备数据：使用pyhton解析文本文件</li><li>分析数据：使用matplotlib画二维扩散图</li><li>训练算法：k近邻算法用不着训练数据</li><li>测试算法：使用海伦提供的部分数据作为测试样本</li><li>使用算法：产生简单的命令行程序，使得海伦通过输入一些数据来判断对方是否为自己喜欢的类型<h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3>下载海伦提供的数据。查看数据，可以看出，每个样本数据占据一行，每一行有四列，前三列是3种特征：</li></ol><ul><li>每年获得的飞行常客里程数</li><li>玩视频游戏所消耗的时间百分比</li><li>每周消耗的冰淇淋公升数<br>第四列是海伦给这个样本定义的标签，有’largeDoses’,’smallDoses’,’didntLike’</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://github.com/pbharrin/machinelearninginaction/raw/master/Ch02/datingTestSet.txt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cat datingTestSet.txt</span><br></pre></td></tr></table></figure><p>在kNN.py中创建名为file2matrix的函数，以此来处理输入格式问题。file2matrix输入文件名，返回特征数据矩阵和标签向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    根据文件名读取数据，返回特征数据矩阵和标签向量</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dic = &#123;<span class="string">'didntLike'</span>:<span class="number">1</span>,<span class="string">'smallDoses'</span>:<span class="number">2</span>,<span class="string">'largeDoses'</span>:<span class="number">3</span>&#125;</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    arrayOLines = fr.readlines() <span class="comment"># 以列表形式存储文本数据，列表元素为字符串</span></span><br><span class="line">    numberOfLines = len(arrayOLines)</span><br><span class="line">    returnMat = np.zeros((numberOfLines,<span class="number">3</span>)) <span class="comment"># 返回的特征数据矩阵</span></span><br><span class="line">    classLabelVector = []     <span class="comment"># 返回的标签向量</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> arrayOLines:</span><br><span class="line">        line = line.strip() <span class="comment"># remove leading and trailing whitespace</span></span><br><span class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        returnMat[index,:] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">        classLabelVector.append(dic[listFromLine[<span class="number">-1</span>]])</span><br><span class="line">        index+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> returnMat,classLabelVector</span><br></pre></td></tr></table></figure><p>在执行上述代码后，可调用file2matrix函数将文件’datingTestSet.txt’导入到内存中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datingDataMat,datingLabels = file2matrix(<span class="string">'datingTestSet.txt'</span>)</span><br></pre></td></tr></table></figure><h3 id="分析数据"><a href="#分析数据" class="headerlink" title="分析数据"></a>分析数据</h3><p>利用Matplotlib制作原始数据的散点图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">15</span>))</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">311</span>) <span class="comment"># 设定figure里面有多少个子图和子图位置</span></span><br><span class="line">ax1.scatter(datingDataMat[:,<span class="number">0</span>],datingDataMat[:,<span class="number">1</span>],<span class="number">15.0</span>*np.array(datingLabels),<span class="number">15.0</span>*np.array(datingLabels))</span><br><span class="line">ax1.set_title(<span class="string">"Charisma scattering plot"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"Flying milages"</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">"Time percentage of playing games"</span>)</span><br><span class="line"></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">312</span>) <span class="comment"># 设定figure里面有多少个子图和子图位置</span></span><br><span class="line">ax2.scatter(datingDataMat[:,<span class="number">0</span>],datingDataMat[:,<span class="number">2</span>],<span class="number">15.0</span>*np.array(datingLabels),<span class="number">15.0</span>*np.array(datingLabels))</span><br><span class="line">ax2.set_title(<span class="string">"Charisma scattering plot"</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">"Flying milages"</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">"Weekly consumption of ice cream/liter"</span>)</span><br><span class="line">ax3 = fig.add_subplot(<span class="number">313</span>) <span class="comment"># 设定figure里面有多少个子图和子图位置</span></span><br><span class="line">ax3.scatter(datingDataMat[:,<span class="number">1</span>],datingDataMat[:,<span class="number">2</span>],<span class="number">15.0</span>*np.array(datingLabels),<span class="number">15.0</span>*np.array(datingLabels))</span><br><span class="line">ax3.set_title(<span class="string">'Charisma scattering plot'</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">'Time percentage of playing games'</span>)</span><br><span class="line">ax3.set_ylabel(<span class="string">'Weekly consumption of ice cream/liter'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://hjx-markdown-images.test.upcdn.net/2018/12/08/cebf487775d2ade34214ae98aac63c00.png" alt="K-nearest neighbor algorithm_15_0.png"></p><h3 id="准备数据：归一化数值"><a href="#准备数据：归一化数值" class="headerlink" title="准备数据：归一化数值"></a>准备数据：归一化数值</h3><p>显然，因为飞行常客里程数远远大于玩视频游戏时间占比与每周消费冰淇淋公升数，而海伦认为这三种特征是同样重要的，所以需要对特征树进行归一化处理。通过下面公式将任意范围的特征值转为0到1区间的值：</p><script type="math/tex; mode=display">newValue = (oldValue-min)/(max-min)</script><p>下面是归一化特征值的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">autoNorm</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    minVals = dataSet.min(<span class="number">0</span>) <span class="comment"># 对每一列求最小值，得到一个有三个元素的向量</span></span><br><span class="line">    maxVals = dataSet.max(<span class="number">0</span>) <span class="comment"># 对每一列求最大值，得到一个有三个元素的向量</span></span><br><span class="line">    ranges = maxVals-minVals <span class="comment"># 获得每一列最大值与最小值的差值</span></span><br><span class="line">    normDataSet = np.zeros(np.shape(dataSet))</span><br><span class="line">    m = dataSet.shape[<span class="number">0</span>]  <span class="comment">#数据集有多少行</span></span><br><span class="line">    normDataSet = dataSet - np.tile(minVals,(m,<span class="number">1</span>))</span><br><span class="line">    normDataSet = normDataSet/tile(ranges,(m,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> normDataSet,ranges,minVals</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">normMat,ranges,minVals = autoNorm(datingDataMat)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(normMat[<span class="number">0</span>:<span class="number">5</span>])</span><br><span class="line">print(ranges)</span><br><span class="line">print(minVals)</span><br></pre></td></tr></table></figure><pre><code>[[0.44832535 0.39805139 0.56233353] [0.15873259 0.34195467 0.98724416] [0.28542943 0.06892523 0.47449629] [0.82320073 0.62848007 0.25248929] [0.42010233 0.07982027 0.0785783 ]][9.1273000e+04 2.0919349e+01 1.6943610e+00][0.       0.       0.001156]</code></pre><h3 id="测试算法"><a href="#测试算法" class="headerlink" title="测试算法"></a>测试算法</h3><p>为了测试分类器效果，我们定义了一个datingClassTest函数，该函数是自包含的，选用海伦提供数据的前10%作为测试数据，后90%作为训练集数据。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">datingClassTest</span><span class="params">()</span>:</span></span><br><span class="line">    hoRatio = <span class="number">0.10</span></span><br><span class="line">    datingDataMat,datingDataLabels = file2matrix(<span class="string">'datingTestSet.txt'</span>)</span><br><span class="line">    normMat,ranges,minVals = autoNorm(datingDataMat)</span><br><span class="line">    m = normMat.shape[<span class="number">0</span>]</span><br><span class="line">    numTestVecs = int(m*hoRatio)</span><br><span class="line">    errCoount = <span class="number">0</span>    <span class="comment"># 预测错误向量个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTestVecs):</span><br><span class="line">        <span class="comment"># 遍历所有的测试向量</span></span><br><span class="line">        classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># print("the classifier came back with:%d, the real answer is:%d"%(classifierResult,datingLabels[i]))</span></span><br><span class="line">        <span class="keyword">if</span> classifierResult!=datingLabels[i]:</span><br><span class="line">            errCoount += <span class="number">1</span></span><br><span class="line">    print(<span class="string">"the total error rate is: %f"</span>%(errCoount/float(numTestVecs)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datingClassTest()</span><br></pre></td></tr></table></figure><pre><code>the total error rate is: 0.050000</code></pre><h3 id="使用算法：构建完整系统"><a href="#使用算法：构建完整系统" class="headerlink" title="使用算法：构建完整系统"></a>使用算法：构建完整系统</h3><p>设计一个函数，能够询问约会对象的特征数据，然后给出预估的分类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyPerson</span><span class="params">()</span>:</span></span><br><span class="line">    resultList = [<span class="string">'not at all'</span>,<span class="string">'in small doses'</span>,<span class="string">'in large doses'</span>]</span><br><span class="line">    percentageTats = float(input(<span class="string">"percentage of time spent in playing video games?"</span>))</span><br><span class="line">    ffMiles = float(input(<span class="string">"frequent flier miles earned each year?"</span>))</span><br><span class="line">    icecream = float(input(<span class="string">"liters of ice cream cosumed each week?"</span>))</span><br><span class="line">    datingDataMat,datingLabels = file2matrix(<span class="string">'datingTestSet.txt'</span>)</span><br><span class="line">    normMat,ranges,minVals = autoNorm(datingDataMat)</span><br><span class="line">    inArr = array([ffMiles,percentageTats,icecream])</span><br><span class="line">    classifierResult = classify0((inArr-minVals)/ranges,normMat,datingLabels,<span class="number">3</span>)</span><br><span class="line">    print(<span class="string">"You will propably like this person %s"</span>%resultList[int(classifierResult)<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classifyPerson()</span><br></pre></td></tr></table></figure><pre><code>percentage of time spent in playing video games?10frequent flier miles earned each year?10000liters of ice cream cosumed each week?0.5You will propably like this person in small doses</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">以上让人觉得十分容易看懂，事实上k-近邻算法本身就是一个非常简单的算法。接下来看看，如何在二进制存储的图像数据上使用kNN。</span><br></pre></td></tr></table></figure><h2 id="手写识别数字"><a href="#手写识别数字" class="headerlink" title="手写识别数字"></a>手写识别数字</h2><p>需要识别的数字已经通过软件转成宽高32x32的黑白图像，这里直接使用图像的文本格式</p><h3 id="准备数据-将图像转化为测试向量"><a href="#准备数据-将图像转化为测试向量" class="headerlink" title="准备数据:将图像转化为测试向量"></a>准备数据:将图像转化为测试向量</h3><p>执行以下指令，获取并解压数据文件，文件夹中包含两个文件夹trainingDigits和testDigits，分别对应训练数据和测试数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!wget https://github.com/pbharrin/machinelearninginaction/raw/master/Ch02/digits.zip</span><br><span class="line">!unzip digits.zip</span><br></pre></td></tr></table></figure><p>首先编写一个函数根据手写数字的文件名读入数据将32x32的矩阵转成一个1x1024的向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img2vector</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数为一个图像文本文件的名字</span></span><br><span class="line"><span class="string">    返回1x1024的向量</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    returnVect = zeros((<span class="number">1</span>,<span class="number">1024</span>))</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):</span><br><span class="line">        lineStr = fr.readline()</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">32</span>):</span><br><span class="line">            returnVect[<span class="number">0</span>,<span class="number">32</span>*i+j] = int(lineStr[j])</span><br><span class="line">    <span class="keyword">return</span> returnVect</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(img2vector(<span class="string">"testDigits/0_0.txt"</span>))</span><br></pre></td></tr></table></figure><pre><code>[[0. 0. 0. ... 0. 0. 0.]]</code></pre><h3 id="测试算法：使用k近邻算法实现手写数字的识别"><a href="#测试算法：使用k近邻算法实现手写数字的识别" class="headerlink" title="测试算法：使用k近邻算法实现手写数字的识别"></a>测试算法：使用k近邻算法实现手写数字的识别</h3><p>下面实现一个函数classifyDigitTest，输入数字图像转化来的1x1024向量，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyDigitTest</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 首先列出trainingDigits下的所有文件名，文件数为m</span></span><br><span class="line">    <span class="comment"># 根据trainingDigits下的所有文件构造m*1024的特征矩阵和，m*1的标签向量</span></span><br><span class="line">    <span class="comment"># 列出testDigits下的所有文件名，文件数为testN</span></span><br><span class="line">    <span class="comment"># 对testDigits文件夹下的进行循环判断，以获得算法的手写数字识别错误率</span></span><br><span class="line">        <span class="comment"># 调用classify0获得digitVect的结果标签</span></span><br><span class="line">        <span class="comment"># 有文件名名可获得digitVect的真实标签，对比，若不等errorCount++</span></span><br><span class="line">    <span class="comment"># 获得手写识别错误率</span></span><br><span class="line">    trainingFiles = listdir(<span class="string">'trainingDigits'</span>)</span><br><span class="line">    m = len(trainingFiles)</span><br><span class="line">    trainingDataMat = np.zeros((m,<span class="number">1024</span>))</span><br><span class="line">    trainingLabelsVect = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        trainingFileName = trainingFiles[i]</span><br><span class="line">        realLabel = int(trainingFileName.split(<span class="string">'.'</span>)[<span class="number">0</span>].split(<span class="string">'_'</span>)[<span class="number">0</span>])</span><br><span class="line">        trainingDataMat[i,:] = img2vector(<span class="string">'trainingDigits/'</span>+trainingFileName) <span class="comment"># 构造特征矩阵第i行</span></span><br><span class="line">        trainingLabelsVect.append(realLabel)</span><br><span class="line">    testFiles = listdir(<span class="string">'testDigits'</span>)</span><br><span class="line">    testN = len(testFiles)</span><br><span class="line">    errCount = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(testN):</span><br><span class="line">        testFileName = testFiles[i]</span><br><span class="line">        testDataVect = img2vector(<span class="string">'testDigits/'</span>+testFileName)  <span class="comment"># 获得测试文件的特征向量</span></span><br><span class="line">        testRealLabel = int(testFileName.split(<span class="string">'.'</span>)[<span class="number">0</span>].split(<span class="string">'_'</span>)[<span class="number">0</span>]) <span class="comment"># 获得测试文件名中的数据标签</span></span><br><span class="line">        testLabel = classify0(testDataVect,trainingDataMat,trainingLabelsVect,<span class="number">3</span>) <span class="comment"># 采用k近邻算法估计测试文件的标签</span></span><br><span class="line">        <span class="comment"># print("test data file:%s,predicted label:%s,real label:%s"%(testFileName,testLabel,testRealLabel))</span></span><br><span class="line">        <span class="keyword">if</span> testLabel!=testRealLabel:</span><br><span class="line">            errCount+=<span class="number">1</span></span><br><span class="line">    print(<span class="string">"model accuracy:%.5f"</span>%(<span class="number">1</span>-errCount/testN))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start = tiem</span><br><span class="line">classifyDigitTest()</span><br></pre></td></tr></table></figure><pre><code> model accuracy:0.99</code></pre><p>实际上，使用这个算法效率太低，而且训练集数据越大，耗时越多，我们需要为每个测试向量做m次距离计算(m是训练集样本数)，每个距离计算包括1024个维度的浮点数计算。k近邻算法没有训练出一个模型出来，而是直接将输入与所有的训练数据一一比较。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;k-近邻算法概述&quot;&gt;&lt;a href=&quot;#k-近邻算法概述&quot; class=&quot;headerlink&quot; title=&quot;k-近邻算法概述&quot;&gt;&lt;/a&gt;k-近邻算法概述&lt;/h2&gt;&lt;p&gt;k-近邻算法的工作原理是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;存在一个样本数据集，也即
      
    
    </summary>
    
      <category term="机器学习实战" scheme="hjx051013.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="k近邻算法" scheme="hjx051013.github.io/tags/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="机器学习" scheme="hjx051013.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>python传递参数究竟是值传递还是引用传递</title>
    <link href="hjx051013.github.io/2018/12/08/python-passParam/"/>
    <id>hjx051013.github.io/2018/12/08/python-passParam/</id>
    <published>2018-12-08T07:57:27.000Z</published>
    <updated>2018-12-08T08:32:28.238Z</updated>
    
    <content type="html"><![CDATA[<p>首先还是应该科普下函数参数传递机制，传值和传引用是什么意思？</p><p>　　 函数参数传递机制问题在本质上是调用函数（过程）和被调用函数（过程）在调用发生时进行通信的方法问题。基本的参数传递机制有两种：值传递和引用传递。</p><p>　　值传递（passl-by-value）过程中，被调函数的形式参数作为被调函数的局部变量处理，即在堆栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。</p><p>　　引用传递(pass-by-reference)过程中，被调函数的形式参数虽然也作为局部变量在堆栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过堆栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。</p><p>那么,python究竟是怎样的呢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os.path  </span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(c)</span>:</span></span><br><span class="line">    print(<span class="string">"test before "</span>)</span><br><span class="line">    print(id(c))</span><br><span class="line">    c+=<span class="number">2</span></span><br><span class="line">    print(<span class="string">"test after"</span>)</span><br><span class="line">    print(id(c))</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printIt</span><span class="params">(t)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(t)):</span><br><span class="line">        print(t[i])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    a=<span class="number">2</span></span><br><span class="line">    print(<span class="string">"main before invoke test"</span>)</span><br><span class="line">    print(id(a))</span><br><span class="line">    n=test(a)</span><br><span class="line">    print(<span class="string">"main afterf invoke test"</span>)</span><br><span class="line">    print(a)</span><br><span class="line">    print(id(a))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">main before invoke test</span><br><span class="line">test before </span><br><span class="line">test after +</span><br><span class="line">main afterf invoke test</span><br><span class="line">39601564</span><br></pre></td></tr></table></figure><p>从上可以看出，传参数进去时，传得是引用，因为参数地址没变。但是对传入参数赋值后，其地址就发生了变化。基于这个例子画了个图表示</p><p><img src="http://hjx-markdown-images.test.upcdn.net/2018/12/08/5c76d4645b932a417ded382c0ec1e38d.jpg" alt="849009-20160314194651474-1039918478.jpg"></p><p>那么python传递参数传得真是引用，然后传参的值在被调函数内被修改也不影响主调函数的实参变量的值？有传入对象可变与不可变的说法，<br>对于可变对象，在被调函数内修改传参会影响主调函数的实参变量，对于不可变对象修改传参则不会改变主调函数实参的值，因为修改不可变对象<br>实际上是另开辟内存重新赋值并让传参变量指向该内存。看下面例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os.path  </span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(list2)</span>:</span></span><br><span class="line">    print(<span class="string">"test before "</span>)</span><br><span class="line">    print(id(list2))</span><br><span class="line">    list2[<span class="number">1</span>]=<span class="number">30</span></span><br><span class="line">    print(<span class="string">"test after +"</span>)</span><br><span class="line">    print(id(list2))</span><br><span class="line">    <span class="keyword">return</span> list2</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printIt</span><span class="params">(t)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(t)):</span><br><span class="line">        print(t[i])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    list1=[<span class="string">"loleina"</span>,<span class="number">25</span>,<span class="string">'female'</span>]</span><br><span class="line">    print(<span class="string">"main before invoke test"</span>)</span><br><span class="line">    print(id(list1))</span><br><span class="line">    list3=test(list1)</span><br><span class="line">    print(<span class="string">"main afterf invoke test"</span>)</span><br><span class="line">    print(list1)</span><br><span class="line">    print(id(list1))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">main before invoke test</span><br><span class="line">4485568072</span><br><span class="line">test before </span><br><span class="line">4485568072</span><br><span class="line">test after +</span><br><span class="line">4485568072</span><br><span class="line">main afterf invoke test</span><br><span class="line">[&apos;loleina&apos;, 30, &apos;female&apos;]</span><br><span class="line">4485568072</span><br></pre></td></tr></table></figure><p>结论：python不允许程序员选择采用传值还是传引用。Python参数传递采用的肯定是“传对象引用”的方式。这种方式相当于传值和传引用的一种综合。如果函数收到的是一个可变对象（比如<strong>字典或者列表</strong>）的引用，就能修改对象的原始值－－相当于通过“传引用”来传递对象。如果函数收到的是一个不可变对象（比如<strong>数字、字符或者元组</strong>）的引用，就不能直接修改原始对象－－相当于通过“传值’来传递对象。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;首先还是应该科普下函数参数传递机制，传值和传引用是什么意思？&lt;/p&gt;
&lt;p&gt;　　 函数参数传递机制问题在本质上是调用函数（过程）和被调用函数（过程）在调用发生时进行通信的方法问题。基本的参数传递机制有两种：值传递和引用传递。&lt;/p&gt;
&lt;p&gt;　　值传递（passl-by-va
      
    
    </summary>
    
      <category term="python" scheme="hjx051013.github.io/categories/python/"/>
    
    
      <category term="python语言" scheme="hjx051013.github.io/tags/python%E8%AF%AD%E8%A8%80/"/>
    
  </entry>
  
  <entry>
    <title>python在命令行下查看模块，函数的用法</title>
    <link href="hjx051013.github.io/2018/11/29/python-help/"/>
    <id>hjx051013.github.io/2018/11/29/python-help/</id>
    <published>2018-11-29T15:07:06.000Z</published>
    <updated>2018-12-07T04:20:47.635Z</updated>
    
    <content type="html"><![CDATA[<p>python的一个优势是有着大量自带和在线的模块(module)资源，可以提供丰富的功能，在使用这些模块的时候，如果每次都去网站找在线文档会过于耗费时间，结果也不一定准确。因此这里介绍下python自带的查看帮助功能，可以在编程时不中断地迅速找到所需模块和函数的使用方法。</p><h3 id="通用帮助函数help"><a href="#通用帮助函数help" class="headerlink" title="通用帮助函数help()"></a>通用帮助函数help()</h3><p>在python命令行中键入help(),可以看到：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; help()</span><br><span class="line"></span><br><span class="line">Welcome to Python 3.5&apos;s help utility!</span><br><span class="line"></span><br><span class="line">If this is your first time using Python, you should definitely check out</span><br><span class="line">the tutorial on the Internet at http://docs.python.org/3.5/tutorial/.</span><br><span class="line"></span><br><span class="line">Enter the name of any module, keyword, or topic to get help on writing</span><br><span class="line">Python programs and using Python modules.  To quit this help utility and</span><br><span class="line">return to the interpreter, just type &quot;quit&quot;.</span><br><span class="line"></span><br><span class="line">To get a list of available modules, keywords, symbols, or topics, type</span><br><span class="line">&quot;modules&quot;, &quot;keywords&quot;, &quot;symbols&quot;, or &quot;topics&quot;.  Each module also comes</span><br><span class="line">with a one-line summary of what it does; to list the modules whose name</span><br><span class="line">or summary contain a given string such as &quot;spam&quot;, type &quot;modules spam&quot;.</span><br><span class="line"></span><br><span class="line">help&gt;</span><br></pre></td></tr></table></figure></p><p>进入help帮助文档界面，根据屏幕提示可以继续键入相应关键词进行查询，继续键入modules可以列出当前所有安装的模块：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">help&gt; modules</span><br><span class="line"></span><br><span class="line">Please wait a moment while I gather a list of all available modules...</span><br><span class="line"></span><br><span class="line">AutoComplete        _pyio               filecmp             pyscreeze</span><br><span class="line">AutoCompleteWindow  _random             fileinput           pytweening</span><br><span class="line">......        </span><br><span class="line"></span><br><span class="line">Enter any module name to get more help.  Or, type &quot;modules spam&quot; to search</span><br><span class="line">for modules whose name or summary contain the string &quot;spam&quot;.</span><br></pre></td></tr></table></figure></p><blockquote><p>可以继续键入相应的模块名称得到该模块的帮助信息。<br>这是python的通用的查询帮助，可以查到几乎所有的帮助文档，但我们很多时候不需要这样层级式地向下查询，接下来会介绍如何直接查询特定的模块和函数帮助信息。</p></blockquote><h3 id="模块帮助查询"><a href="#模块帮助查询" class="headerlink" title="模块帮助查询"></a>模块帮助查询</h3><h4 id="查看-py结尾的普通模块help-module-name"><a href="#查看-py结尾的普通模块help-module-name" class="headerlink" title="查看.py结尾的普通模块help(module_name)"></a>查看.py结尾的普通模块help(module_name)</h4><p>例如要查询math模块的使用方法，可以如下操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import math</span><br><span class="line">&gt;&gt;&gt; help(math)</span><br><span class="line">Help on built-in module math:</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">    math</span><br><span class="line"></span><br><span class="line">DESCRIPTION</span><br><span class="line">    This module is always available.  It provides access to the</span><br><span class="line">    mathematical functions defined by the C standard.</span><br><span class="line"></span><br><span class="line">FUNCTIONS</span><br><span class="line">    acos(...)</span><br><span class="line">        acos(x)</span><br><span class="line"></span><br><span class="line">        Return the arc cosine (measured in radians) of x.</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>使用help(module_name)时首先需要import该模块，有些教程中不进行导入而在模块名中加入引号help(‘module_name’)，这种方法可能会带来问题，大家可以用math模块测试，建议使用先导入再使用help()函数查询。</p><h4 id="查看内建模块sys-bultin-modulenames"><a href="#查看内建模块sys-bultin-modulenames" class="headerlink" title="查看内建模块sys.bultin_modulenames"></a>查看内建模块sys.bultin_modulenames</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import sys</span><br><span class="line">&gt;&gt;&gt; sys.builtin_module_names</span><br><span class="line">(&apos;_ast&apos;, &apos;_bisect&apos;, &apos;_codecs&apos;, &apos;_codecs_cn&apos;, &apos;_codecs_hk&apos;, ... &apos;zlib&apos;)</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><p>需要导入sys模块。这里列举的一般是自带的使用C/C++编译链接的模块</p></blockquote><h3 id="查询函数信息"><a href="#查询函数信息" class="headerlink" title="查询函数信息"></a>查询函数信息</h3><h4 id="查看模块下所有函数dir-module-name"><a href="#查看模块下所有函数dir-module-name" class="headerlink" title="查看模块下所有函数dir(module_name)"></a>查看模块下所有函数dir(module_name)</h4><p>如我们需要列举出math模块下所有的函数名称<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; dir(math)</span><br><span class="line">[&apos;__doc__&apos;, &apos;__loader__&apos;, &apos;__name__&apos;,...]</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>同样需要首先导入该模块</p><h4 id="查看模块下特定函数信息help-module-name-func-name"><a href="#查看模块下特定函数信息help-module-name-func-name" class="headerlink" title="查看模块下特定函数信息help(module_name.func_name)"></a>查看模块下特定函数信息help(module_name.func_name)</h4><p>如查看math下的sin()函数</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; help(math.sin)</span><br><span class="line">Help on built-in function sin in module math:</span><br><span class="line"></span><br><span class="line">sin(...)</span><br><span class="line">    sin(x)</span><br><span class="line"></span><br><span class="line">    Return the sine of x (measured in radians).</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><h4 id="查看函数信息的另一种方法print-func-name-doc"><a href="#查看函数信息的另一种方法print-func-name-doc" class="headerlink" title="查看函数信息的另一种方法print(func_name.doc)"></a>查看函数信息的另一种方法print(func_name.<strong>doc</strong>)</h4><p>如查看内建函数print用法。既可以用来查看内建函数，也可以查看模块函数信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; print(print.__doc__)</span><br><span class="line">print(value, ..., sep=&apos; &apos;, end=&apos;\n&apos;, file=sys.stdout, flush=False)</span><br><span class="line"></span><br><span class="line">Prints the values to a stream, or to sys.stdout by default.</span><br><span class="line">...</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><blockquote><p><strong>doc</strong>前后是两个短下划线，在python中会合并为长下划线<br>python中的help()类似unix中的man指令，熟悉后会对我们的编程带来很大帮助</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;python的一个优势是有着大量自带和在线的模块(module)资源，可以提供丰富的功能，在使用这些模块的时候，如果每次都去网站找在线文档会过于耗费时间，结果也不一定准确。因此这里介绍下python自带的查看帮助功能，可以在编程时不中断地迅速找到所需模块和函数的使用方法。&lt;
      
    
    </summary>
    
      <category term="python" scheme="hjx051013.github.io/categories/python/"/>
    
    
      <category term="python使用" scheme="hjx051013.github.io/tags/python%E4%BD%BF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>python中的lambda表达式</title>
    <link href="hjx051013.github.io/2018/11/29/python-lambda/"/>
    <id>hjx051013.github.io/2018/11/29/python-lambda/</id>
    <published>2018-11-29T14:29:38.000Z</published>
    <updated>2018-11-29T14:55:33.980Z</updated>
    
    <content type="html"><![CDATA[<p>这里，我们通过阅读各方资料，总结了关于Python中的lambda的“一个语法，三个特性，四个用法”。</p><h3 id="一个语法"><a href="#一个语法" class="headerlink" title="一个语法"></a>一个语法</h3><p>在Python中，lambda的语法是唯一的。其形式如下：</p><blockquote><p>lambda argument_list: expression</p></blockquote><p>其中，lambda是Python预留的关键字，argument_list和expression由用户自定义。具体介绍如下。<br>这里的argument_list是参数列表。它的结构与Python中函数(function)的参数列表是一样的。具体来说，argument_list可以有非常多的形式。例如：</p><ul><li>a, b</li><li>a=1, b=2</li><li>*args</li><li>**kwargs</li><li>a, b=1, *args</li><li>空</li><li>……</li></ul><p>这里的expression是一个关于参数的表达式。表达式中出现的参数需要在argument_list中有定义，并且表达式只能是单行的。以下都是合法的表达式：</p><ul><li>1</li><li>None</li><li>a + b</li><li>sum(a)</li><li>1 if a &gt;10 else 0</li><li>……</li></ul><p>这里的<code>lambda argument_list: expression</code>表示的是一个函数。这个函数叫做lambda函数。</p><h3 id="三个特性"><a href="#三个特性" class="headerlink" title="三个特性"></a>三个特性</h3><p>lambda函数有如下特性：</p><ul><li>lambda函数是匿名的：所谓匿名函数，通俗地说就是没有名字的函数。lambda函数没有名字。</li><li>lambda函数有输入和输出：输入是传入到参数列表argument_list的值，输出是根据表达式expression计算得到的值。</li><li>lambda函数一般功能简单：单行expression决定了lambda函数不可能完成复杂的逻辑，只能完成非常简单的功能。由于其实现的功能一目了然，甚至不需要专门的名字来说明。</li></ul><p>下面是一些lambda函数示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lambda x, y: x*y；函数输入是x和y，输出是它们的积x*y</span><br><span class="line"></span><br><span class="line">lambda:None；函数没有输入参数，输出是None</span><br><span class="line"></span><br><span class="line">lambda *args: sum(args); 输入是任意个数的参数，输出是它们的和(隐性要求是输入参数必须能够进行加法运算)</span><br><span class="line"></span><br><span class="line">lambda **kwargs: 1；输入是任意键值对参数，输出是1</span><br></pre></td></tr></table></figure></p><h3 id="四个用法"><a href="#四个用法" class="headerlink" title="四个用法"></a>四个用法</h3><p>由于lambda语法是固定的，其本质上只有一种用法，那就是定义一个lambda函数。在实际中，根据这个lambda函数应用场景的不同，可以将lambda函数的用法扩展为以下几种：</p><ol><li>将lambda函数赋值给一个变量，通过这个变量间接调用该lambda函数。例如，执行语句<code>add=lambda x, y: x+y</code>，定义了加法函数<code>lambda x, y: x+y</code>，并将其赋值给变量add，这样变量add便成为具有加法功能的函数。例如，执行add(1,2)，输出为3。</li><li>将lambda函数赋值给其他函数，从而将其他函数用该lambda函数替换。例如，为了把标准库time中的函数sleep的功能屏蔽(Mock)，我们可以在程序初始化时调用：<code>time.sleep=lambda x:None</code>。这样，在后续代码中调用time库的sleep函数将不会执行原有的功能。例如，执行<code>time.sleep(3)</code>时，程序不会休眠3秒钟，而是什么都不做。</li><li>将lambda函数作为其他函数的返回值，返回给调用者。函数的返回值也可以是函数。例如<code>return lambda x, y: x+y</code>返回一个加法函数。这时，lambda函数实际上是定义在某个函数内部的函数，称之为嵌套函数，或者内部函数。对应的，将包含嵌套函数的函数称之为外部函数。内部函数能够访问外部函数的局部变量，这个特性是闭包(Closure)编程的基础，在这里我们不展开。</li><li>将lambda函数作为参数传递给其他函数。<ul><li>部分Python内置函数接收函数作为参数。典型的此类内置函数有这些。filter函数。此时lambda函数用于指定过滤列表元素的条件。例如<code>filter(lambda x: x % 3 == 0, [1, 2, 3])</code>指定将列表[1,2,3]中能够被3整除的元素过滤出来，其结果是[3]。</li><li>sorted函数。此时lambda函数用于指定对列表中所有元素进行排序的准则。例如<code>sorted([1, 2, 3, 4, 5, 6, 7, 8, 9], key=lambda x: abs(5-x))</code>将列表[1, 2, 3, 4, 5, 6, 7, 8, 9]按照元素与5距离从小到大进行排序，其结果是[5, 4, 6, 3, 7, 2, 8, 1, 9]。</li><li>map函数。此时lambda函数用于指定对列表中每一个元素的共同操作。例如<code>map(lambda x: x+1, [1, 2,3])</code>将列表[1, 2, 3]中的元素分别加1，其结果[2, 3, 4]。</li><li>reduce函数。此时lambda函数用于指定列表中两两相邻元素的结合条件。例如<code>reduce(lambda a, b: &#39;{}, {}&#39;.format(a, b), [1, 2, 3, 4, 5, 6, 7, 8, 9])</code>将列表 [1, 2, 3, 4, 5, 6, 7, 8, 9]中的元素从左往右两两以逗号分隔的字符的形式依次结合起来，其结果是’1, 2, 3, 4, 5, 6, 7, 8, 9’。</li><li>另外，部分Python库函数也接收函数作为参数，例如gevent的spawn函数。此时，lambda函数也能够作为参数传入。</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这里，我们通过阅读各方资料，总结了关于Python中的lambda的“一个语法，三个特性，四个用法”。&lt;/p&gt;
&lt;h3 id=&quot;一个语法&quot;&gt;&lt;a href=&quot;#一个语法&quot; class=&quot;headerlink&quot; title=&quot;一个语法&quot;&gt;&lt;/a&gt;一个语法&lt;/h3&gt;&lt;p&gt;在Py
      
    
    </summary>
    
      <category term="python" scheme="hjx051013.github.io/categories/python/"/>
    
    
      <category term="python" scheme="hjx051013.github.io/tags/python/"/>
    
      <category term="lambda表达式" scheme="hjx051013.github.io/tags/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>线性代数行列式总结</title>
    <link href="hjx051013.github.io/2018/11/28/post/"/>
    <id>hjx051013.github.io/2018/11/28/post/</id>
    <published>2018-11-28T03:24:25.000Z</published>
    <updated>2018-11-29T14:58:17.494Z</updated>
    
    <content type="html"><![CDATA[<p>最近入坑机器学习，线性代数的知识用到很多，所以就回顾了一下，发现也是挺有意思的。<br>行列式对于方阵给出一个特殊的定义值，与方阵的秩和方阵对应的齐次线性方程有没有唯一非零解有着很大的关系。</p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>当$n\geq2$时，$n\times n$矩阵$A=\begin{bmatrix}a_{ij}\end{bmatrix}$的行列式是形如$\pm a_{ij} detA_{ij}$的n个项的和，其中加减号交替出现，这里的$a_{11},a_{12},a_{13}…a_{1n}$来自于第一行，即</p><script type="math/tex; mode=display">\begin{aligned}detA&=a_{11}\cdot detA_{11}-a_{12}\cdot detA_{12}+\cdots +(-1)^{1+n}a_{1n}detA_{1n}\\&=\sum_{j=1}^{n}(-1)^{1+j}a_{1j}detA_{1j}\\\end{aligned}</script><p>当然这是针对第一行展开的，从中可以看出$n\times n$阶的行列式被展开成若干个$(n-1)\times(n-1)$阶的行列式。$detA_{1j}$称为代数余子式，是划掉行列式A的第$1$行第$j$列后余下行列式的值，也可以对第$i$行进行展开，$1$替换成$i$即可。同样地，也可以对某一列进行展开。</p><h4 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h4><ol><li>若$A$为三角阵，则$detA$为主对角线上元素乘积。这里的三角阵仅考虑行列式主对角线上边或下边元素全为零的情况。</li><li><p>行变换性质。令$A$是一个方阵，则有</p><ul><li>若$A$的一行加上另一行的倍数得到$B$，则$detA=detB$ </li><li>若$A$的两行互换得到$B$，则$detA=-detB$</li><li>若$A$的某行乘以k得到$B$，则$detA=kdetB$</li><li>$A$中有任何一行为0，则$detA=0$</li></ul><p>实际上，列变换也具有这些性质<br>通过行列式的行变换，可以将一个复杂的行列式化简成三角型，如果化成阶梯型后不是三角型，则说明行列式值为0。</p><ol><li>当且仅当$detA\neq 0$时方阵$A$是可逆的</li><li>若$A$为一个$n\times n$矩阵，则$detA^T=detA$</li><li>乘法性质。$det(AB)=(detA)(detB)$</li></ol></li></ol><h4 id="线性方程组的解集问题"><a href="#线性方程组的解集问题" class="headerlink" title="线性方程组的解集问题"></a>线性方程组的解集问题</h4><ul><li>齐次线性方程组的解集<ul><li>首先说一下什么是齐次线性方程组。就是方程组可以写成$A\textbf x=\textbf 0$，$A$是系数矩阵($m\times n$阶)，$\textbf x$是未知数n维列向量。显然这个方程必然有零解($x_1=0,x_2=0\cdots x_n=0$)。</li><li>有没有非零解，取决于方程组有没有自由变量。如果系数矩阵的行秩$\geq$未知数个数n（事实上只能$=$，因为任何矩阵行秩$=$列秩$=$秩），也就是线性无关的有效方程的个数$=$未知数个数n，方程只有零解。如果小于，则$n-$行秩就是方程组自有变量的个数。如果$x_1,x_2$是自有变量的话，那么通解为$\textbf x=x_1\textbf u+x_2\textbf v$，$\textbf u,\textbf v$为由方程解出来的列向量。</li></ul></li><li>非齐次线性方程的解集<ul><li>非齐次线性方程组是为$A\textbf x=\textbf b$的形式，$\textbf b$为n维非$0$列向量。它的解有三种情况，由增广矩阵<br>$\begin{bmatrix}A&amp;\textbf b\end{bmatrix}$与系数矩阵$A$的秩的关系决定。若$r_{系数矩阵}=r_{增广矩阵}=n$，则有唯一解；若$r_{系数矩阵}=r_{增广矩阵}&lt;n$,则有无穷解。若$r_{系数矩阵}\neq r_{增广矩阵}$，则无解。（其中n为未知数的个数）。$r_{系数矩阵}\neq r_{增广矩阵}$反映了给定的线性方程组有互相矛盾的情况，其差为矛盾线性方程的个数；若$r_{系数矩阵}=r_{增广矩阵}&lt;n$，则说明给定的线性无关方程的个数小于未知变量个数，自然会有无穷多个解。<ul><li>如果非齐次线性方程组有解，且p是一个特解，则$A\textbf x=\textbf b$的解集所有形如$\textbf w=\textbf p+\textbf v_{h}$，其中$\textbf v_{h}$是齐次线性方程组$A\textbf x=\textbf 0$的通解。<h4 id="克拉默法则"><a href="#克拉默法则" class="headerlink" title="克拉默法则"></a>克拉默法则</h4>克拉默法则是用来求解系数矩阵为方阵且可逆的非齐次线性方程组的唯一解的定理。首先定义一个替换矩阵，对于任意$n\times n$矩阵$A$和任意$\mathbb{R^{n}}$中向量$\textbf b$，令${A_i(b)}$表示$A$中第i列由向量$b$替换得到的矩阵。即</li></ul></li></ul></li></ul><script type="math/tex; mode=display">{A_i(b)=}\begin{bmatrix} {a_1}& \cdots &{b}  &\cdots  &{a_n} \end{bmatrix}</script><p>接下来正式说明一下什么是克拉默法则<br>设$ A$是一个可逆的$n\times n$矩阵，对任意$\mathbb{R^{n}}$中向量$ b$，方程${Ax=b}$的唯一解可由下式给出，</p><script type="math/tex; mode=display">{x_i=\frac{detA_ib}{detA},i=1,2\cdots n}</script><p>$detA\neq 0$再加上$n\times n$方阵的条件可以说明$r_{系数矩阵}=r_{增广矩阵}=n$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近入坑机器学习，线性代数的知识用到很多，所以就回顾了一下，发现也是挺有意思的。&lt;br&gt;行列式对于方阵给出一个特殊的定义值，与方阵的秩和方阵对应的齐次线性方程有没有唯一非零解有着很大的关系。&lt;/p&gt;
&lt;h4 id=&quot;定义&quot;&gt;&lt;a href=&quot;#定义&quot; class=&quot;head
      
    
    </summary>
    
      <category term="机器学习" scheme="hjx051013.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="线性代数" scheme="hjx051013.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
      <category term="行列式" scheme="hjx051013.github.io/tags/%E8%A1%8C%E5%88%97%E5%BC%8F/"/>
    
  </entry>
  
</feed>
